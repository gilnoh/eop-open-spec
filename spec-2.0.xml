<?xml version="1.0" encoding="ISO-8859-1"?>

<?xml-stylesheet type="text/xsl" 
href="file://./stylesheets/oasis-specification-html-offline.xsl"?>

<!DOCTYPE article
  PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"./docbook/docbookx.dtd"
[
<!--the document properties-->
<!ENTITY name "Excitement Open Platform Specification (DRAFT)">
<!ENTITY pversion "2.0">
<!ENTITY version "2.0.0">
<!ENTITY stage "draft">
<!ENTITY standard "Specification V2.0">
<!ENTITY this-loc "http://hltfbk.github.io/Excitement-Open-Platform/specification"> 
<!ENTITY this-loc "http://hltfbk.github.io/Excitement-Open-Platform/specification/spec-&version;"> 
<!ENTITY previous-loc "http://hltfbk.github.io/Excitement-Open-Platform/specification/spec-&version;"> 
<!ENTITY latest-loc "http://hltfbk.github.io/Excitement-Open-Platform/specification/spec-&version;"> 
<!ENTITY pubdate "14 March 2014">
]>

<article status="&stage;">
<articleinfo>
<title>EXCITEMENT open platform: Architecture and Interfaces</title> 

<!-- <releaseinfo role="cvs"> -->
<!-- <?nospell-start?>$Id: spectools-docbook-template-wd03.xml,v 1.4 2010/07/08 12:28:15 admin Exp $<?nospell-end?> -->
<!-- </releaseinfo> -->

<productname>&name;</productname>
<productnumber>&stage;</productnumber>

<releaseinfo role="OASIS-specification-this-authoritative">&this-loc;/&name;-&stage;.html</releaseinfo>
<releaseinfo role="OASIS-specification-this">&this-loc;/&name;-&stage;.pdf</releaseinfo>
<releaseinfo role="OASIS-specification-this">&this-loc;/&name;-&stage;.xml</releaseinfo>

<releaseinfo role="OASIS-specification-previous">&previous-loc;/&name;.html</releaseinfo>
<releaseinfo role="OASIS-specification-previous">&previous-loc;/&name;.pdf</releaseinfo>
<releaseinfo role="OASIS-specification-previous">&previous-loc;/&name;.xml</releaseinfo>

<releaseinfo role="OASIS-specification-latest-authoritative">&latest-loc;/&name;.html</releaseinfo>
<releaseinfo role="OASIS-specification-latest">&latest-loc;/&name;.pdf</releaseinfo>
<releaseinfo role="OASIS-specification-latest">&latest-loc;/&name;.xml</releaseinfo>
<!-- <?nospell-end?> -->
<!-- <releaseinfo role="committee"><ulink url="http://www.oasis-open.org/committees/">OASIS {official name of technical committee} TC</ulink></releaseinfo> -->

<authorgroup>
<!-- <editor> -->
<!--   <firstname>{Jane}</firstname><surname>{Doe}</surname> -->
<!--   <affiliation> -->
<!--     <orgname>{Example Corporation}</orgname> -->
<!--     <address><email>{jane.doe@example.com}</email></address> -->
<!--   </affiliation> -->
<!-- </editor> -->
<author>
  <firstname>Tae-Gil</firstname><surname>Noh</surname>
  <affiliation>
    <orgname>Heidelberg University</orgname>
    <address><email>noh@cl.uni-heidelberg.de</email></address>
  </affiliation>
</author>
<author>
  <firstname>Sebastian</firstname><surname>Pado</surname>
  <affiliation>
    <orgname>Heidelberg University</orgname>
    <address><email>pado@cl.uni-heidelberg.de</email></address>
  </affiliation>
</author>
<author>
  <firstname>Asher</firstname><surname>Stern</surname>
  <affiliation>
    <orgname>Bar Ilan University</orgname>
    <address><email>astern7@gmail.com</email></address>
  </affiliation>
</author>
<author>
  <firstname>Ofer</firstname><surname>Bronstein</surname>
  <affiliation>
    <orgname>Bar Ilan University</orgname>
    <address><email>oferbr@gmail.com</email></address>
  </affiliation>
</author>
<author>
  <firstname>Rui</firstname><surname>Wang</surname>
  <affiliation>
    <orgname>DFKI</orgname>
    <address><email>wang.rui@dfki.de</email></address>
  </affiliation>
</author>
<author>
  <firstname>Roberto</firstname><surname>Zanoli</surname>
  <affiliation>
    <orgname>FBK</orgname>
    <address><email>zanoli@fbk.eu</email></address>
  </affiliation>
</author>


</authorgroup>

<pubdate>&pubdate;</pubdate>

<!-- <copyright><year>2010</year> -->
<!-- <holder>OASIS Open, Inc. All Rights Reserved.</holder></copyright> -->

<abstract>
<para>This specification defines various parts of the EXCITEMENT
open platform.</para>
</abstract>

<!--<legalnotice role="status"><title>Status</title>
<para>Deliverable Draft: This release is for internal review process
targeted to Specification 1.0 Deliverable (Deliverable 3.1a). </para> 
-->

<!--<legalnotice role="notices"><title>Notices</title>
<para> {Describe all "Legal" things here (for example, copyrights &amp; IPR notice of the document). Also note official names, partners, acknowledgement, and etc.}
</para> 
</legalnotice>-->

</articleinfo>

<section>
<title>Introduction</title>
<section>
<title>Preface to the specification version 2.0</title>
<formalpara>
<title>Short history of the specification</title>
<para>The EXCITEMENT open platform specification has been first
published in June 2012, as version 1.0. This first version defined
backbones of the EXCITEMENT open platform with major component types,
data structures and conventions for the development of the open
platform. The specification has been updated a few time during the
actual development progress. Version 1.1 was released in August
2012. This version  was a major update that provided missing parts to
version 1.0, and became the blueprint for the platform development
over 2012 and 2013. The last version of specification 1.1 is <ulink
url="http://hltfbk.github.io/Excitement-Open-Platform/specification/spec-1.1.4.pdf">
specification version 1.1.4</ulink>, published in October 2013. 
<ulink url="http://hltfbk.github.io/Excitement-Open-Platform/">
EXCITEMENT open platform (EOP)</ulink> has been successfully
developed following the specification. EXCITEMENT open platform
(version 1.1.1, at the time of writing) is a matured,
well-documented, multi-lingual, open-source Textual Inference
platform.
</para> 
</formalpara>

<formalpara>
<title>Scope of the specification 2.0 </title>
<para>Specification 1.0 introduced a common platform that can
support different RTE (Recognizing Textual Entailment) systems on
multiple languages. One of the main goal was (and still is) making the
platform a paradigm-neutral platform, where various Textual Inference
approaches can share their components. This goal was very broad.
Thus, the consortium adopted a practical strategy of analyzing and
utilizing three existing RTE systems as the basis. This was a very
successful strategy, and delivered a multilingual platform with
easy-to-share components. But the strategy also had its limits. For
example, the specification did not cover some other RTE approaches
(like alignment-based method), and its scope did not include support
for novel research topics. In this sense, spec 1.0 was an enabler that
allowed us to fuse three existing RTE systems into one coherent
platform.      
We now broaden the scope of the open specification with the version
2.0 and beyond. Basically, specification 2.0 is still a linear 
extension of specification version 1.1. All the major structures, and
components are already stable and there is no major updates on those 
existing modules. However, Spec 2.0 also aims to achieve more than
consolidating existing pre-EOP systems. Specification 2.0 adds
content to support additional data types and component types that
were not part of any of the existing systems. This includes alignment
components, phrases-level resources, context sensitive lexical
resources, and support for new Entailment Decision Algorithms
(EDAs). The following list outlines major new component types and
updated sections that are new to specification 2.0. 
<itemizedlist>
<listitem><para>Context sensitive Lexical resource (<xref
linkend="context_sensitive_lexical_resource"/>)</para></listitem> 
<!-- <listitem><para>Phrase level knowledge resource (TODO add XREF
once added) </para></listitem> --> 
<listitem><para>Annotation component (<xref linkend="annotator_component"/>)</para></listitem>   
<listitem><para>Alignment component and alignment CAS types (<xref
linkend="alignment_component"/>)</para></listitem>     
<listitem><para>Training interface for components (<xref
linkend="interface_trainable"/>)</para></listitem>    
<listitem><para>Sentence Similarity Decision
Algorithm (<xref linkend="SDA" />)</para></listitem>  
<!-- <listitem><para>Updates on Syntactic resource
component</para></listitem>   --> 
</itemizedlist>
Please note that other sections, such as LAP interface sections,
configuration sections and details of syntactic resources, also
received minor updates. For the full list of changes since the
specification version 1.0 (Deliverable 3.1a), please see <xref
linkend="list_of_changes"/>.  
</para> 
</formalpara>

<formalpara>
<title>Related documents</title> 
<para>If you are reading this specification for the first time (no
prior experience on the specification or the platform), maybe it is
better to start with a journal paper that describes the platform in 
general <xref linkend="jnle2013"/> . Also, The UIMA part of the
platform (type systems and UIMA module adaptation) is well summarized
in a workshop paper <xref linkend="uimaws2013"/>. 

</para> 
</formalpara> 


</section>

<section>
<title>Introduction to EXCITEMENT open specification</title> 
<para>
Identifying semantic inference relations between texts is a major
underlying language processing task, needed in practically all text
understanding applications. For example, Question Answering and
Information Extraction systems should verify that extracted answers
and relations are indeed inferred from the text passages. While such
apparently similar inferences are broadly needed, there are currently
no generic semantic <emphasis>inference engines</emphasis>, that is,
platforms for broad textual inference.
</para>

<para>
Annotation tools do exist for narrow semantic tasks (i.e. they
consider one phenomenon at a time and one single fragment of text at
time). Inference systems assemble and augment them to obtain a
complete inference process. By now, a variety of architectures and
implemented systems exist, most at the scientific prototype stage. The
problem is that there is no standardization across systems, which
causes a number of problems. For example, reasoning components cannot
be re-used, nor knowledge resources exchanged. This hampers in
particular the pick-up of textual entailment as a "standard"
technology in the same way that parsing is used, by researchers in
semantics or NLP applications.
</para>

<para>EXCITEMENT has two primary goals (see the project proposal for
details):
<orderedlist>
<listitem><para>Goal A: Develop and advance a comprehensive
open-source platform for multi-lingual textual inference, based on the
textual entailment paradigm.</para></listitem>
<listitem><para>Goal B: Inference-based exploration and processing of
customer interactions at the statement level, for multiple languages
and interaction channels.  </para></listitem>
</orderedlist>
where Goal B builds strongly on the development of the platform for
Goal A. We envisage the role of this platform to be similar to the one
played by MOSES in the Machine Translation community -- that is, as a
basis for reusable development. For these goals, we work towards the
following properties:
<orderedlist>
<listitem><para><emphasis>Algorithm independence.</emphasis> The
platform should be able to accommodate a wide range of possible
algorithms (or more generally, strategies) for entailment
inference.</para></listitem>
<listitem><para><emphasis>Language independence.</emphasis> Similarly,
the platform should be, as far as possible, agnostic to the language
that is processes so that it can be applied to new languages in a
straightforward manner. </para></listitem>
<listitem><para><emphasis>Component-based architecture.</emphasis> We
base our approach onto the decomposition of entailment inference
decisions into a set of more or less independent components which
encapsulate some part of the entailment computation -- such as the
overall decision and different kinds of knowledge. Since components
communicate only through well-defined interfaces, this architecture
makes it possible to combine the best possible set of components given
the constraints of a given application scenario, and the re-use of
components that have been developed.
</para></listitem>
<listitem><para><emphasis>Versatility. </emphasis>The platform
should be configurable in different ways to meet the needs of
different deployment scenarios. For example, for deployment in
industrial settings, efficiency will be a primary consideration, while
research applications may call for a focus on precision.</para></listitem>
<listitem><para><emphasis>Clear specification and
documentation.</emphasis></para></listitem> 
<listitem><para><emphasis>Reference implementation.</emphasis> We will
provide an implementation of the platform that covers a majority of
proposed entailment decision algorithms together with large knowledge
resources for English, German, and Italian.</para></listitem>
</orderedlist>
</para>

<para>
For reasons of practicality, the implementation will be based on three
preexisting systems for textual entailment. These systems are:
<itemizedlist>
<listitem><para><emphasis>BIUTEE</emphasis>, The Bar Ilan University
Textual Entailment Engine (BIU) <biblioref linkend="report_BIUTEE"/>.</para></listitem>
<listitem><para><emphasis>EDITS</emphasis>, an edit distance-based
approach to textual entailment recognition (FBK) <biblioref linkend="report_EDITS"/>.</para></listitem>
<listitem><para><emphasis>TIE</emphasis>, Textual Inference Engine (DFKI) <biblioref linkend="report_TIE"/>.</para></listitem>
</itemizedlist>
</para>

<para>The role of this document is to meet the third goal -- to
provide a specification of the EXCITEMENT platform. Our goal for the
specification is to be as general as possible (in order to preserve
the goal of generality) while remaining as specific as necessary (to
ensure compatibility). At a small number of decisions, we have
sacrificed generality in order to keep the implementation effort
manageable; these decisions are pointed out below.
</para>

<para>
The structure of this document mirrors the aspects of the EXCITEMENT
platform that require specification. These aspects fall into two
categories: actual interfaces, and specification of meta-issues.
</para>

<para>
Regarding interfaces, we have to specify:
<orderedlist numeration="loweralpha">
<listitem><para> The linguistic analysis pipeline which creates some
data structure with linguistic information which serves as the input
for the actual entailment inference (Section 3). </para></listitem>
<listitem><para>The interfaces between components and component groups
within the actual entailment computation (Section
4).</para></listitem>
</orderedlist>
As for meta-issues, we need to address:
<orderedlist continuation="continues" numeration="loweralpha">
<listitem><para>The shape of the overall architecture and the
definition of terminology (Section 2).</para></listitem>
<listitem><para>Further standardization issues such as configuration,
shared storage of resources, error handling etc. (Section
5)</para></listitem>
</orderedlist>

Outside the scope of this document is the specification of
the transduction layer. This layer is part of the work towards Goal
B. It translates between the queries posed by the industrial partners'
use cases and entailment queries that can be answered by the open
platform developed for Goal A. The transduction layer is described in
a separate document (Deliverable 3.2b). Note that, the EOP and TL
specifications are compatible irrespective of releases. 
</para>
</section>
</section> 

<!-- Section 2 -->


<section> <title>Elements of the EXCITEMENT platform</title>


<section> <title>The Platform</title>
<para>
As sketched, we assume that it is beneficial to decompose the
recognition of textual entailment into individual components which are
best developed and independent of each other. This approach gives rise
to the overall system architecture that is shown in <xref
linkend="platform_overview"/>.
</para>

<figure id="platform_overview">
<title>The EXCITEMENT platform</title>
<mediaobject>
<imageobject>
<imagedata fileref="./figures/architecture-overview.jpg" scalefit="1" width="90%"
	   align="center"/> 
</imageobject>
</mediaobject>
</figure>

<para>
The most important top-level distinction is between the
<emphasis>Linguistic Analysis Pipeline (LAP)</emphasis> and the
<emphasis>Entailment Core</emphasis>. We separate these two parts in
order to (a), on a conceptual level, ensure that the algorithms in the
Entailment Core only rely on linguistic analyses in well-defined ways;
and (b), on a practical level, make sure that the LAP and the
Entailment Core can be run independently of one another (e.g., to
preprocess all data beforehand).
</para>

<para>
Since it has been shown that deciding entailment on the basis of
unprocessed text is a very difficult endeavor, the Linguistic
Analysis Pipeline is essentially a series of annotation modules that
provide linguistic annotation on various layers for the input. The
Entailment Core then performs the actual entailment computation on the
basis of the processed text.
</para>

<para>
The Entailment Core itself can be further decomposed into exactly one
<emphasis>Entailment Decision Algorithm (EDA)</emphasis> and 
zero or more <emphasis>Components</emphasis>. An Entailment Decision
Algorithm is a special Component which computes an entailment decision
for a given Text/Hypothesis pair. Trivially, each complete Entailment
Core is an EDA. However, the goal of EXCITEMENT is exactly to identify
functionality within Entailment Cores that can be re-used and, for
example, combined with other EDAs. Examples of functionality that are
strong candidates for Components are WordNet (on the knowledge side)
and distance computations between text and hypothesis (on the
algorithmic side). Both of these can be combined with EDAs of
different natures, and should therefore be encapsulated in Components.
</para>
</section>

<section><title>Engines: Instantiations of the Platform</title>
<para>
In order to use the EXCITEMENT infrastructure, a user will have to
configure the platform for his application setting, that is, for his
language and his analysis tools (on the pipeline side) and for his
algorithm and components (on the entailment core side). 
</para>

<para>
For an example, consider Figure <xref linkend="edits_engine"/>. It
shows an engine instantiating the EXCITEMENT platform that mirrors the
functionality of the EDITS system. The linguistic analysis pipeline
remains very basic and only provides fundamental tasks (sentence
segmentation and tokenization). The components are different variants
of simple distance and overlap measures (at the string token level)
between text and hypothesis.  The EDA is a simple linear classifier
which computes weighted output of the components into a final score and
compares it against a threshold.
</para>
<para>
This is a supervised learning setup -- both the weights for components
and the threshold must be learned. Therefore, training must be part of
the EXCITEMENT platform's functionality.
</para>
<para>
Note also that although this engine is fairly generic, it is not
completely language-independent. Language-specific functionality is
definitely part of the content word overlap component (at least in the
form of a "closed class word list") and potentially also in the
linguistic analysis pipeline, for example in the form of tokenization
knowledge. For this reason, the LAP must enrich the input with meta
data that describes its language, as well as the performed
preprocessing steps so that the Entailment Core can verify the
applicability of the current Engine configuration to the input data.
</para>

<figure id="edits_engine">
<title>An EDITS-style EXCITEMENT engine</title>
<mediaobject>
<imageobject>
<imagedata fileref="./figures/edits-engine.jpg" scalefit="1" width="90%"
	   align="center"/> 
</imageobject>
</mediaobject>
</figure>


</section>

<!--<para> { This part will summarizes and overview the next section (actual
%specification). This section should be able to describe the general
impressions on why, how, and on what level the common definitions are
drawn for EXCITEMENT framework. In the first part (2.1) it should
describe the whole platform. The other parts (2.2.1, 2.2.2 ...)  should
describe the scope and issues of the specifications. In some sense, the
sections will look like the "memo on the scope of common interfaces"
with all its issues resolved. } </para> -->


<!--   </section> --> 
<!-- end of Architecture Overview --> 

      <!-- <section><title>Lexical Knowledge Resources</title> -->
      <!--    <para> {will be converted and expanded} </para> -->
      <!-- </section> -->

      <!-- <section><title>Lexico-Syntactic Knowledge Resources</title> -->
      <!--    <para> {will be expanded} </para> -->
      <!-- </section> -->

      <!-- <section><title>Distance/Similarity Calculation Components </title> -->
      <!--    <para> {will be expanded} </para> -->
      <!-- </section> -->

      <!-- <section><title>Entailment Decision Algorithms </title> -->
      <!--    <para> {will be expanded} </para> -->
      <!-- </section> -->

      <!-- <section><title>Linguistic Analysis Pipelines </title> -->
      <!--    <para> {will be expanded}  </para> -->
      <!-- </section> -->


    <section><title>Concepts and Terminology</title>
       <section> <title>Key words</title>
          <para>The key words <glossterm>must</glossterm>, <glossterm>must
	  not</glossterm>, <glossterm>required</glossterm>,
	  <glossterm>shall</glossterm>, <glossterm>shall not</glossterm>,
	  <glossterm>should</glossterm>, <glossterm>should not</glossterm>,
	  <glossterm>recommended</glossterm>, <glossterm>may</glossterm>, and
	  <glossterm>optional</glossterm> are to be
	  interpreted as described in <xref linkend="rfc2119"/>. Note that for
	  reasons of style, these words are not capitalized in this
	  document.</para>
       </section>
       <section> <title>Key Terms (Content)</title>
       <variablelist>
	 <varlistentry>
	   <term>
	   Entailment Platform</term>
	   <listitem><para> The totality of the infrastructure
	   provided by the EXCITEMENT project for all languages and
	   entailment paradigms. The Platform can be configured
	   into an Entailment Engine.</para>
	   </listitem>
	 </varlistentry>
	 <varlistentry>
	   <term>
	   Entailment Engine</term>
	   <listitem><para> A configured instance of the Entailment
	   Platform that makes entailment decisions for one
	   language. An Entailment Engine consists of a Linguistic
	   Analysis Pipeline and an Entailment Core.</para>
	   </listitem>
	 </varlistentry>
	 <varlistentry>
	   <term>
	   Linguistic Analysis Pipeline (LAP)</term>
	   <listitem><para> A set of linguistic tools that analyze a
	   given set of Text-Hypothesis pairs, typically performing steps such as
	   sentence splitting, POS tagging, Named Entity Recognition etc.
	   </para>
	   </listitem>
	 </varlistentry>
	 <varlistentry>
	   <term>
	   Entailment Core</term>
	   <listitem><para> A part of an Entailment Platform that
	   decides entailment for a set of Text-Hypothesis pairs that
	   have been processed in the Linguistic Analysis
	   Pipeline. The Entailment Core consists of exactly one
	   Entailment Decision Algorithm and zero or more
	   Components.</para>
	   </listitem>
	 </varlistentry>
	 <varlistentry>
	   <term>
	   Entailment Decision Algorithm (EDA)</term>
	   <listitem><para> An Entailment Decision Algorithm is a
	   Component which takes a Text-Hypothesis pair and returns
	   one of a small set of answers. <!-- (NB: discuss this
	   tomorrow!!)  --> A complete entailment recognition system is
	   trivially an EDA. However, in the interest of re-usability,
	   generic parts of the system should be made into individual
	   Components. Entailment Decision Algorithms communicate with
	   Components through generic specified interfaces. 
	   </para>
	   </listitem>
	 </varlistentry>
	 <varlistentry>
	   <term>
	   Component</term>
	   <listitem><para> Any functionality that is part of an
	   entailment decision and which is presumably reusable. This
	   covers both "static" functionality (that is, knowledge) and
	   "dynamic" functionality (that is, algorithms). A typology
	   of Components is given in <xref
	   linkend="sec-4.1.3"/>.</para>
	   </listitem>
	 </varlistentry>
	 <varlistentry>
	   <term>
	   User code</term>
	   <listitem><para>Any code that calls the interfaces and
	   utilizes the types defined in this specification. This
	   includes the "top level" entailment code that calls the LAP
	   and the EDA to apply an engine to an actual
	   data-set.</para></listitem>
	 </varlistentry>
       </variablelist>
       </section>
       <section> <title>Key Terms (Methodology)</title>
       <variablelist>
	 <varlistentry>
	   <term>
	   Interface</term>
	   <listitem><para> A set of methods and their signatures for
	   a class that define how the class is supposed
	   to interact with the outside world</para></listitem></varlistentry>
	 <varlistentry>
	   <term>
	   Type</term>
	   <listitem><para> We use the term "type" for classes that
	   denote data structures (i.e. which have a representational,
	   rather than algorithmic, nature). </para></listitem></varlistentry>
	 <varlistentry>
	   <term>
	   Contract</term>
	   <listitem><para> Further specification on how to use
	   particular interfaces and types that goes beyond
	   signatures. For example, rules on initialization of
	   objects or pre/postconditions for method calls. 
	   </para></listitem></varlistentry>
       </variablelist>
       </section>
    </section>


<!-- Gil: LICENSE issue is no longer needed in the spec. --> 

<!-- <section> -->
<!-- <title>Licensing considerations -->
<!-- </title> -->
<!-- <para>The goal of this document is to define interfaces that allow the -->
<!-- use of a wide range of externally developed linguistic analysis -->
<!-- modules and inference components within the EXCITEMENT platform. An -->
<!-- issue that arises in practice is that externally developed software -->
<!-- will come with its own licenses, which may be problematic. (NB. This -->
<!-- question also concerns libraries that might be used in EXCITEMENT, for -->
<!-- example regarding data input/output or configuration.) -->
<!-- </para> -->
<!-- <para>This issue requires more future discussion among partners. Our -->
<!-- momentary analysis of the situation is that we need to distinguish -->
<!-- between the two major application scenarios of EXCITEMENT, namely as -->
<!-- the open-source platform and in industry partners' systems. -->
<!-- <orderedlist> -->
<!-- <listitem><para>Open-Source Platform. Within the open-source platform, -->
<!-- externally developed modules will generally be admissible as long as -->
<!-- their license permits academic use. We will however only be able to -->
<!-- package modules as part of the platform that permit redistribution; -->
<!-- other modules will have to be installed separately by the end -->
<!-- users. </para> -->
<!-- <para> -->
<!-- Which license the open-source platform itself will be released under -->
<!-- is still undecided. -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem><para>Industrial Systems. We will need to adopt a more -->
<!-- restricted policy for the use of EXCITEMENT in the industrial -->
<!-- systems. Only software that permits commercial use is -->
<!-- admissible. Major licenses that meet this requirement are the Apache -->
<!-- license; the BSD license; CC licenses that are not part of the NC -->
<!-- family; the MIT license. The GPL is presumably unsuitable since it -->
<!-- requires distribution of the complete system under the GPL. Under the -->
<!-- assumption that the resulting systems will be used only in-house at -->
<!-- the industrial partners, at least for the time being, the question of -->
<!-- whether redistribution is permissible does not arise here. -->
<!-- </para> -->
<!-- </listitem> -->
<!-- </orderedlist> -->
<!-- </para> -->
<!-- </section> -->

</section> <!-- end of section ELEMENTS of EXCITEMENT platform -->

<section>
<title>Linguistic Analysis Pipeline (LAP) </title>
<para> This section describes the specification (interfaces and
exchange data structure) of the Linguistic Analysis Pipeline.
</para> 

<section>
<title>Requirements</title>
<para>
This subsection describes the requirements for two aspects of the LAP:
First, the user interface of the LAP. Second, the type (i.e., data
structure) that is used to exchange data between the LAP and the
Entailment Core.
</para>

<section>
<title>Requirements for the linguistic analysis pipeline</title>

<itemizedlist>
<listitem><para><emphasis>Separation between LAP and entailment
core.</emphasis> (This is a global requirement.) </para></listitem>
<listitem><para><emphasis>Language independence.</emphasis> The
pipeline should not be tied to properties of individual
languages.</para></listitem>
<listitem><para><emphasis>"One-click analysis".</emphasis> The
pipeline should be easy to use, ideally runnable with one command or
click.</para></listitem>
<listitem><para><emphasis>Customizability.</emphasis> The pipeline
should be easily extensible with new modules.</para></listitem>
<listitem><para><emphasis>Easy configuration.</emphasis> The pipeline
should be easy to (re)configure.</para></listitem>
</itemizedlist>

</section>

<section>
<title>Requirements for the interface between LAP and entailment core</title>
<itemizedlist>
<listitem><para><emphasis>Language independence.</emphasis> The data
structure should be able to accommodate analyses of individual languages.</para></listitem>
<listitem><para><emphasis>Linguistic formalism independence.</emphasis> The data
structure should be independent of specific linguistic theories and
formalisms.</para></listitem>
<listitem><para><emphasis>Extensible multi-level
representation.</emphasis> The data structure should be extensible
with new linguistic information when the LAP is extended with new
modules.</para></listitem>
<listitem><para><emphasis>Support for in-memory and on-disk
storage.</emphasis> The data structure should be serializable so that
LAP and Entailment Core can be run independently of one another.</para></listitem>
<listitem><para><emphasis>Metadata support.</emphasis> The data
structure should encode metadata that specify (a) the language of the
input data and (b) the levels and type of linguistic analysis so that
the Entailment Core can ensure that the input meets the requirements
of the current Engine configuration.</para></listitem>
</itemizedlist>
</section>

<section id="sec-3.1.3">
<title>A rejected option: CoNLL</title>
<para>
An option which we initially considered was the CoNLL shared task
tabular format (<ulink
url="http://ufal.mff.cuni.cz/conll2009-st/task-description.html">http://ufal.mff.cuni.cz/conll2009-st/task-description.html</ulink>). We
rejected this possibility because it could not meet several of our
requirements. (1), it does not specify a pipeline, just an interchange
format. (2), it is extensible but at the same time fairly brittle and
unwieldy for more complex annotations (cf. the handling of semantic
roles in CoNLL 2009 which requires a flexible number of columns). (3),
it only specifies an on-disk file format but no in-memory data
structure. (4), no support for metadata.
</para>
</section>

</section>


<section id="sec-3.2">
<title>UIMA as linguistic analysis pipeline of EXCITEMENT</title>
<section>
<title>UIMA</title>
<para><link linkend="ref-Apache_UIMA">UIMA</link> (Unstructured
Information Management Applications) is a framework that started as a
common platform for IBM NLP components. It evolved into a
well-developed unstructured information processing platform, which is
now supported by Apache Foundation as an open source framework. It has
been used by many well known NLP projects and has healthy communities
in both academic and commercial domain.
</para>

<para>
UIMA provides a unified way of accessing linguistic analysis
components and their analysis results. All analysis modules are
standardized into UIMA components. UIMA components shares a predefined
way of accessing input, output, configuration data, etc. Within
UIMA, it is easy to setting up a composition of analysis components to
provide new pipelines, or adopt a newly developed analysis module to
 already existing pipelines.     
</para>

<para>
On the top level, the unification of UIMA components is achieved on
two levels. </para>
<orderedlist>
<listitem>
<para>
The first is unification of components
behavior. Instead of providing different APIs for each analysis
module, UIMA components all shares a set of common methods. Also,
calling and accessing of a component is done by the UIMA framework,
not by user level code. 
<!-- Each component has its code with an XML file, which describes the
capability of the component in a standard language. -->
Users of a component do not directly call the component. Instead, they 
<!-- point the 
XML description of the component, and 
--> 
request the UIMA framework to run the component and return the analysis
result. The framework then calls the component with predefined access
methods contracted among UIMA components.  This common behavior
makes it possible to treat every component as pluggable modules, and
enables the users to establish two or more components to work
together. 
</para> 
</listitem>
<listitem>
<para>
The second unification is done with common data representation. If the
inputs and outputs of each component are not compatible, then the
unification of components' behaviors is not really meaningful. In
UIMA, the compatibility of input and output is provided by the Common
Analysis Structure (CAS) <biblioref linkend="UIMA_CAS_ref"/>.  One can
see CAS as a data container, which holds original texts with various
layers of analysis results that annotates the original text. As a CAS
is passed through analysis engines, additional annotation layers are
stacked into the CAS. Input and output of every components are
standardized in terms of the CAS. Every component works on the CAS as
the input, and adds something to the CAS as output. Thus, within UIMA,
each components capabilities can be described in terms of CAS; what it
needs in the CAS to operate (for example, a parser might need the
result of a POS tagging step), and what it will add on the CAS after
the processing (like a dependency parse tree).
</para>

<para>
CAS itself is a container. The actual content (analysis result) is
defined by the CAS type systems. UIMA provides a generic type system
that is strong enough to describe various annotation layers (like POS
tagging, parsing, coreference resolution, etc). Definition and usage
of common type system is one important aspect of using CAS. The UIMA
framework itself only provides a handful of default types like
strings, and double values. Additional types must be proposed or
adopted for actual systems; we can however cover most of our
requirements with existing type systems.
</para>
</listitem>
</orderedlist>
</section>

<section id="sec-3.3.2">
<title>The EXCITEMENT linguistic analysis pipeline</title>
<para>The following figure shows the Apache UIMA Java implementation as
the LAP of EXCITEMENT. It provides a unified way
of calling linguistic analysis components for user code.
</para>

<figure id="LAP_overview">
<title>UIMA as the linguistic analysis pipeline  of EXCITEMENT </title> 
<mediaobject>
<imageobject>
<imagedata fileref="./figures/UIMA_as_LAP.jpg" scalefit="1" width="90%"
	   align="center"/> 
</imageobject>
</mediaobject>
</figure> 

<para>
UIMA comes with various components and tools. However, in this
specification, we will only review the components that an EDA
developer should provide to the EXCITEMENT LAP as UIMA
components. They are also the components that EXCITEMENT top level
users can access from the linguistic analysis pipeline. <xref
linkend="LAP_overview"/> shows them.  We first provide generic
definition of AE, AAE and collection processing. Then we will state
what EDA implementers should provide to realize an EXCITEMENT LAP. 
</para>

<para>
<emphasis role="bold">AE</emphasis>. Analysis modules of UIMA are called as
Analysis Engines (AEs). For example, individual analysis components
like POS tagger, parser, NER annotators are AEs. All AEs share a set
of contracted methods, and they will be accessed by the UIMA
framework. All analysis results of an AE are returned to the caller as
added layers on a CAS. 
<!-- Each AE has two
parts: definitions (the capability of the component, as an XML file)
and actual code (Java, or C++ binaries). User code can utilize an AE
by pointing the definition file and call UIMA framework. -->
</para>

<para>
<emphasis role="bold">AAE</emphasis>. UIMA also provides analysis
pipelines that are called Aggregated Analysis Engines (AAEs). An AAE
is defined by composing multiple AEs. For example, a pipeline that
outputs parsing results can be composed by subsequent calls of a
sentence splitter AE, a POS tagger AE, and a parser AE. UIMA provides
a standard way to compose analysis pipelines without changing anything
on the individual analyzers.
</para>

<para>
<emphasis role="bold">Collection Processing (and UIMA
Runtime)</emphasis>.  A linguistic analysis pipeline often needs to
work on a collection of documents and produce a set of enriched
documents. For example, a user might want to optimize parameters of a
TE system with repeated experiments on the same dataset. In this case,
repeating the same linguistic preprocessing would be redundant. AAEs
do not provide any capability for accessing files or processing
collections. It is the responsibility of the AAEs caller to recognize
such cases and avoid redundant calls. To guarantee that this happens
in a uniform manner, UIMA provides the concepts of <emphasis>UIMA
runtime</emphasis> and <emphasis>collection reader</emphasis>.</para>

<para> 
A <emphasis>collection reader</emphasis> is a UIMA component that is
specialized in data reading and CAS generation. Compared to an AE, it
shares a different set of contractual methods. A collection reader
reads an input (document) and generates a CAS that can be processed
by AEs.
</para> 

<para> 
A <emphasis>UIMA runtime</emphasis> is a runner mechanism that enables
running of AEs. 
If a user calls an AE directly (via the framework), the component is
actually running in the caller's space (same process, thread). In this
case, running AEs on multiple files would still be the caller's
responsibility. A UIMA runtime is designed to take over 
that responsibility. A runtime is capable of iterating over a set of
documents in its own space. Apache UIMA and the UIMA community provide
various runtimes, from simple single thread runtime to asynchronous
distributed runtimes. Examples for UIMA runtimes are UIMA CPE/CPM
(collection processing engine / collection processing manager), UIMA
AS (Asynchronous scale-out), UIMAfit simple pipeline, and the UIMAfit
hadoop runtime.
</para>

<para>
The LAPs of EXCITEMENT exist primarily for processing textual
entailment data. As a secondary goal, the LAPs need to provide
linguistic analysis capabilities for the user level code and the
transduction layer. With these goals in mind, it is possible to
formulate more focused requirements for EXCITEMENT LAP components. An
EXCITEMENT LAP should provide the following capabilities:
</para>

<itemizedlist>
<listitem>
<para>Calling individual analysis components: A single AE represents an
individual linguistic analysis component, like tagger, tokenizer, or
parser. The user code can call an AE, or a set of AEs to utilize
the analysis capability provided by each component. 
</para>
<!-- [Gil] Commented this paragraph, since it is a bit too specific to
appear in this section. -->
<!-- <para>In terms of efficiency considerations, providing linguistic -->
<!-- analysis components as <emphasis>individual</emphasis> AEs can  -->
<!-- enhance LAP performance in some special cases. For example, assume -->
<!-- that an EDA needs POS tagging and NER, and that a user must run POS -->
<!-- tagging on his data prior to preprocessing (e.g., to detect hypothesis -->
<!-- candidates, running in the transduction layer). The user can continue -->
<!-- the analysis pipeline for the EDA if and only if the pipeline consists -->
<!-- of individual AEs. If no individual AEs are available, the whole LAP -->
<!-- has to be re-run.  -->
<!-- </para> -->
</listitem>
<listitem>
<para>Calling a prepared pipeline: A specific EDA needs a specific
level of analysis. For example, one EDA might need "tokenizer - POS
tagger" analysis sequence, and another EDA might need "tokenizer - POS
tagger - parser - NER" sequence. UIMA AAE can provides this specific
analysis sequence that is optimized for a specific EDA. Note that AAEs
do not (and should not) know about the concepts of Text and
Hypothesis. AEs and AAEs treat given CAS (or CAS view) as plain
running text, and simply process a sequence of analysis.
</para> 
</listitem>
<!-- <listitem> -->
<!-- <para>Calling prepared pipelines for EDAs: User code can utilize the -->
<!-- AAE pipelines to generate inputs to EDAs. Thus, these pipelines must -->
<!-- know how to extract information about text and hypothesis spans from -->
<!-- the input files. They must output CAS structure according to the -->
<!-- EXCITEMENT type system (cf. <xref linkend="TETypes"/>). -->
<!-- </para> -->
<!-- </listitem> -->
<listitem>
<para>
Calling a collection processing for EDAs: The EDA interface requires a
CAS that is prepared for EDAs. This will include types and
views specially designed to represent textual entailment problems. AEs
and AAEs do not know about TE-related types or setups.  Such
entailment specific types are prepared by a "collection
processor". The flow of a collection processor starts with a
"collection reader". A collection reader reads one (or more) textual
entailment problem input (like RTE data), and generates a UIMA CAS
with views and types defined for entailment problems. Then, the
collection processor calls one configured AAE for each view. For
example, if the processor calls an AAE prepared for some EDA (say
EDA-A), the CAS is now ready to be processed by "EDA-A". If the views
are processed by an AAE prepared for "EDA-B", the resulting CAS (or
CASes) is prepared for "EDA-B". </para>    
<!-- <para> -->
<!-- Note that the name can be misleading. A "collection reader" can -->
<!-- process multiple files (thus, a collection), but it can also process a -->
<!-- single input, like java String input of an entailment problem. We will -->
<!-- need different readers for different types of inputs. It is expected -->
<!-- that EXCITEMENT LAPs will share a common set of collection readers.    -->
<!-- </para>  -->
</listitem>
</itemizedlist>
</section>


<section id="LAP-conformance">
<title>Adoption of UIMA in EXCITEMENT</title>

<para>
At the time of writing of this specification (V1.0), the EXCITEMENT
consortium has made the following decision regarding the adoption of
UIMA within the linguistic analysis pipeline:
</para>
<itemizedlist>
<listitem>
<para>We will definitely adopt the UIMA type system.</para>
</listitem>
<listitem>
<para>Given the existence of working pipelines that form part of the
three existing systems, we do not immediately adopt a stance with
regard to the adoption of the UIMA runtime system. The minimal level
of interoperability that these pipelines must provide at the moment is
that they conform to the LAP input (<xref linkend="sec-5.2"/>) and output
(CAS) specifications. 
 </para> </listitem>
<listitem>
<para>For the future (2013/14), we see a number of graded options
regarding UIMA adoption:
</para>
<itemizedlist>
<listitem>
<para>Status quo (minimal interoperability)</para>
</listitem>
<listitem>
<para>Wrapping of pipelines into AAEs (basic use of UIMA runtime)</para>
</listitem>
<listitem>
<para>Decomposition of pipelines into AEs (advanced use of UIMA runtime)</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>The choice among these future strategies will be taken when
consortium partners have had more practical experience in working with
UIMA. </para>
</listitem>
</itemizedlist>

<para>More formally, the following requirements fall out of these
decisions:</para>
<itemizedlist>
<listitem>
<para>All pipeline implementations <emphasis
role="bold">must</emphasis> utilize the common type system. The common
type system is described in <xref linkend="TypeSystem"/>.  The EDA
implementer <emphasis role="bold">may</emphasis> extend the
type system to meet particular information needs. This is discussed in
<xref linkend="sec-3.3.3"/>.
</para>
</listitem>
<listitem>
<para>The implementer <emphasis role="bold">must</emphasis> provide 
linguistic pipelines that can process T-H pairs and generate
proper CAS structures, by implementing a specific interface. The
interface is defined in <xref linkend="lap_interfaces"/>.  
</para>
</listitem>
<!-- <listitem> -->
<!-- <para>It is <emphasis role="bold">recommended</emphasis> that the -->
<!-- implementer provides the ability to pre-process a set of documents and -->
<!-- produce a set of properly serialized CAS structures that can be -->
<!-- consumed by the EDA. This capability can be easily provided by -->
<!-- implement This is specified in <xref linkend="FileOut"/>. -->
<!-- </para> -->
<!-- </listitem> -->

<!-- <listitem> -->
<!-- <para>The implementer <emphasis role="bold">can</emphasis> provide -->
<!-- individual linguistic analysis components as individual AEs. This is -->
<!-- specified in <xref linkend="AEs"/>. In some cases, providing -->
<!-- individual engine might not be desirable. Treatment of such cases are -->
<!-- described in subsection <xref linkend="alternativeAAE"/>. -->
<!-- </para> -->
<!-- </listitem> -->
</itemizedlist>
<para>
This specification provides no further information on UIMA. Please
consult external UIMA documentation such as <biblioref
linkend="ref-Apache_UIMA_DOC"/> to learn more about the UIMA framework
and on how to build UIMA components.
</para>
</section>
</section>

<section id="TypeSystem">
<title>Type Systems</title>
<para>The annotation layers of a CAS are represented in terms of UIMA
types. To ensure the compatibility of components and their consumers,
it is vital to have a common type system. UIMA community already has
well developed type systems that cover generic NLP tools. Two notable
systems are DKPro <biblioref linkend="DKPRO"/> and ClearTK <biblioref
linkend="CLEARTK"/>. They cover almost all domains of common NLP
tools, including dependency and constituent parsing, POS tagging, NER,
coreference resolution, etc. Their type systems are also fairly
language-independent. For example, the POS tags of DKPro have been
used for taggers of Russian, English, French, and German, and its
parse annotations have been used in Spanish, German, and English
parsers.
</para>

<para>
Types needed for EXCITEMENT will be defined based on the existing
types of the UIMA community. For generic linguistic analysis results,
we adopt many types from DKPro. The UIMA types of DKPro components
have been used in many applications, and they are relatively well
matured types. We also add a few new types that were absent in
DKPro, like temporal annotations and semantic role labels. The adopted
and proposed UIMA types for generic linguistic analysis are described
in <xref linkend="genericTypes"/>, and their type listings are
included in <xref linkend="genericTypesXML"/>.    
</para>

<para>
This specification also defines some UIMA types that are designed to
represent textual entailment problems and related annotations. They
are including text and hypothesis marking, predicate truth annotation, 
event annotation, etc. They are described in <xref
linkend="TETypes"/>, and their actual type definitions are included in
<xref linkend="TETypesXML"/>.  
</para>

<para>
Once a type is defined and used in implementations, the cost of
changing to another type system is prohibitive. Therefore, the choice
of types is a serious decision. At the same time, the type system has
to allow for a certain amount of flexibility. First, it needs to
permit users to extend it without impacting other components that use
already existing types. It even permits old components that are not
aware of new types to work with the data annotated with components
that work with extended types (see <xref
linkend="sec-3.3.3"/>). Second, types are generally evolving with the
community. In this sense, we must assume that our type system
(especially the parts defined specifically for textual entailment
problems) may face some changes driven by practical experiences with
the EXCITEMENT open platform. In contrast, we assume that the adopted
generic NLP types of DKPro constitute a relatively matured system,
since it has been around for some years.
</para>


<section id="UIMA_concepts"> 
<title>Relevant UIMA concepts: Artifact, View, SOFA</title> 

<para><emphasis>Artifact</emphasis> is a UIMA concept which describes
the raw input.  For example, a document, a web page, or a RTE test
dataset, etc, are all artifacts. For the moment, let's assume that we
have a web page as an artifact, and the goal is to provide various
analysis on the text of the web page.
</para>   
<para> The generic analysis tools (like POS tagger, parser, etc) do
not know about HTML tags of the webpage. And it is not desirable to
add such specific tag support to generic tools. In UIMA, generic tools
can be used without modifications for such cases, by adopting
<emphasis>View</emphasis>s.  For the previous example, an HTML
detagger module can generate a plain text version of the webpage. This
can be regarded as a new perspective (view) on the original data
(artifact). In UIMA this new view can be introduced into a CAS. Once
the view is introduced in the CAS, subsequent analysis like POS
tagging and parsing can process the plain text view of the web page
without knowing that it is from a webpage.
</para> 
<para>
<emphasis>Subject OF Analysis</emphasis> (SOFA) is another UIMA
concept. It is referring the data subject that is associated with
a given view. In the website example, it is the plain text version of
the web page. One view has one SOFA, and one CAS can have multiple
views. Views (and Sofas) can have names that can uniquely identify
them among a given CAS. Annotations of CAS generally have a span:
beginning position and the end positing of the annotated text. Such
spans are expressed as offset of each SOFA. Thus, annotators
(individual analysis engines) are annotating SOFAs, instead of
artifacts directly. </para>

<para>A pictorial example of CAS, views and annotations are given
after introduction of the types for textual entailments, in <xref
linkend="CAS_example"/>. </para>  
</section> 

<section>
<title>Relevant UIMA default types </title>
<para>The UIMA framework itself defines only a handful of default
types. They are including primitive types (like string, numerical
values), and basic annotation types.
</para> 
<para> 
Primitive types only represent simple values, but user-defined types
can express arbitrary data by composing primitive types, and other
types. For example, a token type might have a string (primitive type)
for lemma, another string for POS, and two numbers for starting
position and end position of the token. Within UIMA CAS, this list of
values are called as feature structures. Each feature in the feature
structure has a name and a type, thus only a specific type can be
pointed by the feature. 
</para> 
<para>UIMA type system is based on single-parent inheritance
system. Each type must have a one super-type, and it gets all features
from the super-type. 
</para> 

<para> 
The followings are non-exhaustive list of the default types that are
used in the adopted and proposed type system of the specification.   
<itemizedlist>
<listitem><para><code>uima.cas.TOP</code>: This type is the top type
of the CAS type hierarchy. All CAS types are subtypes of
<code>TOP</code>. It does not have any feature.</para></listitem>    

<listitem><para><code>uima.cas.String</code>: one of the primitive
types. By primitive types, it means that it is not part of normal type
hierarchy. Examples of other primitive types are including <code>Boolean</code>,  
<code>Integer</code>, <code>Double</code>, etc. String is represented
as java string (thus Unicode 16 bit code). </para></listitem>  
<listitem><para><code>uima.tcas.Annotation</code>: This type supports
basic text annotation ability by providing span: starting and ending of
this annotation. It has two features, <code>begin</code> and
<code>end</code>. They are <code>uima.cas.Integer</code>, and
associated with a character position of a SOFA. Most of the
annotations used in the adopted type system is a subtype of this
type. </para></listitem>
<listitem><para><code>uima.tcas.DocumentAnnotation</code>: This is a
special type that is used by the UIMA framework. It has a single feature
<code>language</code>, which is a string indicating the language of
the document in the CAS. </para></listitem>
</itemizedlist>
</para>  

<para> 
Fully detailed information on CAS, and types of default CAS can be
found in the CAS reference section of the UIMA reference document
<biblioref linkend="UIMA_CAS_ref"/>.
</para> 
</section>

<section id="genericTypes">
<title>Types for generic NLP analysis results</title>
<para>
This section outlines adopted and proposed UIMA types for generic NLP
analysis results. The full list of the types are given in the <xref
linkend="genericTypesXML"/>.   
</para>

<para>
In this section, the string <code>DKPRO</code> is used as a short-form of <code>de.tudarmstadt.ukp.dkpro.core.api</code>.  
</para>
<section>
<title>Segmentation types</title>
<para>Segmentation represents general segments of document, paragraphs, sentences and tokens. They are defined as extension of UIMA annotation types. Paragraphs and sentences are simple UIMA annotations (<code>uima.tcas.Annotation</code>) that mark begin and end. Token annotation holds additional information, including the lemma (string), stem (string) and POS (POS type). 
</para>

<para>
See <code>DKPRO.segmentation.*</code> types. 
</para>
</section>

<section>
<title>POS types</title>
<para>POS types are defined as extension of UIMA annotation type (<code>uima.tcas.Annotation</code>). It has feature of PosValue (string). This string value holds the unmapped (original) value that is generated by the POS tagger. Common POS types are defined as inherited types of this POS type. They are including PP, PR, PUNK, V, N, etc. To see all common POS types, see <code>DKPRO.lexmorpth.types.pos</code> and the inherited types (<code>DKPRO.lexmorph.types.pos.*</code>). 
</para>

<para>Note that POS types have inherited structures --- like NN and NP
are subtype of N, etc. Thus, if you access all type.N, you will 
also get all inherited annotations (like NN, NP), too. </para> 
<para>Also note that the POS type can be extended to cover other (more
detailed, or domain-specific) tagsets. See also <xref
linkend="sec-3.3.3"/>.</para>  

</section>

<section>
<title>Document Metadata</title>
<para>DocumentMetadata holds meta data of the document, including document ID and collection ID. It is a sub type of UIMA Document annotation, which holds language and encoding of the document. See <code>DKPRO.metadata.type.DocumentMetaData</code>. 
</para>
</section>

<section>
<title>Named Entity Recognition</title>
<para>Types related to NER data are defined as subtype of UIMA annotation type. It has string feature named "value" that holds output string of NER annotator. Actual entity types are mapped into subtypes that represents organizations, nationality, person, product, etc. See <code>DKPRO.ner.type.NamedEntity</code> and its sub types (<code>DKPRO.ner.type.NamedEntity.*</code>). 
</para>
</section>

<section>
<title>Constituency parse result</title>
<para>Constituency parsing results can be represented with
<code>DKPRO.syntax.type.constituent</code>. It has a set of types
related to constituency parsing. <code>constituent</code> type
represent a parse node, and holds required information such as
<code>parent</code> (single node), <code>children</code> (array), and
constituentType. <code>constituentType</code> field holds the raw data
(unmapped value) of the parser output, and the mapped value are
represented with types, such as <code>type.constituent.DT</code>,
<code>type.constituent.EX</code>, etc. See
<code>DKPRO.syntax.type.constituent.Constituent</code> and its sub
types (<code>DKPRO.syntax.type.constituent.*</code>).  
</para>
<para>
Note that the EXCITEMENT platform has adopted dependency parse trees
as its canonical representation for syntactic knowledge (as described
in <xref linkend="sec-4.6"/>). EDA implementers can use constituency
parsers and their results within their code, but constituency parse
trees cannot be used together with EXCITEMENT syntactic rule-bases,
unless they are converted to dependency parse trees.
</para> 
</section>

<section>
<title>Dependency parse result</title>
<para>Dependency parse results are represented with type <code>DKPRO.syntax.type.dependency.Dependency</code> and its subtypes. The main type has three features: <code>Governor</code> (points a <code>segmentation.type.Token</code>), <code>Dependent</code> (points a <code>segmentation.type.Token</code>), and <code>DependencyType</code> (string, holds an unmapped dependency type). Common representation of dependency parse tree are built by subtypes that inherit the type. Each subtype represents mapped dependency, like <code>type.dependency.INFMOD</code>, <code>type.dependency.IOBJ</code>, etc. To see all mapped common dependency types, see <code>DKPRO.syntax.type.dependency.*</code>.  
</para>
</section>

<section>
<title>Coreference Resolution</title>
<para>Coreferences are represented with <code>DKPRO.coref.type.CoreferenceLink</code>. It is a UIMA annotation type, and represents link between two annotations. The type holds <code>next</code> feature that points another <code>type.CoreferenceLink</code>, and a string feature that holds the <code>referenceType</code> (unmapped output). Currently it does not provide common type on coreference type. <code>CoreferenceLink</code> represent single link between nodes. They will naturally form a chain, and the start point of such chain is represented by <code>DKPRO.coref.type.CoreferenceChain</code>. 
</para>
</section>

<section>
<title>Semantic Role Labels</title>
<para>This subsection describes types related to represent semantic role labels. It consists of two types, <code>EXCITEMENT.semanticrole.Predicate</code> and <code>EXCITEMENT.semanticrole.Argument</code>. 
</para>  

<para>
<code>Predicate</code> is a <code>uima.tcas.Annotation</code>. It represents a predicate. It holds the predicate sense as string and links to its arguments (An array of <code>Argument</code>). It has the following features: 
</para>
<itemizedlist>
<listitem>
<para><code>predicateName</code> (<code>uima.cas.String</code>): This feature represents the name of this predicate. It actually refers to the sense of the predicate in PropBank or FrameNet. </para>
</listitem>
<listitem>
<para><code>arguments</code> (<code>uima.cas.FSArray</code>): This feature is an array of <code>EXCITEMENT.semanticrole.Argument</code>. It holds the predicate's arguments. </para> 
</listitem> 
</itemizedlist> 

<para>
<code>Argument</code> is a <code>uima.tcas.Annotation</code>. It represents an argument. It has two features; the argument's semantic role (type), and a backward reference to the predicate that governs the argument. They are: 
</para>
<itemizedlist>
<listitem>
<para><code>argumentName</code> (<code>uima.cas.String</code>): This
feature represents the semantic role (type) of this argument. The fact
that this feature is a String means that arbitrary role labels can be
adopted, such as the PropBank argument set (A0, A1, AM-LOC, etc.), the
FrameNet role set (Communication.Communicator, Communication.Message,
etc.), or any other. 
 </para> 
</listitem>
<listitem>
<para><code>predicates</code> (<code>uima.cas.FSArray</code>): This feature is an array of <code>EXCITEMENT.semanticrole.Predicate</code>. (Backward) references to the predicates which governs it. </para> 
</listitem> 
</itemizedlist> 

<para> Both annotations are applied to tokens (same span to tokens), and the semantic dependencies are implicitly recorded in the FSArrays. The reason to keep the FSArray for both side is that the redundancy makes the later processing easier (e.g. it is easier to find the corresponding predicates from each argument). </para> 

</section>

<section>
<title>Types for Temporal Expression</title>
<para>The temporal expression types are needed for event models, and
they are used in event-based EDAs. This section defines the related
types. One is <code>TemporalExpression</code> and the other is
<code>DefaultTimeOfText</code> and its subtypes. </para>  

<para>
<code>EXCITEMENT.temporal.DefaultTimeOfText</code> is a
<code>uima.tcas.Annotation</code>. It is anchored to a textual region
(a paragraph, or a document), and holds the "default time" that has
been determined for this passage and can be useful to interpret
relative time expressions ("now", "yesterday") in the text. It has one
feature:
</para> 
<itemizedlist>
<listitem>
<para><code>time</code> (<code>uima.cas.String</code>): This feature
holds the default time for the textual unit which is annotated by this
annotation. The time string is expressed in the normalized ISO 8601
format. More specifically, it is a concatenation of the ISO 8601
calendar date and extended time: "YYYY-MM-DD hh:mm:ss".
</para>
</listitem>
</itemizedlist> 

<para>
The second type, <code>EXCITEMENT.temporal.TemporalExpression</code>
annotates a temporal expression.  It is a
<code>uima.tcas.Annotation</code> that annotates a temporal expression
within a passage, adding a normalized time representation. It holds
two string features: One contains the original temporal expression,
and the other contains a normalized time representation, using
ISO 8601 as above. 
</para>
<itemizedlist>
<listitem>
<para><code>text</code> (<code>uima.cas.String</code>): This feature
holds the original expression appearing in the text.
</para>
</listitem>
<listitem>
<para><code>resolvedTime</code> (<code>uima.cas.String</code>): This
feature holds the resolved time in ISO 8601 format. For example,
"Yesterday", will be resolved into "2012-11-01", etc. See the type
DefaultTimeOfText for details.
</para>
</listitem>
</itemizedlist> 

<para> <code>temporal.TemporalExpression</code> has four subtypes,
which closely reflects TIMEX3 classification <biblioref
linkend="TIMEX3"/> of temporal expression. They are:
<code>temporal.Date</code>, <code>temporal.Time</code>,
<code>temporal.Duration</code>, and <code>temporal.Set</code>.  
</para>

</section>

<section>
<title>Types for Text Alignment</title>
<para> A simple annotation type is provided for text
alignment. <code>EXCITEMENT.alignment.AlignedText</code> represent an
aligned textual unit. It is a <code>uima.tcas.Annotation</code>. Its
span refers to the "source" linguistic entity. This can be a token
(word alignment), a syntax node (phrase alignments), or a sentence
(sentence alignment). It has a single feature that can point other
instances of of <code>AlignedText</code>:  
</para>
<itemizedlist>
<listitem>
<para><code>alignedTo</code>
(<code>uima.cas.FSArray</code> of type
<code>EXCITEMENT.alignment.AlignedText</code>): This feature holds
references to other <code>AlignedText</code> instances. Note that this
array can have null, one, or multiple <code>AlignedText</code>. 
</para>
</listitem>
<listitem>
<para><code>alignmentType</code> (<code>uima.cas.String</code>): This
feature gives additional information about the alignment ("type" of
the alignment) as a string. The feature can be null, if no additional
information is available. </para>  
</listitem>
</itemizedlist> 
<para>
The <code>alignedTo</code> feature is an array that can contain
multiple references, which means that it is one-to-many
alignment. Likewise, a null array can also be a valid value for this
feature, if the underlying alignment method is an asymmetric one;
empty array means that this <code>AlignedText</code> instance is a
recipient, but it does not align itself to other text.
</para> 
</section>

</section>

<section id="TETypes">
<title>Additional Types for Textual Entailment</title>
<para>This section outlines the types proposed for textual entailments
and related sub-tasks. Full listing of the mentioned types are
listed in <xref linkend="TETypesXML"/>. 
</para>
<section>
<title>Representation of Text and Hypothesis</title>

<para> 
The basic approach of the platform is to use a single CAS to represent
a single entailment problem. The CAS holds text, hypothesis and
associated linguistic analysis annotations. 
<!-- The CAS that holds the entailment problem
provides two named views. One is the <code>TextView</code> and the
other is the <code>HypothesisView</code>. The CAS output of an
analysis pipeline must provide two views with these names. -->
<!-- Each view holds all data the text and the hypothesis,
respectively. -->
</para>

<para> 
Let's first consider <xref linkend="CAS_example"/> which shows an
example of entailment problem represented in a.  It includes UIMA CAS
elements like artifact, view, and SOFA (cf. <xref
linkend="UIMA_concepts"/>). The original raw input is shown in the
figure as the artifact. It is a simple XML annotation with a T-H
pair. The artifact contains two plain-text subjects of analysis
(SOFA). Analysis tools like taggers will only see this SOFA data,
instead of the artifact XML. All annotations (all types that inherits
<code>uima.tcas.Annotation</code>) are annotated on top of the
SOFA. For example, the first <code>token</code> annotation of the text
("this") is annotated on <code>TextView</code> SOFA position 0 to
position 3. This SOFA positional span underlies the most common way of
accessing fetching UIMA text annotations, namely to retrieve, e.g.,
"all annotations of type Token from the TextView SOFA span 0 - 14".</para>

<para> 
Each view has exactly one SOFA.  <!-- The term "View" and "SOFA of a
View" are often used interchangingly, although SOFA only means the
data, while view implies SOFA and the annotations associated with the
SOFA.  --> In this example, each view is enriched by token annotations
and POS annotations. Both token and POS are annotation types, and have
<code>begin</code> and <code>end</code> fields, which shows the span
of the annotation. (POS types also have begin and end span.  They are
omitted here for clarity.)
</para>

<figure id="CAS_example">
<title>Example of an entailment problem in CAS</title> 
<mediaobject>
<imageobject>
<imagedata fileref="./figures/cas_example.jpg" scalefit="1" width="80%"
	   align="center"/> 
</imageobject>
</mediaobject>
</figure> 

<para> 
The figure also shows a set of entailment specific annotation types:
they are <code>entailment.Pair</code>, <code>entailment.Text</code>,
<code>entailment.Hypothesis</code>, and
<code>entailment.EntailmentMetadata</code>. 
The example has  a single <code>entailment.Pair</code>, which points 
<code>entailment.Text</code> and
<code>entailment.Hypothesis</code>. The <code>Pair</code> has an ID,
and it also has a <code>goldAnswer</code>. The CAS has no additional
pair, and the entailment problem described in this example is a single
T-H pair.  There is one <code>entailment.EntailmentMetadata</code> in
this CAS. It shows that the language of the two views is "EN" (English
as defined in <biblioref linkend="langid"/>), and the task is "QA". It
also has a string for <code>channel</code> value as "email".   </para>  
<para>
The following subsections define the annotations in detail. 
</para> 

<section id="entailment.EntailmentMetadata">
<title>Type <code>entailment.EntailmentMetadata</code></title>
<para>
<code>EXCITEMENT.entailment.EntailmentMetadata</code> provides
metadata for each entailment problem. It is an extension of
<code>uima.cas.TOP</code>. An instance of this type should be indexed
directly on the CAS (not on <code>TextView</code> or
<code>HypothesisView</code>).  
</para>
<itemizedlist>
<listitem>
<para><code>language (uima.cas.String)</code>: this string represents
the language of the CAS and its entailment problem. It holds two
character language identifier, as defined in <biblioref
linkend="langid"/>).  
</para>
</listitem>
<listitem>
<para><code>task (uima.cas.String)</code>: this string holds task
description which can be observed in the RTE challenge data.  
</para>
</listitem>
<listitem>
<para><code>channel (uima.cas.String)</code>: this metadata field
can holds a string that shows the channel where this problem was
originated. For example, "customer e-mail", "online forum", 
or "automatic transcription", "manual transcription", etc. 
</para>
</listitem>
<listitem>
<para><code>origin (uima.cas.String)</code>: this metadata field
can hold a string that shows the origin of this text and hypothesis. A
company name, or a product name. 
</para>
</listitem>

<listitem>
<para><code>TextDocumentID (uima.cas.String)</code>: This field can hold
a string that identifies the document of the
<code>TextView</code>. This feature must have a value, if
<code>TextCollectionID</code> is not null. 
</para>
</listitem>
 
<listitem>
<para><code>TextCollectionID (uima.cas.String)</code>: This field can
hold a string that identifies the collection name where the document
of the <code>TextView</code> belongs to. 
</para>
</listitem>

<listitem>
<para><code>HypothesisDocumentID (uima.cas.String)</code>: This field can hold
a string that identifies the document of the
<code>HypothesisView</code>. This feature must have a value, if
<code>HypothesisCollectionID</code> is not null. 
</para>
</listitem>

<listitem>
<para><code>HypothesisCollectionID (uima.cas.String)</code>: This field can
hold a string that identifies the collection name where the document
of the <code>HypothesisView</code> belongs to. 
</para>
</listitem>
</itemizedlist>
<para>
The values of these fields are unrestricted Strings. Pipeline users
are responsible for documenting the semantics of the values if they
want to ensure interoperability.
</para>
</section> 

<section>
<title>Type <code>entailment.Pair</code> </title>
<para> Text-Hypothesis pairs are represented by the type <code>
EXCITEMENT.entailment.Pair</code>. The type is a subtype of
<code>uima.cas.TOP</code>.  An instance of <code>Pair</code> should be
indexed directly on the CAS (not on <code>TextView</code> or
<code>HypothesisView</code>). If the CAS represents multiple text
and/or hypothesis, the CAS will holds multiple <code>Pair</code> 
instances.
</para> 

<para> 
The type has following features:
<itemizedlist>
<listitem>
<para><code>pairID (uima.cas.String)</code>: ID of this pair. The main
purpose of this value is to distinguish a certain pair among multiple
pairs. 
</para>
</listitem>
<listitem>
<para><code>text (EXCITEMENT.entailment.Text)</code>: this features
points the text part of this pair. 
</para>
</listitem>
<listitem>
<para><code>hypothesis (EXCITEMENT.entailment.Hypothesis)</code>: this
features points the hypothesis part of this pair. 
</para>
</listitem>
<listitem>
<para><code>goldAnswer (EXCITEMENT.entailment.Decision)</code>: this
features records the gold standard answer for this pair. If the pair
(and CAS) represents a training data, this value will be filled in with
the gold standard answer. If it is a null value, the pair represents a
entailment problem that is yet to be answered.  
</para>
</listitem>
</itemizedlist>
</para> 
</section> 

<section id="section_text_hyp_annotation">
<title><code>entailment.Text</code>,
<code>entailment.Hypothesis</code> and
<code>entailment.Decision</code> </title>
<para><code>EXCITEMENT.entailment.Text</code> is an annotation
(extending <code>uima.tcas.Annotation</code>) that annotates a text
item within the <code>TextView</code>.  It can occur multiple times
(for multi-text problems). It does not have any features. A
<code>Text</code> instance is always referred to by a
<code>Pair</code> instance. 
</para>
<para>
Note that <code>Text</code> annotations and <code>TextView</code> are
two different concepts. A <code>TextView</code> is a container that
contains a SOFA plus all of its annotations, including
<code>entailment.Text</code> 
Thus, the fact that a sentence forms part of a <code>TextView</code>
does not automatically mean that it is compared to a hypothesis. This
only happens if it is annotated with <code>entailment.Text</code> and
linked with <code>entailment.Pair</code>.
</para>
<para>The situation is similar for
<code>EXCITEMENT.entailment.Hypothesis</code>. It is also an
annotation (<code>uima.tcas.Annotation</code>) that annotates a
hypothesis item within the <code>HypothesisView</code>. It can occur
multiple times (in multiple-hypothesis cases). It does not have any
features either. A <code>Hypothesis</code> instance is always referred
to by a <code>Pair</code> instance. <code>Hypothesis</code>
annotations and <code>HypothesisView</code> are different entities,
and sentences are only compared to a specific text annotation when
they are annotated with <code>entailment.Hypothesis</code>, like for
texts. </para>

<para>The EDA <code>process</code> interface receives CAS data as a
JCas object (the UIMA-created Java type hierarchy corresponding to the
UIMA CAS types). CASes that feed into the EDA <code>process</code>
interface must have at least a single <code>entailment.Pair</code>.
Naturally, each view (<code>TextView</code> and
<code>HypothesisView</code>) must have at least one
<code>entailment.Text</code> and <code>entailment.Hypothesis</code>.
Multiple text and multiple hypothesis cases will be represented by
multiple number of <code>entailment.Pair</code>. Note that the
relationship between pairs on one side and texts and hypotheses is not
a one-to-one relationship. Several pairs can point the same
hypothesis, or to the same text.  For example, if one hypothesis is
paired with several potential texts, there will be multiple pairs. All
pairs will point to the same hypothesis, but to different texts.
</para>

<para><code>EXCITEMENT.entailment.Decision</code> represents the
entailment decision. It is a string subtype, which is a string
(<code>uima.tcas.String</code>) that is only permitted with predefined
values. <code>entailment.Decision</code> type can only haves one of
"ENTAILMENT", "NONENTAILMENT", "PARAPHRASE", "CONTRADICTION", and
"UNKNOWN" (The type can be further expanded in the future). This UIMA
type has a corresponding Java enum type within the entailment core
(see <xref linkend="sec-4.2.1.6"/>). 
</para> 
</section> 

</section> <!-- end of "representation of text and hypothesis --> 

<section>
<title>Generalization to multiple pairs</title>
<para>
<xref linkend="CAS_example2"/> shows another example of a CAS with
entailment types. In this figure, the CAS has multiple pairs. The
TextView holds a document with six sentences. All six sentences are
annotated by sentence splitter, and additional analyzers (for clarity,
only sentence annotations are shown). Among the analyzed sentences,
the <code>entailment.Text</code> annotations are marked on the first,
third and sixth sentences. The HypothesisView holds only a single
sentence, which is the single Hypothesis annotation. The CAS holds
three pairs, and it is a multiple text entailment decision problem. In
the figure, linguistic analysis annotations other than sentences are
omitted for clarity. The sentences that are not annotated with a
<code>Text</code> annotation can be regarded as context for the
annotated texts. For example, co-reference resolutions will take
benefits from the sentences. Also, components like distance
calculation components, or text rewriting components can use the
tokens in the context sentences to get better results. (Note that
generic components like tokenizer, parser, and co-reference resolver,
do not aware of entailment specific annotations, and process all
data in the given view. "Generic" verses "TE specific" LAP component
is described in the next subsection <xref linkend="two_groups_LAP"/>.) 
</para> 

<figure id="CAS_example2">
<title>Example of an entailment problem with multiple pairs</title> 
<mediaobject>
<imageobject>
<imagedata fileref="./figures/cas_example2.jpg" scalefit="1" width="80%"
	   align="center"/> 
</imageobject>
</mediaobject>
</figure> 

<para> Note that EDAs will only decide entailment of pairs that are
explicitly marked with <code>Pair</code> annotations. Existence of
text or hypothesis annotation does not automatically lead to
processing in an EDA. For example, if the pair-2 is missing from the
figure, the <code>Text</code> annotated on sentence-3 will not be
compared to the hypothesis sentence. Also note that nothing stops us
from annotating a text item that overlaps with other text items. For
example, it would be a legal annotation if we add a new text item that
covers from sentence-2 to sentence-4 (which will include the text of
pair-1).
</para> 
</section>

<section id="two_groups_LAP">
<title>Two groups of LAP components</title>
<!--<para>
The overall structure of CAS that holds the entailment problem is now 
declared in the previous subsection. This subsection defines two major
groups of LAP components with regard to the structure. 
</para>-->

<para>
All EXCITEMENT LAP components can be divided into two groups:
</para>
<itemizedlist>
<listitem>
<para><emphasis>generic analysis components</emphasis>
</para>
</listitem>
<listitem>
<para><emphasis>TE specific components</emphasis>
</para>
</listitem>
</itemizedlist>
<para>
The most important difference between the two groups is awareness of
the two views (the <code>TextView</code> and the
<code>HypothesisView</code> as introduced in <xref
linkend="section_text_hyp_annotation" />). Only the second group knows
about the views, and also the entailment specific annotations (like
<code>entailment.Metadata</code>). General LAP components (like
taggers and parsers) only process a view. Keeping generic analysis
tools as single view annotators is intentional and well-established
UIMA practice. It enables the tools as generic as possible. In our
case, user level or transduction layer can call analysis components
not only on TE problems, but also on any textual data.
</para>

<para>
Pipelines with two (or more) views use generic AEs to annotate one of
its views. If a pipeline needs to annotate all of its views, it needs
to call the generic LAP component multiple times.  For instance, a
typical pipeline that produce a CAS for a EDA looks like this:
</para>
<orderedlist>
<listitem>
<para>collectionReader reads a TE problem from the text format (like that
   of <xref linkend="sec-5.2"/> )
</para>
</listitem>
<listitem>
<para>collectionReader generates a CAS with two views, 
   entailment.metadata, and entailment.pair. 
</para>
</listitem>
<listitem>
<para>runtime calls a generic AE (or AAE) on the Text View (for example,
   a Tagger+Parser AE/AAE) 
</para>
</listitem>
<listitem>
<para>runtime calls a generic AE (or AAE) on the Hypothesis View (same
   Tagger+Parser AE/AAE)  
</para>
</listitem>
<listitem>
<para>runtime calls a TE specific AE on the CAS (e.g. a TE-specific
   alignment annotator) 
</para>
</listitem>
<listitem>
<para>the CAS is ready and passed to the entailment core. 
</para>
</listitem>
</orderedlist>
<para>
Note that generic analysis annotators are called twice for once on
TextView and once on HypothesisView (step 3 and 4), while TE-specific
tool (step 5) is called only once. 
Also note that this is only one example, and a whole set
of different processing pipelines can be designed. For example, to
process a big set of short texts, we can imagine a pipeline that first
call taggers for all problems as a single document and then generate
multiple CASes for efficiency reasons, etc. 
</para>
</section>


<section>
<title>Other cases: T-H from multiple documents, T-H on a same document</title>
<para>
<!-- Gil: new section added, as previous subsection --> 
<!-- [SP: I must admit I don't find this subsection easy to follow yet. Do -->
<!-- we describe somewhere that AEs receive (the content of) T and H views -->
<!-- as input?  I didn't find it in 3.2 or 3.3 or 3.4. I think this needs -->
<!-- to be said clearly at an obivous place, it's an important bit of -->
<!-- information. ] -->
</para>

<para>Ordinary annotators (taggers, parsers, etc) do not (and should
not) know about the views of <code>TextView</code> and
<code>HypothesisView</code>. They only see one view at a time, its
SOFA as a single document. Thus the two views of T and H naturally
represent two separate documents, one for text and one for hypothesis.   
<!-- Gil: explained with an e-mail --> 
<!-- [SP. What I -->
<!-- do not understand: if annotators only see H views and T views, then -->
<!-- sentences that are not part of either (like Sent4, Sent 5 in Fig 5) -->
<!-- are never annotated..? What am I missing? ] -->
</para>

<para>
One problem of this setup is that we have to process other cases like:  
</para>
<itemizedlist>
<listitem>
<para>Text (or Hypothesis) from Multiple documents.
</para>
</listitem>
<listitem>
<para>Text and Hypothesis on the same document. 
</para>
</listitem>
</itemizedlist>

<para>The following subsections describe how we will represent such cases
with the proposed types and CAS. 
</para>
<section>
<title>Multiple document problem: decomposition to multiple CASes</title>
<para>Some problems involve multiple documents. Examples are the main
task of RTE6 and RTE7. They have TE problem that consists of multiple
texts (T) and a single hypothesis. The texts are scattered over a set
of documents (collection). Additionally, there are global
features associated with the document collection (e.g., topic).
</para>

<para>
We can break down this case with multiple CASes with the proposed
CAS representation. The following figure shows one artificial
example. In the figure, it has a single hypothesis and multiple
texts. The texts are located in three different documents. It is
possible to represent this problem with three CASes. 
</para>

<para>
<figure id="multidoc_multiCAS">
<title>Multiple document TE problem decomposed into multiple CASes.</title>
<mediaobject>
<imageobject>
<imagedata fileref="./figures/multidoc_multiCAS.jpg" scalefit="1" width="80%" align="center" valign="middle"/>
</imageobject>
</mediaobject>
</figure>
 
</para>

<para>
Each CAS of the decomposed one will look like <xref
linkend="CAS_example2"/>. Note that the multi document example is
decomposed into several CASes whose number corresponds to the number
of documents. Each view holds a single document in this setup, and
normal annotators can process each view just as a normal document.
</para>

<para>
<code>EXCITEMENT.entailment.EntailmentMetadata</code> holds two
additional features for multiple document cases. It has
<code>documentID</code> and <code>collectionID</code> for both text
and hypothesis. Document ID identifies the document assigned in the
view, and collection ID can show the collection where the document is
belong to. 
</para>

<para>
Note that this decomposition assumes that breaking down the multiple
document case into multiple single document problem does not change
the final output. See <xref linkend="future_TE_problem_description"/>
for more complex cases of multiple text/hypothesis. 
<!-- This might not be true, if the final output is not a
set of independent decisions, but consists for example of rankings.
For the moment (specification V1.1), we do not consider such cases,
which are beyond the scope of current RTE datasets. -->
<!-- Gil: removed duplicated part, and added a reference --> 
<!-- [SP: can this
paragraph maybe merged into 3.3.4.3.3? It looks to me like it falls
under that heading, at any rate.]-->
</para>
</section>

<section>
<title>T and H on same document : Two views hold the same document </title>
<para>Since we have two separate views for text and hypothesis, it can be
problematic when we have the text and the hypothesis from the same
document. 
</para>

<para>
In such a case, we will have two views with the same document (two
views have the same document with same analysis result). All other TE
related annotations stays normal, like metadata and entailment problem
annotation. Only document specific annotations (like tagging, parsing)
are duplicated into two views. 
</para>

<para>
Note that this "duplicated analysis result in two views" does not mean
the analysis of the document has to be done twice. We can setup a
special pipeline for single document T-H case, where it first runs
analysis and copies the result into two views. 
<!-- Gil: e-mailed, Not possible as far as I know... [SP: Is maybe a simple
general-purpose solution that analysis tools check whether the text of
any view that they want to annotate is already known to them? (Maybe
Spec 1.2)?] --> 
</para>
</section>

<section id="future_TE_problem_description">
<title>More complex problems and their use-cases </title> 
<para>Note that the above two mappings (multiple documents THs and single
TH) simplify EDA interfaces. For EDAs, all inputs look alike with two
views with <code>entailment.Pair</code> type annotations.  
However, we can imagine more complex use cases where no trivial mapping
is possible. Within the WP3 discussions, the following tasks have been
discussed for possible future support. 
</para>
<itemizedlist>
<listitem>
<para>Text expansion: Automatically generating a (large) set of additional
texts that can entail the given input text.  
</para>
</listitem>
<listitem>
<para>Dialog system: Ranking hypothesis for the given text. The goal is to
rank, instead of decision.  
</para>
</listitem>
<listitem>
<para>Hypothesis with variables: Hypothesis that includes variables, where
the variables can be replaced by parts (like words) that appears in
the text.  
</para>
</listitem>
</itemizedlist>

<para>For such cases, we will probably additional interfaces on EDA
side, also with new problem descriptions. However, this version of 
specification only deals with existing, well-known RTE problem
sets. The WP3 members have agreed that additional use-cases will only be 
discussed in a future version of the specification. 
</para>
</section>
</section>

<section>
<title>Types for Predicate Truth</title>
<para>This subsection describes types related to the representation of
predicate truth values. Predicate truth annotation is an annotation
that provides truth values for all predicates and clauses by
traversing the parse tree and taking into account implications,
presuppositions, negations, clausal embeddings, and more. See
<biblioref linkend="Amnon"/> for details. </para>

<para> We need four annotation types according to the annotations that
are needed for predicate truth annotator. They are
<code>PredicateTruth</code>, <code>ClauseTruth</code>,
<code>NegationAndUncertainty</code>, and
<code>PredicateSignature</code>. They add annotations to
tokens. <code>ClauseTruth</code> can annotate a set of consecutive
tokens, while other types only annotate a single token. </para>   

<para> 
<code>EXCITEMENT.predicatetruth.PredicateTruth</code> is a <code>uima.tcas.Annotation</code>. It represents a predicate truth value annotation. It has the following feature: 
</para>
<itemizedlist>
<listitem>
<para><code>value</code> (<code>PredicateTruthValue</code>, a string
subtype): This represents the value of the annotation. The value type
subtype of string permitting only the values <code>PT+</code>,
<code>PT-</code>, and <code>PT?</code>.
</para>
</listitem>
</itemizedlist> 

<para> 
<code>EXCITEMENT.predicatetruth.ClauseTruth</code> is a <code>uima.tcas.Annotation</code>. It represents a clause truth value annotation. Note that the <code>begin</code> and <code>end</code> of this annotation can span more than a token. It has the following feature: 
</para>
<itemizedlist>
<listitem>
<para><code>value</code> (<code>ClauseTruthValue</code>, a string subtype): This represents the value of the annotation. The value type is a subtype of string permitting only the values <code>CT+</code>, <code>CT-</code>, and <code>CT?</code>. 
</para>
</listitem>
</itemizedlist> 

<para> 
<code>EXCITEMENT.predicatetruth.NegationAndUncertainty</code> is a <code>uima.tcas.Annotation</code>. It represents a negation-and-uncertainty annotation. It has the following feature: 
</para>
<itemizedlist>
<listitem>
<para><code>value</code> (<code>NegationAndUncertaintyValue</code>, a string subtype): This represents the value of the annotation. The value type is a subtype of string permitting only the values <code>NU+</code>, <code>NU-</code>, and <code>NU?</code>. 
</para>
</listitem>
</itemizedlist> 

<para> 
<code>EXCITEMENT.predicatetruth.PredicateSignature</code> is a <code>uima.tcas.Annotation</code>. It represents an implication signature. It has the following feature: 
</para>
<itemizedlist>
<listitem>
<para><code>value</code> (<code>PredicateSignatureValue</code>, a string subtype): This represents the value of the annotation. The value type is a subtype of string permitting only the values "+/-", "+/?", "?/-", "-/+", "-/?", "?/+", "+/+", "-/-", "?/?".  
</para>
</listitem>
<listitem>
<para>The implementation uses a set of more fine grained values, that
may grow in the future. <code>PredicateSignatureValue</code> will be
extended and modified accordingly </para> 
</listitem> 
</itemizedlist> 

</section>

</section>

<section id="sec-3.3.3">
<title>Extending existing types</title>
<para>It is possible that users want to add additional information to
entailment problems. For example, task-oriented TE modules might want
to include additional information such as ranks among texts, relevance
of each hypothesis to some topics, etc. </para>

<para>
The canonical way to represent such information is to extend the
<code>entailment.Pair</code> and related types. The type and related
types (like <code>MetaData</code>, <code>Text</code> and
<code>Hypothesis</code>, etc) are presented to serve the basic need of
the EXCITEMENT platform, and additional data can be embedded into CAS
structure by extending the basic types. 
</para>

<para>
Naturally, the extension should be performed in a
<emphasis>consistent</emphasis> manner. This means that the
implementer can only define a new type that is extending the existing
types, and may not change already existing types. Also, it is
recommended that attributes and methods inherited from the existing
types should be used in the same way so that components and EDAs which
are unaware of the extensions can still can operate on the data.
</para>

<para>
The type <code>EXCITEMENT.entailment.Decision</code> is also open for
future extensions. When we define a new relation between text and
hypothesis, this type should be first extended to cover the new
relation. (This extension should always done with the extension of
internal <code>DecisionLabel</code> enumeration, see <xref
linkend="sec-4.2.1.6"/>. 
</para>

<para>
Unlike <code>EXCITEMENT</code> types, generic types (of <xref
linkend="genericTypes"/>) should in general not be extended.
Exceptional cases may arise, though, for example when an EDA utilizes
some additional information of a specific linguistic analysis tool. In
such a case, one may choose to extend generic types to define special
types (for example, defining myNN by extending NN, etc). The EDA can
then confirm the data is processed by a specific tool (like existence
of myNN) and can use the additional data that is only available in the
extended type. Other modules that do not recognize the extended types
are still able to use the super-types in the output (in the example,
myNN will map onto NN).
</para>
<!-- <para> (However, this behavior is generally not recommended. In such a -->
<!-- case, the EDA implementer should provide a correct pipeline and should -->
<!-- clearly state that it only accepts the output of the specific pipeline -->
<!-- as its input.)   -->
<!-- If a downstream analysis engine needs a specific analysis result -->
<!-- from the previous analysis step, then it should be provided with a -->
<!-- proper pipeline, instead of adding additional types. For example, if a -->
<!-- parser needs a specific POS tagging (like treetagger and its output), -->
<!-- it should be provided in a pipeline where treetagger and the parser is -->
<!-- called in sequence. And should be noted that the components should be -->
<!-- only used in the pipeline (tagger-parser) form.  -->
<!-- </para> --> 

</section>
</section>

<!-- <section> -->
<!-- <title>Providing analysis components for LAP </title>  -->

<!-- <section id="AEs"> -->
<!-- <title>Providing individual analysis engines (AEs)</title> -->

<!-- [Gil: we have a subsection talks about UIMA adoption (3.2.3) and don't -->
<!-- need this paragraph.] -->
<!-- <para> This section deals with policy issues related to UIMA AEs. -->
<!-- Providing each linguistic analysis component as an individual AE -->
<!-- grants us maximum flexibility. However, this also comes with -->
<!-- additional technical difficulties and work items. The consortium will -->
<!-- come to a decision until August 2012 on whether or not to provide -->
<!-- individual analysis components as UIMA AEs. The following section -->
<!-- reflects the current status (as of June 2012).  -->
<!-- </para>  -->

<!-- <para>It would be ideal if each linguistic analysis module (like POS -->
<!-- taggers, parsers or coreference resolvers) were provided as a generic -->
<!-- individual UIMA analysis engine (AE). With individual AEs, user code -->
<!-- would be able to call these modules as UIMA components, as described -->
<!-- in <xref linkend="sec-3.3.2"/>. -->
<!-- </para> -->

<!-- <para>It is recommended that each linguistic analysis module (like POS -->
<!-- taggers, parsers or coreference resolvers) should be provided as a -->
<!-- generic individual UIMA analysis engine (AE). Thus, user code should -->
<!-- be able to call these modules as UIMA components, as described in -->
<!-- <xref linkend="sec-3.3.2"/>. -->
<!-- </para> -->

<!-- <para>  -->
<!-- By generic, we mean they are supposed to process normal text and not -->
<!-- T/H pairs. The modules are not supposed to process or even be aware of -->
<!-- annotations related to entailment problems. This ensures their -->
<!-- reusability. The necessary specific processing for entailment data -->
<!-- (H/T markup) should be implemented within a complete pipeline, cf. the -->
<!-- following subsection. -->
<!-- </para>  -->

<!-- <para> -->
<!-- As described in <xref linkend="sec-3.3.3"/>, all analysis engines must -->
<!-- annotate the given data with the common type system. In the rare case -->
<!-- where the provided common type system is not sufficient, the -->
<!-- implementer must not modify any of the existing types and should only -->
<!-- expand existing types with an own type that inherits existing types. -->
<!-- </para> -->

<!-- <para> -->
<!-- It is recommended that the implementer should reuse existing AEs as -->
<!-- much as possible. For example, DKPro already provides many of the well -->
<!-- known NLP tools including major parsers and taggers for various -->
<!-- languages. ClearTK or OpenNLP also ships various NLP tools as UIMA -->
<!-- components. ClearTK or OpenNLP uses different type systems, thus one -->
<!-- needs to add additional glue code to map the types into adopted DKPro -->
<!-- types. However, such mappings are generally trivial and should not -->
<!-- pose large problems. -->
<!-- </para> -->

<!-- <para> -->
<!-- Note that there is more than one flavor in providing UIMA -->
<!-- components. This specification only defines types and components in -->
<!-- terms of the bare UIMA framework. Each component is supposed to have -->
<!-- its component description, and should be runnable by the UIMA -->
<!-- framework.  However, the implementers are free to utilize additional -->
<!-- tools. For example, DKPro and ClearTK both uses UIMAFit as tool layer, -->
<!-- which provides the functionalities of the UIMA framework with -->
<!-- additional tool layers. The implementer may utilize such tools, as -->
<!-- long as the end results are compatible with what are defined by this -->
<!-- specification. -->
<!-- </para> -->

<!-- <para> -->
<!-- In some cases, one may choose NOT to provide individual analysis -->
<!-- components as UIMA components. See <xref linkend="alternativeAAE"/> -->
<!-- for such a case.  -->
<!-- </para> -->
<!-- </section> -->

<!-- <section id="AAEs"> -->
<!-- <title>Providing an analysis pipeline</title> -->
<!-- <para>Individual analysis engines (AEs) are generic. They process a -->
<!-- single input (single CAS) and add some annotation layers back to CAS. -->
<!-- As mentioned above, however, EDAs require more the sum of single AE -->
<!-- annotations, namely T-H views, and T-H pair annotations.  Thus, it is -->
<!-- desirable to provide complete "pipelines" that is properly annotated -->
<!-- with types needed for textual entailment.  -->
<!-- </para> -->

<!-- <para> -->
<!-- A pipeline for EXCITEMENT EDA must process the followings:  -->
<!-- </para> -->
<!-- <itemizedlist>  -->
<!-- <listitem> -->
<!-- <para> The end result of the pipeline should generate the CAS as an -->
<!-- entailment test case, as described in <xref linkend="TETypes"/>.  </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para> It should be able to process input of formatted text that follows the -->
<!-- EXCITEMENT test data format, defined in <xref linkend="sec-5.2"/>.  </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para> All linguistic analysis annotations should follow the adopted -->
<!-- type system (of <xref linkend="genericTypes"/>), or some extension of -->
<!-- the adopted types. </para>  -->
<!-- </listitem> -->
<!-- </itemizedlist>  -->

<!-- <itemizedlist> -->
<!-- <listitem> -->
<!-- <para>It should generate T-H pairs in different views. This -->
<!-- T-H annotation must be able to process text following the common -->
<!-- EXCITEMENT test data format as defined in <xref linkend="sec-5.2"/>.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para>It needs to run single AEs and enrich the two views with analysis results. This needs mapping of multi-views (TextView, HypothesisView) to single view (InitialView) of AEs.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para>Output of the pipeline is also a CAS, that holds all required annotations to run the corresponding EDA.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- </itemizedlist> -->

<!-- <para> -->
<!-- EDA implementers <emphasis role="bold">must</emphasis> provide at -->
<!-- least a single pipeline that produces suitable input for their EDA, or -->
<!-- declare that an already existing pipeline as the suitable pipeline. If -->
<!-- the EDA supports additional input mode like multiple texts/hypotheses, -->
<!-- the implementer should provide a corresponding pipeline that produce -->
<!-- multiple text/hypothesis.  -->
<!-- </para> -->
<!-- </section> -->

<!-- <section id="FileOut"> -->
<!-- <title>Providing serialized outputs for a set of documents</title> -->
<!-- <para>Pre-processing of a set of document (collection) is often needed for -->
<!-- NLP applications. In textual entailment context, a pre-processed set -->
<!-- of training/testing data can be beneficial for various cases.  -->
<!-- </para> -->

<!-- <para> -->
<!-- EDA implementers <emphasis role="bold">should</emphasis> provide the -->
<!-- collection pre-processing capability.  -->
<!-- </para> -->
<!-- <itemizedlist> -->
<!-- <listitem> -->
<!-- <para>It must process a collection of documents stored in a path.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para> The end result for each file process must generate the CAS as -->
<!-- an entailment test case, as described in <xref -->
<!-- linkend="TETypes"/>. The CAS should be stored in a path as the XMI   -->
<!-- serialization.</para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para>Each stored CAS data must be identical to the output of the -->
<!-- corresponding pipeline.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para> It should be able to process input of formatted text that follows the -->
<!-- EXCITEMENT test data format, defined in <xref linkend="sec-5.2"/>.  </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para> All linguistic analysis annotations should follow the adopted -->
<!-- type system (of <xref linkend="genericTypes"/>), or some extension of -->
<!-- the adopted types. </para>  -->
<!-- </listitem> -->
<!-- </itemizedlist> -->

<!-- <para>Note that XMI (XML Media Interchange format) serialization is -->
<!-- the standard serialization supported by UIMA framework. It stores each -->
<!-- CAS as an XML file, and the stored files can be easily deserialized by -->
<!-- UIMA framework utilities. You can find additional information about CAS -->
<!-- serialization in <xref linkend="UIMA_ref_ser"/> </para>     -->
<!-- </section> -->

<!-- <section id="alternativeAAE"> -->
<!-- <title>An alternative: Independent pipelines with CAS output</title> -->

<!-- <para>It is recommended that individual analysis components are -->
<!-- supplied as UIMA analysis engine (AE). This will make sure those -->
<!-- analysis modules can be used by top level users in various situations, -->
<!-- as suited for the need of application programmers. -->
<!-- </para> -->

<!-- <para> -->
<!-- However, there can be situations where EDAs depend on specialized -->
<!-- analysis modules which form a pipeline that cannot easily be divided -->
<!-- into individual UIMA analysis engines. For example, assume that there -->
<!-- is a parser and a coreference resolution system that are designed to -->
<!-- work together to produce a specific output for a given EDA. Then, it -->
<!-- might not be desirable to break them into individual analysis -->
<!-- engines. In such a case, one may choose to provide only the pipeline -->
<!-- as a single analysis engine which translates the final output of the -->
<!-- pipeline into the common representation format. -->
<!-- </para> -->

<!-- <para> -->
<!-- Even in these cases, the developers should provide the pipeline as an -->
<!-- UIMA component. This will ensure that the pipeline can be called in an  -->
<!-- identical manner to normal pipelines. -->
<!-- </para> -->
<!-- </section> -->
<!-- </section> --> 

<!-- LAP interface section --> 
<section id="lap_interfaces">
<title>Linguistic Analysis Pipeline (LAP) interface</title> 

<section id="LAP-goal">
<title>The goals of the LAP interface</title>
<para>
LAP (Linguistic Analysis Pipelines) is an important part of the
platform that provides all linguistic analysis capabilities for the
EXCITEMENT platform and its users. It provides not only normal NLP
annotation capabilities like tagging and parsing, but also the
capability to generate well-formed CASes for EXCITEMENT entailment
decision algorithms (EDAs).
</para>

<para>
The purpose of this set of LAP interfaces is twofold. First, it
defines the common minimal capability that each pipeline should
provide, in terms of interface definition. Each EDA implementer must provide a
compatible pipeline for the EDA. For the developer who will provide a
new pipeline, these interfaces can serve as an implementation
guideline. 
</para>

<para>
The second purpose of the interface is to make the underlying pipeline
mechanism transparent for the end user.  As stated in the previous
sections (<xref linkend="LAP-conformance"/>), the EXCITEMENT
consortium already agreed on using UIMA CAS. However, we have not yet
come to a decision about the adoption of UIMA runtime mechanism (like
AE, AAE or CPE, etc). In the first iteration of the platform, it is
expected that some of the pipelines are composed by a set of UIMA AEs,
while other pipelines will only "translate" their pipeline output to
the UIMA CAS. </para>

<para>
In this situation, it is important to define a coherent set of
interfaces that is shared by all pipelines, regardless to the
underlying mechanism. The users should be able to call all different
pipelines with the same argument and signatures. This is more
important for users who just want to use the platform only as
"off-the-shelf TE engine". For example, knowledge of CAS or UIMA types
should not exposed to such users. Those users should be able to use
LAP pipelines for their EDA calls without knowing what CAS has within
it.
</para>

<para>
The following sections define the three set of methods that will be
shared by all pipelines.  
</para>
</section> <!-- end of subsection LAP-goal --> 


<section id="LAP-interface">
<title>Interface <code>LAPAccess</code></title>
<para>
<code>interface LAPAccess extends Components</code> 
</para>
<para>
This interface defines the minimal set of methods that a working
LAP pipeline should provide for EXCITEMENT platform. It defines three 
types of methods. One for generic annotation, one for single pair
online-generation, and one for collection processing of single-pair
input files. 
</para>

<!-- <para>
Note that this interface extends <code>interface
Components</code>. This enables an implementation of
<code>LAPAccess</code> to receive configuration data in the same way
to other core components (via <code>initialize()</code>).  
</para>
--> 

<section>
<title>method <code>generateSingleTHPairCAS</code> </title>
<itemizedlist>
<listitem>
<para><code>public JCas generateSingleTHPairCAS(String text, String
hypothesis) throws LAPException</code>   
</para>
<itemizedlist>
<listitem>

<para>Arguments: <code>text</code> holds the text string of the single
pair TE problem. <code>hypothesis</code> holds the hypothesis string of the
problem.  
</para>
</listitem>
<listitem>
<para>returns: a <code>JCas</code>, where the CAS is ready to be used as an input
for an EDA.  
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>

<para>This method gets two strings as input and generates a CAS for an
EDA. The resulting CAS must be a well-formed CAS that contains all
types can are necessary for a complete description of the entailment
problem (i.e. all types from the <code>EXCITEMENT.entailment</code> namespace),
as defined in <xref linkend="TETypes"/>. 
</para>

<para>
The amount of linguistic annotation can differ among implementations
(say, EnglishTokenizationOnly(t,h) only returns token with TE
annotations, while GermanParsingAndNER(t,h) returns tagging, parsing,
POS and NER, etc).
</para>
</section>

<section>
<title>method <code>processRawInputFormat</code></title>
<itemizedlist>
<listitem>

<para><code>public void processRawInputFormat(File inputFile, File outputDir) throws LAPException</code>
</para>
<itemizedlist>
<listitem>

<para>Arguments: <code>File inputFile</code> holds the raw input XML file. <code>File     outputDir</code> holds the output directory where the resulting CAS XMI
should be stored.  
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>

<para>This method gets two <code>File</code> as arguments. First argument is a single
input file that follows the raw input XML format (as defined in
<xref linkend="sec-5.2"/>), and the second argument
<code>outputDir</code> is the output directory. The method returns
nothing. Analysis results are stored as serialized CAS files in the
directory. (standard XMI serialization of UIMA CAS).   
</para>

<para>
Again, the generated CASes should be well-formed and must contain all
types can are necessary for a complete description of the entailment
problem (i.e. all types from the <code>EXCITEMENT.entailment</code> namespace).
</para>
</section>

<section>
<title>method <code>addAnnotationsToCAS</code> </title>
<itemizedlist>
<listitem>

<para><code>public void addAnnotationOn(JCas aJCas) throws LAPException</code>  
</para>
<itemizedlist>
<listitem>

<para>Arguments: <code>aJCas</code> holds the CAS object that will be annotated by
the analysis pipeline. 
</para>
</listitem>
<listitem>
<para>Returns: Nothing. The JCas argument is enriched by the
linguistic analysis annotations provided by the pipeline. 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>public void addAnnotationOn(JCas aJCas, String viewName) throws LAPException</code>
</para>
<itemizedlist>
<listitem>

<para>Arguments: <code>aJCas</code> holds the CAS object that will be annotated by
the analysis pipeline. This overridden method is for multi-view
CASes. <code>aJCas</code> holds two or more view, where one of them has the
view name equal to <code>viewName</code>. 
</para>
</listitem>
<listitem>
<para>Returns: Nothing. The argument JCas is enriched: one of its view
where its name is equal to <code>viewName</code> is enriched by the
linguistic analysis annotations provided by the pipeline. 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>

<para>The interface is a generic interface that can be called for adding
linguistic annotations for any data.  <code>addAnnotattionOn</code> method does
not produce CASes that are ready for EDAs. It only adds generic
language analysis results to the provided CAS. This method provides
users with the ability to analyze some text data that is not directly
a TE pair.  
</para>

<para>
The method's argument is not a string or text, but a JCas. The user
must have some knowledge on CAS to use this interface. For example,
they needs to know how to generate a new CAS and add text data to
it, before calling this method. This design is intentional. The user
needs to know about CAS data access methods beforehand, to open up and
manually access the analysis results provided by a pipeline.
Moreover, all entailment core interfaces that accept CAS as an
argument accept only the EDA-compatible CASes. That is, a specific
form and type of CASes that can be consumed by EDAs and components
(CASes with <code>EXCITEMENT.entailment.*</code> types, and with <code>TextView</code> and
<code>HypothesisViews</code>). 
</para>

<para>
Thus, the <code>addAnnotationOn</code> interface (unlike
<code>generateSingleTHPairCAS</code> or <code>processRawInputFormat</code>) produces
"generic CASes", which can be non-EDA-compatible CASes. 
The resulting CASes of <code>addAnnotationOn</code> are meant to be used mainly
by the caller himself, when they require to perform linguistic
analysis on additional data of some kind. For example, the
Transduction layer needs to use this functionality to determine which
sentence of a customer e-mail can be regarded as text or hypothesis,
respectively.
</para>

<para>
Note that <code>addAnnotationOn</code> exists in two versions: one that applies
to the single view CAS and one that applies just a specific View
within the CAS. The pipeline implementer must provide both of them; we
recommend to implement <code>addAnnotationOn(JCas)</code> simply as a call of
<code>addAnnotationOn(JCas,"_InitialView")</code> (single view CAS is a CAS with
one view, that is implicitly named as "<subscript>InivitalView</subscript>"). 
</para>

<para>
<code>addAnnotationOn</code> should not add any type that belongs to
<code>EXCITEMENT.entailment.*</code> types (types related to text, hypothesis,
pair and entailment metadata).
</para>

<para>
An <code>LAPAccess</code> implementation must provide all three sets of methods
defined in the interface.  
</para>
</section>
</section> <!-- end of subsection LAP-interface --> 

<!-- <section id="LAP-future"> -->
<!-- <title>Room for improvements with UIMA adoption</title> -->
<!-- <para>There is a room for improvement for the interface, if the consortium -->
<!-- decides to adopt UIMA Analysis Engines (AEs) as the basis for LAP -->
<!-- components. Such improvements (such as using UIMA AE, AAE, and runtime -->
<!-- to share and standardize LAP components) will be considered fully, -->
<!-- after the project members have decided UIMA adoption as scheduled in -->
<!-- <xref linkend="LAP-conformance"/>.   -->
<!-- </para> -->
<!-- </section> --> 
<!-- end of subsection LAP-future -->

</section> 
<!-- end of lap interface section -->  

</section> <!-- end of Section 3-->

<section id="sec-4">
<title>Common Interfaces of the Entailment Core </title>
<para>
This section defines the interfaces and types of the Entailment
Core. Section 4.1 provides a list of requirements and some
methodological requirements. The remaining subsections contain the
actual specification. 
</para>

<section id="sec-4.1">
<title>Requirements for the Entailment Core </title>

<section id="sec-4.1.1">
<title>Requirements for the EDA</title>
<itemizedlist>
<listitem><para><emphasis>Entailment recognition (classification
mode).</emphasis> The basic functionality that EDAs have is to take an
unlabeled text-hypothesis pair as input and return an entailment
decision.  </para></listitem>
<listitem><para><emphasis> Entailment recognition (training mode).
</emphasis> Virtually all EDAs will have a training component which
optimizes its parameters on a labeled set of text-hypothesis
pairs. </para></listitem>
<listitem><para><emphasis>Confidence output.</emphasis> EDA should be
able to express their confidence in their decision.</para></listitem>
<listitem><para><emphasis>Support for additional modes.</emphasis> The
platform should support the processing of multiple Hs for one T,
multiple Ts for one H, as well as multiple Ts and Hs.</para></listitem>
</itemizedlist>

</section>
<section id="sec-4.1.2">
<title>Requirements for the Components</title>
<itemizedlist>
<listitem><para><emphasis>A small set of reusable component
classes.</emphasis> The specification should describe a small set of
component classes that provide similar functionality and that are
sufficiently general to be reusable by a range of EDAs.
</para></listitem>
<listitem><para><emphasis>Interfaces and types for component classes.</emphasis>
The specification should specify user interfaces for these component
classes, including the types used for the exchange of
information between components and EDA.
</para></listitem>
<listitem><para><emphasis>Further extensibility.</emphasis>Users
should be able to extend the set of components beyond the standard
classes in this specification. This may however involve more
effort.</para></listitem>
</itemizedlist>
<para>To determine the set of reusable components and their
interfaces, we started from the three systems that we primarily build
on and followed a <emphasis>bottom-up generalization</emphasis>
approach to identify shared functions (components), interfaces and
types. The results are discussed in <xref
linkend="sec-4.1.3"/>. Further functionality of these components
(e.g. details of their training regimens) are not be specified but in
the scope of the component's developer</para>
</section>

<section id="sec-4.1.3">
<title>Identifying common components and interfaces </title>
<para>By following the bottom-up approach, we have identified a set of major common interfaces. The following figure shows the common components within the entailment core. 
</para>

<figure id="Entailment_Core">
<title>Common components within EXCITEMENT entailment core.</title>
<mediaobject>
<imageobject>
<imagedata fileref="./figures/ECORE-overview.jpg" scalefit="1" width="80%" align="center" valign="middle"/>
</imageobject>
</mediaobject>
</figure>

<para>
The top-level interfaces of the entailment core consist of the EDA
interface and the mode helper interface. EDAs are the access points
for entailment decision engines. They receive annotated input in the
form of CAS, and return a decision object. The EDA interface also
includes support for multiple Text and/or multiple Hypothesis
modes. The EDA interfaces are described in <xref
linkend="sec-4.2"/>. The mode helper is a wrapper tool that supports
multiple text and multiple hypothesis mode for EDAs that can only
process single T-H pairs. Its interface is described in <xref
linkend="sec-4.3"/>. 
</para>

<para>
We have identified three main classes of components that EDAs might
wish to consult. The first type is <emphasis role="bold">distance
calculation</emphasis> components. EDAs can use the semantic distance
between T-H pairs as their primary decision factor, or can use them as
features in more general decision algorithms. The interface of
distance calculation components specifies that they accept a CAS as
the input, and return an object the distance between the two views of
the CAS. The interface is described in <xref linkend="sec-4.4"/>.
</para>

<para>
The second and third component classes deal with different kinds of
linguistic knowledge, namely lexical knowledge and syntactic
knowledge. <emphasis role="bold">Lexical knowledge</emphasis>
components describe relationships between two words. Various lexical
resources are generalized into EXCITEMENT common lexical knowledge
interface. The interface is described in <xref linkend="sec-4.5"/>.
<emphasis role="bold">Syntactic knowledge</emphasis> components
contain describes entailment rules between two (typically lexicalized)
syntactic structures, like partial parse trees. For entailments, the
knowledge can be generalized into rewriting rules at partial parse
trees, where left hand sides are entailing the right hand sides.  The
common interface for syntactic knowledge is described in <xref
linkend="sec-4.6"/>.
</para>
</section>

<section id="sec-4.1.4">
<title>Using CAS or independent types in the Entailment Core?
</title>
<para>The EXCITEMENT platform uses UIMA CAS type system for the
linguistic analysis pipeline (Section 3). The UIMA types are expressive
enough to describe the relevant data structures, and can be used both
in-memory and serialized. It is thus a natural question whether CAS
types can be re-used for the communication between EDAs and
components.
</para>

<para>
Our general guideline within the Entailment Core is that the
interfaces are supposed to use UIMA CAS only when a complete text
(Text or Hypothesis, potentially with context) is exchanged as a
parameter. The reason is that even though CAS types (JCas objects) are
expressive enough to describe any data, they are basically flat
structures --- tables with references. This limits their capability to
be used efficiently. A second reason is that JCas objects only works
within CAS context. Even simple JCas objects like tokens need a
external CAS to be initialized and used. This makes it impractical to
use JCas objects and their types in interfaces that do not refer to
complete texts (which are modeled in CASes). To repeat, we use JCas
and related types only when a reference to the whole text is
exchanged. Furthermore, we only exchange references to the top-level
JCas object and never to any embedded types like views or annotation
layers.
</para>


<para>A second aspect that must be handled with care is the extension
of JCas objects. JCas provides the flexibility to extend objects while
keeping the resulting objects consistent with the original JCas types.
However, this can cause duplicated definitions when mismatches are
introduced. Moreover, CAS types will be used and shared among all
EXCITEMENT developers which makes extensions introduced by one site
problematic. For these reasons, our policy is that JCas objects
should not be extended.
</para>
</section>
</section>

<section id="sec-4.2">
<title>EDA Interface </title>
<para>
<code> public interface EDABasic&lt;T extends TEDecision&gt; </code> 
</para> 
<para>The common interface of EDA is defined through two Java
interfaces. <code>EDABasic</code> interface defines methods related to
single T-H pair process and training. <code>EDAMulti*</code>
interfaces defines additional optional interfaces for multiple text
and/or hypothesis cases.
</para>
<section id="sec-4.2.1">
<title>EDA Basic interface: interface <code>EDABasic</code> </title>
<para>This interface defines the basic capability of EDAs that all
EDAs must support. It has four methods. <code>process</code> is main
access method of textual entailment decision. It uses
<code>JCas</code> as input type, and <code>TEDecision</code> as output
type. 
<!-- The interface as Java code is listed in <xref linkend="c-1"/>. -->
</para>
<section id="sec-4.2.1.1">
<title>method <code>initialize</code></title>
<para><code>public void initialize(CommonConfig config)</code> </para> 
<para> This method will be called by the top level programs as the
signal for initializing the EDA. All initialization of an EDA like
setting up sub components and connecting resources must be done in
this method. An EDA implementation must check the configuration and
raise exceptions if the provided configuration is not compatible.
<!--  See
<xref linkend="sec-6.1"/> for complete list of exceptions that can be
raised by EDAs.  --> 
</para>

<para>
<code>initialize</code> is also responsible for passing the
configuration to common sub-components. At the initialization of core
components (like distance calculation components or knowledge resource
components), they will raise exceptions if the configuration is not
compatible with the component. <code>initialize</code> must pass
through all exceptions that occurred in the subcomponent
initialization to the top level.  
</para>

<para>
The recommended meta data checking policy for the EDA and the core
components is described in more detail in <xref
linkend="sec-4.7.1"/>.
</para> 

<para>Parameters:
</para>
<itemizedlist>
<listitem>
<para><code>config</code>: a common configuration object. This
configuration object holds platform-wide configuration. An EDA should
process the object to retrieve relevant configuration values for the
EDA. Common configuration format and its in-memory object is defined
in section <xref linkend="sec-5.1"/>. 
</para>
</listitem>
</itemizedlist>
</section>

<section id="sec-4.2.1.2">
<title>method <code>process</code> </title>
<para><code>public T process(JCas aCas)</code> </para> 
<para> This is the main access point for the top level. The top level
application can only use this method when the EDA is properly
configured and initialized (via <code>initialize()</code>).   
Each time this method is called, the EDA should check the input for
its compatibility. Within the EXCITEMENT platform, EDA implementations
are decoupled with linguistic analysis pipelines, and you cannot
blindly assume that CAS input is valid. EDA implementation must check
the existence of proper annotation layers corresponding to the
configuration of the EDA.  
</para>

<para>
The TE decision is returned as an object that extends
<code>TEDecision</code> interface which essentially holds the decision 
as enum value, numeric confidence value and additional info.  
</para>

<para>Parameters:
</para>
<itemizedlist>
<listitem>

<para><code>aCas</code>: a JCas object. Which has two named views
(TextView and HypothesisView). It has linguistic analysis
result with <code>entailment.Pair</code> as defined in <xref
linkend="TETypes"/>.   
</para>
</listitem>
</itemizedlist>
<para>Returns:
</para>
<itemizedlist>
<listitem>

<para><code>T extends TEDecision</code>: An object that extends
<code>TEDecision</code> interface. See <xref linkend="sec-4.2.1.5"/>.  
</para>
</listitem>
</itemizedlist>
</section>

<section id="sec-4.2.1.3">
<title>method <code>shutdown</code></title>
<para><code>public void shutdown()</code> </para>
<para> This method provides a graceful exit for the EDA. This method
will be called by top-level as a signal to disengage all
resources. All resources allocated by the EDA should
be released when this method is called.
</para>
</section>

<section id="sec-4.2.1.4">
<title>method <code>startTraining</code> </title>
<para><code>public void startTraining(CommonConfig c)</code>
</para>

<para>
<code>startTraining</code> interface is the common interface for EDA
training. The interface signals the start of the training with the
given configuration <code>c</code>. Note that unlike
<code>process()</code> method, <code>startTraining()</code> method
does not need previous call of <code>initialize()</code>: start
training is independent to <code>initialize()</code>. 
</para>

<para>
If the EDA is trainable, the EDA implementation should provide the
following capability: 
</para>
<itemizedlist>
<listitem>

<para>(Mandatory: Single T-H cases) It must be able to train itself on
a collection of serialized CAS files, where each CAS holds single
entailment <code>Pair</code>.
</para>
</listitem>
<listitem>
<para>(Optional: Multiple T-H cases) It may support the capability to
train on a collection of serialized CAS files, where each CAS
holds multiple entailment <code>Pair</code> annotations. 
</para>
</listitem>
<listitem>
<para>It may provide support of any additional training data type. 
</para>
</listitem>
<listitem>
<para>It should provide all relevant parameters related to the training in the common configuration. 
</para>
</listitem>
<listitem>
<para>Upon a successful training, it should result one or more model file, in a path described in the configuration. And the users should be able to use the model file(s) on future <code>process()</code> by passing the model via configuration, on <code>initialize()</code>. 
</para>
</listitem>
</itemizedlist>

<para><code>startTraining</code> and the consequent training process
should do a capability check (with the configuration), and a
compatibility check (with the training data). If there is any
incompatibility, the component should raise exceptions accordingly.
<!--  Full list of exceptions that can be raised by <code>start_training()</code> can be found in [ref]. -->
</para>
</section>

<section id="sec-4.2.1.5">
<title>interface <code>TEDecision</code> </title>
<para>This interface represents the return value for <code>process</code> interfaces. 
</para>

<para>Methods:
</para>
<itemizedlist>
<listitem>

<para><code>DecisionLabel getDecision()</code>: this method returns an object of type <code>DecisionLabel</code> as the entailment decision. 
</para>
</listitem>
<listitem>
<para><code>double getConfidence()</code>: this method returns the associated confidence value for the entailment decision. The range is [0,1], and 1 means full confidence. If the value is not meaningful for the EDA, it should return a constant number <code>CONFIDENCE_NOT_AVAILABLE</code>, which is defined in the interface as a constant. Note that confidence is about the decision reported in this decision object, and it is not the probability of entailment. For example, high confidence with <code>CONTRADICTION</code> decision means that EDA is cofident that the given input is a contradiction.
</para>
</listitem>
<listitem>
<para><code>String getPairID()</code>: this method returns the <code>entailment.Pair</code> id as described in the CAS.
</para>
</listitem>
<!-- <listitem> -->
<!-- <para><code>String getTextID()</code>: this method returns the text ID as it is reported in <code>TETextItem</code> annotation. Since <code>TETextITem</code> only exists in multiple T/H cases, call of this method should return null in single T-H cases.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>String getHypothesisID()</code>: this method returns the Hypothesis ID as it is reported in <code>TEHypothesisItem</code> annotation. Since <code>TEHypothesisItem</code> only exists in multiple T/H cases, call of this method should return null in single T-H cases.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>Object getInfo()</code>: This method returns an arbitrary object, which is optional and should hold additional information about the decision process. If no additional information is available, it should return <code>null</code>. If it returns a non-null object, the type and usage of the object should be documented with the EDA. Also <code>toString</code> of the object should output some meaningful text.  -->
<!-- </para> -->
<!-- </listitem> -->
</itemizedlist>
<para> Note that the interface only holds the minimal information that
is common for all EDAs. EDA implementers can extend this interface to
hold additional information for their EDAs. For example,
transformation-based EDAs might add transformation steps, and
distance-based EDAs might add more detailed information about distance
calculations, etc.   
</para> 
</section>

<section id="sec-4.2.1.6">
<title>enum <code>DecisionLabel</code></title>
<para>
This enumeration value represents the entailment decision. It should
be implemented as a hierarchical enumeration. 

<!-- One possible -->
<!-- hierarchical enumeration with the method <code>is()</code> is listed -->
<!-- in <xref linkend="c-1-DecisionLabel"/> -->

The current specification (V1.1) defines 6 labels:
<code>Entailment</code>, <code>NonEntailment</code>,
<code>Contradiction</code>, <code>Paraphrase</code>,
<code>Unknown</code>, and <code>Abstain</code>.  These labels form a
hierarchy where Entailment and Non-entailment are the top concepts and
have several subconcepts. For example, <code>Paraphrase</code> is an
<code>Entailment</code>. This means that
<code>DecisionLabel.Paraphrase.is(DecisionLabel.Entailment)</code>
will return true. Likewise, <code>Contradiction</code> and
<code>Unknown</code> are <code>NonEntailment</code>. </para>

<para> This type is open for extension. With the hierarchical
enumeration, one can extend this enumeration type with backward
compatibility. Note that the extension should always done with UIMA
type extension of <code>EXCITEMENT.entailment.Decision</code> <xref
linkend="TETypes"/>). 
</para>

<para>
Usage of <code>Abstain</code> should be
minimized. <code>Abstain</code> values should not be used in the
top-level independent EDAs. They should be only used in special cases,
like filtering type EDAs of TIE. Note that the
<code>DecisionLabel</code> is not used in the lexical knowledge
resources. It is only used on describing entailment decisions (output
of EDAs). 
</para>
</section>

<section> 
<title>Room for improvements: common training and common models </title>
<para>
For the moment, we have a very simple <code>start_training()</code>
interface within the specification. It only signals the EDA to
initiate its training procedure. It does not specify where training
data is, and where the output should fall into, etc. Such details are
assumed to be described in the configuration of the specific EDAs.
Neither do we have any common trained model file, or model
format. This can be problematic in the long term. Configuration values
and model metadata can get fragmented among the EDA implementations,
and this will confuse the platform users.
</para>

<para>
It is therefore desirable to specify common training methods, with a
common model format. With common model, the trained model "content"
can be different among EDAs, but its header (or meta-data wrappers)
should contain common information like, "on what configuration this
model was trained", "who is the generating EDA of this model", etc.
</para>

<para>
This issue has been raised and discussed among WP3 members. The
members all agreed that this common training and model feature is what
we will pursue. However, it also emerged that it is very hard to
realize the common training without some common code base (like common
machine training components). For example, currently some of our EDA
stores instances with full meta-data as "model" (instead of classifier
output model), while some other stores external tools model output
(like Weka, or libsvm) as a "model", without wrapper meta-data,
etc. The WP3 members have agreed that we will postpone the issue of
"common training and model" to later versions of the specification,
after delivery of the platform version 0.2 (the first "non-toy"
version).
</para>
</section>

<section>
<title>Additional interfaces for EDAs</title>
<para> <code>EDABasic</code> is the mandatory interface for all EDAs.
EDA implementers can choose to provide additional capabilities with
optional interfaces. The following is the list of the interfaces
currently specified in EXCITEMENT: 
<!-- Gil: Agree. Currently specified, sounds good [SP: I removed
     "complete" because I assume we don't want to make a closed-world
     assumption - developers may add their own interfaces...] -->
<!-- Gil: Done [SP: reorder sequentially - 4.2, 4.8, 4.9?] [SP: very
nice! very helpful for users] --> 
<itemizedlist>
<listitem>
<para><code>EDAMultiT</code>, <code>EDAMultiH</code>, <code>EDAMultiTH</code>: When an EDA support multiple text and/or hypothesis processing, it should implement the capability with one of the <code>EDAMulti</code> interfaces. See <xref linkend="sec-4.2.2"/>.</para>  
</listitem>

<listitem>
<para><code>EDAConcurrentProcessing</code>: An EDA can choose to
implement this interface directly for concurrent processing of
multiple entailment problems. See <xref linkend="EDAConcurrentProcessing"/>. </para> 
</listitem> 

<listitem>
<para><code>Reconfigurable</code>: If an EDA support online
reconfiguration (change of configurations within its
lifespan), it should provide the capability with this interface. See
<xref linkend="reconfigurable"/>. </para> 
</listitem> 

</itemizedlist> 
</para>

<para>
There are also auxiliary layer classes and interfaces that provide
additional capabilities for user layer code by wrapping EDA
interfaces. They are not part of the EDAs themselves, but provide
useful methods for complementing and deploying EDAs. 
<!-- Gil:Done - [SP: reorder sequentially?] --> 
<itemizedlist>

<listitem>
<para><code>InitializationHelper</code>: Initialization helper
enables users to select different EDAs by changing 
configurations (instead of code changes). see <xref linkend="InitializationHelper"/>. </para> 
</listitem>

<listitem>
<para><code>MultipleTHModeHelper</code>: This class uses a single pair
processing EDA (that only supports EDABasic) and provides methods of
<code>EDAMultiT</code> and <code>EDAMultiH</code>. See <xref linkend="MultipleTHModeHelper"/>. </para>
</listitem> 

<listitem>
<para><code>SinglePairProcessHelper</code>: EDA implementers can implement this interface that provides an easy-to-use access point to their
EDA. The interface provides online raw-text input for the EDA, via
LAP. See <xref linkend="SinglePairProcessHelper"/>.</para> 
</listitem> 

</itemizedlist>
</para> 

</section>
</section>


<section id="sec-4.2.2">
<title>EDA multiple text/hypothesis interface: interface
<code>EDAMultiT</code>, <code>EDAMultiH</code>,
<code>EDAMultiTH</code> </title>

<para><code>public interface EDAMultiT&lt;T extends
TEDecision&gt;</code></para>
<para><code>public interface EDAMultiH&lt;T extends
TEDecision&gt;</code></para>
<para><code>public interface EDAMultiTH&lt;T extends
TEDecision&gt;</code></para>

<para>Each of the interface defines a method, namely
<code>processMultiT</code>, <code>processMultiH</code>, and
<code>processMultiTH</code>. EDAs may choose to support them or not,
since supporting multiple T/H interfaces are optional. Multiple Texts
and Hypotheses are marked in the CAS by multiple
<code>EXCITEMENT.entailment.Pair</code> annotations (compare <xref
linkend="CAS_example2"/>).
<!-- The interface as Java code is listed in <xref linkend="c-2"/>. -->
</para>
<section id="sec-4.2.2.1">
<title><code>processMultiT</code>, <code>processMultiH</code>, <code>processMultiTH</code> </title>
<para><code>public List&lt;T&gt; processMultiT(JCas aCas)</code> </para> 
<para><code>public List&lt;T&gt; processMultiH(JCas aCas)</code> </para>
<para><code>public List&lt;T&gt; processMultiTH(JCas aCas)</code> </para> 

<para>
The processMulti methods share the same signature. They all work on a
single CAS that holds multiple texts and/or hypotheses, and returns a
list of TEDecision (objects that extends TEDecision). Each
<code>TEDecision</code> object has its own pair ID
(<code>getPairID()</code>) --- as annotated in
<code>entailment.Pair</code> data. Just like the single T-H
<code>process</code> interface, <code>processMulti*</code> should
check the input CAS for completeness and raise proper exceptions if
some needed CAS structure is missing. 
</para>

<para>
The specification does not define the ordering of the resulting list. 
</para>
<para>Parameters:
</para>
<itemizedlist>
<listitem>

<para><code>aCas</code>: A JCas object with <code>TETextITem</code> and/or <code>TeHypothesisItem</code> annotations. 
</para>
</listitem>
</itemizedlist>
<para>Returns:
</para>
<itemizedlist>
<listitem>

<para><code>List&lt;T&gt;</code>: A list of objects with type
<code>T</code> where <code>T</code> extends <code>TEDecision</code>.  
</para>
</listitem>
</itemizedlist>
</section>
</section>

<!-- <section id="sec-4.2.4"> -->
<!-- <title>Conformance </title> -->
<!-- <itemizedlist> -->
<!-- <listitem> -->

<!-- <para>EDA implementers must support <code>EDABasic</code> interface.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para>EDA implementers should follow the metadata check procedure -->
<!-- described in <xref linkend="sec-4.2.3"/>. </para> -->
<!-- </listitem> -->
<!-- </itemizedlist> -->
<!-- </section> -->

</section>

<section id="sec-4.3">
<title>Auxiliary Layer for EDAs</title>
<para> This section covers auxiliary layer classes and
interfaces. They are not part of the EDA interfaces, but provide
additional methods that helps accessing EDA functions. </para>      

<section id="InitializationHelper">
<title>Initialization Helper</title> 

<para><code>public abstract class InitializationHelper&lt;T extends
TEDecision&gt;</code></para>  

<para>The main access point to the entailment core is the EDA
interfaces. Users of the platform will process the data with LAP, and
will use EDA interfaces to get the entailment results. To use an EDA,
an instance of the EDA object must be first instantiated, and then it
must be initialized with a proper configuration. Then, the EDA will
initialize all needed components accordingly (see also Section <xref
linkend="sec-5.1.5"/>.
</para> 

<para> 
Thus, to start an EDA's initialization sequence, one must first
instantiate an instance, and then feed it a configuration object. This
also assumes that the configuration file is already read, and the main
EDA that is defined in the configuration is already
determined. <code>InitializationHelper</code> is an auxiliary layer that
takes care of this instantiation and initialization. Without the
helper, all of those process would have to be done by user code, which
would require different initialization sequences for different EDAs.
</para> 

<para> <code>InitializationHelper</code> solves this problem by
providing a common initialization capability. The helper code accepts a
configuration file, and then it reads the configuration file to
determine the main EDA class. Then, the helper instantiate and
initialize the EDA, and returns a ready-to-use EDA instance.
</para> 

<section>
<title>Methods of Initialization Helper</title> 
<para><code>public EDABasic&lt;T&gt; startEngineBasic(File f)</code></para>
<para><code>public EDAMultiT&lt;T&gt; startEngineMultiT(File f)</code></para> 
<para><code>public EDAMultiH&lt;T&gt; startEngineMultiH(File f)</code></para> 
<para><code>public EDAMultiTH&lt;T&gt; startEngineMultiTH(File f)</code></para> 

<para>
<code>InitializeHelper</code> has a set of public methods. They all
start the EDA initialization sequence with a File object (that has an
opened XML configuration file). If the initialization was successful,
it will return an EDA instance, as one of the EDA interfaces. 

<!-- Gil: Moved --> 
<!-- [SP: -->
<!-- 1. what is the relation between this section (Init Helper) and the -->
<!-- Multi H/T mode helper? My understanding is that the Multi H/T mode -->
<!-- helper is about *using* ECs, and this section is about *instantiating* -->
<!-- cores. Is that correct? Then maybe this section should come first -->
<!-- within 4.3.] [ SP: 2. Here we talk about MultiTH, but in the mode -->
<!-- helper we only foresee MultiH and MultiT. It would be better to be -->
<!-- consistent. I would think that for the moment we can ignore -->
<!-- MultiHT. OK?] -->

</para>

<para> With the initialization helper, user code can simply open a
valid configuration file, and call the initialize helper to get a
prepared EDA. Once the <code>startEngineXX</code> running is done, the
user code can call <code>process()</code> of the EDA instance.  Note
that the user code must know what type of EDA interface it will use 
(i.e.. <code>EDABasic</code> or <code>EDAMultiT</code>) before hand,
since they require different <code>process()</code> methods. </para>
<para> Also note that <code>InitializeHelper</code> is still open for
improvements. For example, it might be more realistic to support only
<code>startEngineBasic</code>, considering that it is the only common
interface that every EDA does support. Similar consideration can be
done for generic parameter <code>T</code>: It is likely that
<code>startEngine</code> will only support the common
<code>TEDecision</code>, since It The type every EDA will share. We
leave these possibilities open for now. Once we have a set of first
EDAs, we will decide on the common "engine starter". In this spirit,
work on the WP4 implementation will shape the final form for
<code>initializationHelper</code>.
</para> 

</section>

</section> <!-- end of init helper-->


<section id="MultipleTHModeHelper">
<title>Processing multiple T-H problems with
EDABasic:<code>MultipleTHModeHelper</code></title>  

<para><code>public abstract class MultipleTHModeHelper&lt;T extends
TEDecision&gt;</code></para>  

<para>The "mode helper" is a wrapper implementation that uses a
single-mode EDA (<code>EDABasic</code>) to support multiple T-H cases
(that of <code>EDAMultiT</code>, <code>EDAMultiH</code>, and
<code>EDAMultiTH</code>). It receives an already initialized EDA and
iteratively calls the EDA to produce results for multiple T/H
cases. It is a baseline implementation that can be used with any EDA.  
</para>

<para>
It is defined as an abstract Java object. 
<!-- The interface code is listed in <xref linkend="c-3"/>  -->
It is expected that the platform will share one implementation of mode helper for all EDAs. 
</para>
<section id="sec-4.3.1">
<title>Methods</title>
<section id="sec-4.3.1.1">
<title>method <code>setEDA</code></title>
<para><code>public void setEDA(EDABasic&lt;T&gt; eda)</code>: This
method must be called before calling any of the process methods. Note
that initialization and shutdown of the EDA must be effected by user
code, outside the mode helper.
</para>

<para>Parameters 
</para>
<itemizedlist>
<listitem>

<para><code>eda</code>: An initialized <code>EDABasic</code>. All processing of the mode helper will be done by calling <code>eda.process()</code>. 
</para>
</listitem>
</itemizedlist>
</section>

<section id="sec-4.3.1.2">
<title>Method <code>processMultiT</code>, <code>processMultiH</code>,
and <code>processMultiTH</code> </title>
<para><code>public List&lt;T&gt; processMultiT(JCas aCas)</code> </para>
<para><code>public List&lt;T&gt; processMultiH(JCas aCas)</code> </para> 
<para><code>public List&lt;T&gt; processMultiTH(JCas aCas)</code></para> 
<para>
Mode helper implements the <code>EDAMulti*</code> methods. When
called, they will iteratively call <code>process()</code> of the given
EDA to generate the result. All other behaviors (input specifications
and exception checks, etc) should be the same with
<code>EDAMulti*</code> interface that implements the methods directly.     
</para>
</section>
</section>
</section>

<section id="SinglePairProcessHelper">
<title>Produce entailment decision for raw-text input:
<code>SinglePairProcessHelper</code></title> 

<para><code>public interface SinglePairProcessHelper&lt;T extends
TEDecision&gt;</code></para>  

<para>This interface is a convenience interface for "end users" of an
entailment engine. The implementation of this interface uses a
specific implementation of EDA (<code>EDABasic</code>), and provides a
method that allows the user to run the complete engine including LAP
and Entailment Core with a single call. The access method receives two
<code>String</code> objects as input (the text and the hypothesis,
respectively), and returns the result (an object that extends <code>TEDecision</code>) for them. </para> 

<para>Since this is a convenience interface, it is limited with regard
to functionality and efficiency. It does not support context
sentences, or multiple text/hypothesis situations. Also, calling the
LAP for just one sentence pair is presumably quite inefficient.  
</para>

<para>Note that, unlike <code>MultipleTHModeHelper</code>, the
platform cannot share a single ProcessHelper implementation for all
EDAs. Each EDA needs to run a different LAP, thus each EDA is expected to have its own ProcessHelper.  
</para> 
<!-- <para>This interface is provided as a separate interface from -->
<!-- <code>EDABasic</code>. The reason is to reduce the dependency between -->
<!-- the entailment core and LAP calling mechanism. Among all proposed -->
<!-- interfaces of the entailment core, only this interface needs to know -->
<!-- how to call LAP. By separating the interface from -->
<!-- <code>EDABasic</code>, it permits the implementers to separate LAP -->
<!-- calling parts from the main EDA implementation. </para> -->

<section>
<title>method <code>processRawInput</code></title>
<para><code>public T processRawInput(String text, String
hypothesis)</code></para> 
<para>The method first calls needed LAP pipeline to analyze the given
raw text and hypothesis. Then, it uses <code>EDABasic</code> 
<code>process()</code> method to deliver the result (<code>TEDecision</code> or its extension).   
</para>

<para>Parameters:
</para>
<itemizedlist>
<listitem>
<para><code>text</code>: a java <code>String</code> that holds the text.  
</para>
</listitem>
<listitem>
<para><code>hypothesis</code>: a java <code>String</code> that holds the hypothesis. 
</para>
</listitem> 
</itemizedlist>
<para>Returns:
</para>
<itemizedlist>
<listitem>
<para><code>T</code>: An object of the interface that extends <code>TEDecision</code>.   
</para>
</listitem>
</itemizedlist>

</section> 
</section>




</section> <!-- end of auxiliary layer --> 

<section id="sec-4.3a">
<title>Common functionality of components: The
<code>Component</code> interface</title>
<para>
There is a small set of methods that are common to all components. 
These methods are primarily
concerned with the administrative aspects of components and their
interactions with the EDA. These methods form the
<code>Component</code> interface. All more specific interfaces in the
following sections are subinterfaces of <code>interface Component</code>.
</para>


<!-- <section id="sec-4.3a.1"> -->
<!-- <title>method <code>initialize()</code> </title> -->
<!-- <para><code>public void initialize(CommonConfig config)</code></para> -->
<!-- <para> -->
<!-- This method will be called by the component user as the signal for -->
<!-- initializing the component. All initialization (including connecting -->
<!-- and preparing resources) should be done within this -->
<!-- method. Implementations must check the configuration and raise -->
<!-- exceptions if the provided configuration is not compatible with the -->
<!-- implementation. -->
<!-- </para> -->
<!-- <itemizedlist> -->
<!-- <listitem> -->
<!-- <para>Parameter <code>config</code>: a common configuration object. This -->
<!-- configuration object holds the platform-wide configuration. An -->
<!-- implementation should process the object to retrieve relevant -->
<!-- configuration values for the component. The common configuration is -->
<!-- defined in <xref linkend="sec-5.1"/>. -->
<!-- </para> -->
<!-- </listitem> -->
<!-- </itemizedlist> -->
<!-- </section> -->

<section id="sec-4.3a.2">
<title>method <code>getComponentName</code> </title>
<para><code>public String getComponentName()</code> </para>
<para>This method provides the (human-readable) name of the component. It is
used to identify the relevant section in the common configuration for
the current component. See Sections <xref linkend="sec-5.1.2"/> and <xref linkend="sec-4.7.3" />.
</para>
</section>

<section id="sec-4.3a.3">
<title>method <code>getInstanceName</code></title>
<para><code>public String getInstanceName()</code> </para>
<para>This method provides the (human-readable) name of the instance. It is
used to identify the relevant subsection in the common configuration for
the current component. See Sections <xref linkend="sec-5.1.2"/> and
<xref linkend="sec-4.7.3" />. Note that this method can return null
value, if and only if all instances of the component shares the same
configuration. 
</para>
</section>

<section id="componentInit">
<title>Initialization of a Component</title>
<para>
Previously, the method <code>void initialize(CommonConfig c)</code>
was included in the <code>interface Component</code>. This means that
all components are supposed to be initialized by this method, with a
configuration object. Since specification verion 1.1.2, the method is
removed from the interface. This changes the expected behavior of a
component for its initialization.</para>  

<para>
All component implementations should satisfy the following conditions.

<orderedlist>
<listitem><para> All configurable/settable parameters are exposed in
the constructor. So basically, a user can initialize and run a
component; even without a configuration
(<code>CommonConfiguration</code>) object, as long as the user
supplies correct values for the arguments.</para>  
</listitem> 

<listitem>
<para> Components that need to read from the configuration
<emphasis>shall</emphasis> provide a overridden constructor, which
gets a <code>CommonConfig</code> object. (For example,
<code>GermaNet(CommonConfig c)</code>, or
<code>EnglishWordNet(CommonConfig c)</code>.) This constructor code
knows which part of the common configuration is relevant to the
component, and reads the configuration values from the configuration,
and call the first constructor. </para>     
</listitem> 
</orderedlist>
</para> 

<para> 
Note that the overridden constructor that knows how to deal a 
the configuration object can have forms other than the single 
argument of <code>CommonConfig</code>. For example, components that
permits multiple instances might need additional arguments. It might
look like <code>GermaNet(CommonConfig c, String instanceName)</code>,
where the <code>instanceName</code> will identify proper configuration
subsection for that instance, etc.  
</para> 

<para> 
Also note that EDA still keeps its <code>initialize()</code> method,
in the <code>EDABasic</code> interface. This will force all EDA
implementations to have this method. This reflects that EDA will
always have a dependency to the configurations, and the method will be
used by top-level initialization helper and other user-layer
codes. <!-- For example, any object that follows =EDABasic= interface can
be initialized by eda.initialize(config), and start processing TH
pairs with eda.process(cas).     --> 
</para> 
</section> 

<section id="sec-4.3a.4">
<title>Storage of names</title>
<para>
The specification does not define how and where component and instance
names is stored internally within the component implementations. It is
expected that the implementation efforts will implement a common
practice of keeping instance names. <!-- In any case, components must
provide extensive documentation about the component and instance names
that they assume.--> 
</para>
</section>

</section> <!-- end of interface Component --> 

<section id="ScoringComponent">
<title>Interface for Scoring Components</title>

<para>This component accepts a T-H pair (represented in a
<code>JCas</code>) as the input, and returns a vector of scores (as
<code>Vector&lt;Double&gt;</code>). The scores can be anything that
represent some aspects of the given T-H pair. We can easily imagine
various scores that report possible interesting "features" of the
given pair. For example, number of shared arguments and predicates,
location of main  predicate, length (or length difference) of T/H,
etc.  
</para>

<para>
In a sense, you can regard this type of component as a "feature
extraction component" where the extracted features are reported back
as a vector of numbers. What each number of the resulting vector means
is different among components. This, should be documented by each
component implementers in JavaDoc of the component.  
</para>

<para>
One special case for reporting back scores, is the distance
calculation (or similarity calculation) between a T-H pair.  Since
distance calculation between T-H is such a common capability needed
for various entailment methods, we define it as a separate interface
that extends the scoring component interface. See <code>interface
DistanceCalculation</code> (<xref linkend="sec-4.4"/>) for that
interface. 
</para> 

<section>
<title><code>interface ScoringComponent</code></title>
<para>
Like all other components, the interface extends <code>interface
Component</code>. The interface adds a single method
<code>calculateScores()</code>, which gets a <code>JCas</code> as the
input argument, and returns a <code>Vector&lt;Double&gt;</code>.  
</para>

<section id="calculateScores">
<title>Method calculateScores() </title>
<para><code>public Vector&lt;Double&gt; calculateScores(JCas cas)</code> 
</para>

<para>
The method delivers a list of numbers where the numbers represent some 
features of the given JCas object. The calculation can be only done if
the CAS has two prepared views (<code>TextView</code> and
<code>HypothesisView</code>), and the needed linguistic
annotations. Note that the method compares  all contents of the two
views directly, and does not (and should not) utilizes other
entailment annotations like <code>entailment.Pair</code>, or
<code>entailment.Text</code>, etc. This is to retain the generality of
the scoring component and the distance components (so that they can be
used in comparing any two given texts).  
</para>

<para>
The method may choose to check the validity of the input. For example, 
if the provided annotations are not compatible for the calculation
(e.g. if the parse tree is missing for a tree level feature extractor,
etc), it can raise an exception accordingly. 
</para>

<para>
Multi-pair CASes should not be passed directly to this method, since it
only extracts scores from the two views. (It is expected that LAP code
will provide a tool that breaks down a multi-pair CAS into an
iterative set of single-pair CASes. One can use such tool for
multi-pair CASes).  
</para>
<itemizedlist>
<listitem>

<para>parameter <code>cas</code>: a JCas with <code>TextView</code>
and <code>HypothesisView</code>. The texts from the two views will be
used in the score calculation  </para> 
</listitem>
<listitem>
<para>returns <code>Vector&lt;Double&gt;</code>: a vector of double
values. They can serve as feature values that represent the given
pair. Each implementation should documentate meaning (or underlying
calculation) of the values.  
</para>
</listitem>
</itemizedlist>
</section>

</section> <!-- end of interface definition--> 
</section> <!-- end of ScoringComponent --> 


<section id="sec-4.4">
<title>Interface of distance calculation components</title>

<para>
The ability to calculate the distance or similarity of two textual
units are essential in many textual entailment algorithms. Within the
EXCITEMENT platform, distance calculations and similarity calculations
are generalized with the distance calculation interface. The interface
generalizes both similarity and distance calculations in a normalized
range of distance 0 (totally identical) to distance 1 (maximally
different). 
</para>
<section id="sec-4.4.1">
<title>interface <code>DistanceCalculation</code> </title>
<para>The interface is a subinterface of
<code>ScoringComponent</code>. The new methods it adds is
<code>calculation()</code>, which gets a <code>JCas</code> and returns
an object of <code>DistanceValue</code>. 
<!-- The interface definition in -->
<!-- Java code can be found in <xref linkend="c-4"/>.  -->
</para>

<section id="sec-4.4.1.2">
<title>method <code>calculation()</code> </title>
<para><code>public DistanceValue calculation(JCas aCas)</code>
</para>

<para>
<!-- This method may only be called after a successful call to
<code>initialize()</code>. --> 
The method delivers the distance calculation result
in an Object <code>DistanceValue</code> (<xref linkend="sec-4.4.2"/>),
which represents the distance between two textual objects in the
JCas. The calculation is done between the two views of the JCas:
TextView and HypothesisView.  The <code>calculation()</code> method
knows nothing about other entailment annotations (like
<code>entailment.Pair</code> or <code>entailment.Text</code>) and it
should not check those annotations.  
</para>

<para>
The implementation may choose to check the validity of the input. For
example, if the provided annotations are not compatible for
calculations (e.g. if the parse tree is missing for a tree edit
distance component), it can raise an exception accordingly. However,
unlike in the case of the EDA <code>process()</code> method, this
check is not mandatory.
</para>
</section>

<section> 
<title>Inherited method <code>calculateScores()</code> </title> 
<para>The main data structure that is returned from a distance
component is <code>DistanceValue</code>, of method
<code>calculation()</code>. 
However, an implementation should report back a vector correctly when
it is called by the inherited method <code>calculateScores()</code>
(<xref linkend="calculateScores"/>). The choice of
values to report back is, of course, the implementer's
choice. However, it is recommended that the returned set of vectors
should have the distance  values (duplicated to the ones in
DistanceValue), and all underlying raw scores (if any) that helped
calculating the DistanceValue. (For example, unnormalized values,
raw-frequency count, length of T/H, denominator of normalizing,
etc. They may be used as additional features by some EDAs). </para>  
</section>

</section> <!-- end of interface DistanceCalculation --> 

<section id="sec-4.4.2">
<title>Type <code>DistanceValue</code> </title>
<para>This type holds the distance calculation result. It has some
member variables and public access functions for the variable. The
type is used to exchange data between the component and the EDA. Its
variables are set during initialization. 
<!-- The actual java code listing -->
<!-- is included in <xref linkend="c-4"/>.  -->
</para>
<section id="sec-4.4.2.1">
<title>Variables and access methods </title>
<itemizedlist>
<listitem>
<para><code>private double distance</code>: The normalized
distance. The maximum value is 1 (maximally different), and the
minimum value is 0 (totally identical). Access is provided by the
method <code>double getDistance()</code>.
</para>
</listitem>
<listitem>
<para><code>private boolean isSimBased</code>: This boolean is <code>true</code> if the calculation is based on similarity functions. This boolean is <code>false</code> (default) if the calculation is based on distance-based calculations. This value is provided to help the interpretation of the <code>unnormalizedValue</code>. Users can ignore this value, if the do not use <code>unnormalizedValue</code>. The method <code>getIsSimBased()</code> accesses this value. 
</para>
</listitem>
<listitem>
<para><code>private double unnormalizedValue</code>: This variable
holds a distance or similarity value that is not normalized. If the
value is mapped into the range with common normalization, it will
produce the value stored at <code>distance</code>. This unnormalized
value is provided for the users to use some other methods of
normalizations, such as asymmetric normalizations used in some
EDAs. The value is accessed by the function <code>double
getUnnormalizedValue()</code>.
</para>
</listitem>
<!-- removed; deprecated by ScoringComponent, that is the supertype of
DistanceComponent 
<listitem>
<para><code>private Vector distanceVector</code>: This variable holds a set of
double values. The vector is an optional value that permits the
distance calculation components to return a set of distance values
that is needed, or used to generate the main value. If the component
does not provide this vector, this variable should be
<code>null</code>.  
</para>
</listitem>
--> 
</itemizedlist>

<para>Note that the value <code>unnormalizedValue</code> is not only
unnormalized, but also not mapped into the distance scales. Thus, the
interpretation of the unnormalized value should always consult the
boolean variable <code>isSimBased</code>. For example, the
<code>unnormalizedValue</code> of cosine similarity will presumably
hold the original vector product value, with <code>isSimBased</code> as
<code>true</code>. In this case, a higher <code>unnormalizedValue</code>
means more similar (less distant) objects.
</para>
</section>
</section>
</section>

<section id="sec-4.5">
<title>Interface of lexical knowledge components </title>
<para>
The access to lexical knowledge is generalized with common interfaces
and common types. Each entry of lexical knowledge is encapsulated by
the <code>class LexicalRule</code>, and collections of such rules are
represented by the interface <code>LexicalResource</code>.
</para>

<!-- TODO: update with one read on LHS->RHS, regarding to
TERuleRelation removal --> 

<section id="sec-4.5.1">
<title>Type <code>LexicalRule</code> </title>
<para><code>public final class LexicalRule&lt;I extends RuleInfo&gt;</code> 
</para>

<para>
This type represents a generalization of lexical relationships between
two words, which are provided by resources like WordNet, VerbOcean and
distributional resources. It has two parts: a left hand side (LHS) and
a right hand side (RHS).  The basic arrangement of lexical resource is
that the left hand side has a relationship to the right hand side. 
Normally, this relationship is entailment (LHS entailment RHS; return
values of <xref linkend="sec-4.5.2"/>). However, they can also
represent resource specific or canonical relations (see <xref
linkend="LexicalResourceWithRelation"/> for querying such relations).   

A lexical rule also provides additional pieces of information include
confidence, relation name, and resource name. Finally, lexical rules
are parametrized by a type <code>I</code> (short for information)
which allows the type to hold additional resource-specific properties.  
</para>

<para> 
Before going into details of the class variables, let us first see a
few examples. The following figure shows a pictorial example of the
data type. It shows two examples of lexical relations. Each relation
is represented with a few data features.
</para> 

<figure id="lexical_rule">
<title>Examples of lexical rule instance</title> 
<mediaobject>
<imageobject>
<imagedata fileref="./figures/lexical_rule_example.jpg" scalefit="1" width="85%"
	   align="center"/> 
</imageobject>
</mediaobject>
</figure>

<para> 
On the left, it shows an instance of <code>LexicalRule</code> that
represents the relationship between "pipe" and "tube". The value
<code>originalRelation</code> holds the relation (here the "hypernym") from
left ("pipe") to the right ("tube"), as recorded in the knowledge
resource (here, WordNet). In this example, the left hand side entails
the right hand side.
<!-- , and the canonical relation <code>relation</code>
is <code>entailment</code>. --> 
The confidence is not provided by the implementation, and it is given
as <code>DEFAULT</code>. Additional information is provided in the
example with info variable. The type variable  <code>I</code> is
instantiated by a type "WordNetInfo" which holds information about
synsets.   
</para>

<para>
On the right, another example shows that "Magritte" entails
"painter". In this case, the knowledge is captured from Wikipedia, and
the resource dependent information provides various Wikipedia-based
links and scores. Here, the implementation also provides a confidence
value.
</para>

<para>
All lexical knowledge of EXCITEMENT resource will be delivered as an
instance of this object. 
<!-- Java source code of the <code>class -->
<!-- LexicalRule</code> is provided in <xref linkend="c-5"/>. -->
</para>
<section id="sec-4.5.1.1">
<title>Variables and access methods. </title>
<itemizedlist>
<listitem>
<para><code>private final String leftLemma</code>: lemma of the LHS (left hand side). 
</para>
</listitem>
<listitem>
<para><code>private final PartOfSpeech leftPos</code>: POS of the LHS. 
</para>
</listitem>
<listitem>
<para><code>private final String rightLemma</code>: lemma of the RHS (right hand side). 
</para>
</listitem>
<listitem>
<para><code>private final PartOfSpeech rightPos</code>: POS of the RHS.
</para>
</listitem>
<listitem>
<para><code>private final I info</code>: An object of type I, which
will hold additional information that can be vary among knowledge
bases. This <code>I</code> must be an extension of
<code>RuleInfo</code>.  
</para>
</listitem>
<!-- 
<listitem>
<para><code>private final TERuleRelation relation</code>: This variable
holds an enum value of <code>TERuleRelation</code>. It can be one
of two: <code>Entailment</code> or <code>NonEntailment</code>. 
</para>
<para>
</para>
</listitem>

<listitem>
<para><code>private final String originalRelation</code>: If the
resource uses some relations (like WordNet or VerbOcean), this string
holds the relation name as string. Otherwise, null.  
</para>
</listitem>
--> 
<listitem>
<para><code>private final String relation</code>: If the
resource uses some relations (like WordNet or VerbOcean), this string
holds the relation name as string. Otherwise, null.  
</para>
</listitem>

<listitem>
<para><code>private final String resourceName</code>: name of the resource
</para>
</listitem>
<listitem>
<para><code>private static final double DEFAULT_CONFIDENCE</code>: A
class constance variable that holds a value indicating that no
confidence is available.
</para>
</listitem>
<listitem>
<para><code>private final double confidence</code>: The confidence
score assigned to the rule, in the interval [0,1]. Consider this value
as a probability of entailment from LHS to RHS. Naturally, higher
value means more confident on the entailment of LHS to RHS. If no
meaningful confidence score is provided by the resource, this will
hold the value of DEFAULT_CONFIDENCE.  
</para>
</listitem>
</itemizedlist>

<para>For each variable, a corresponding access method is provided (for example, <code>getLeftPos()</code> for <code>leftPos</code>). The object is immutable, and the values can be only set by the constructors. 
</para>
</section>

<section id="sec-4.5.1.2">
<title>Related Types </title>
<itemizedlist>
<listitem>

<para><code>interface RuleInfo</code>: An interface reserved for
additional information. Any additional information that is not covered
in the <code>LexicalRule</code>, depending on the specific rule base,
should be included by implementing this interface. 
</para>
</listitem>
<listitem>
<para><code>abstract class PartOfSpeech</code>: This class represents
a generalization for part of speech tags. By implementations, it can
support different tag sets. The platform will provide common canonical
POS set that is corresponding to the POS type of adopted CAS
types. <!-- The class source code is listed in <xref linkend="c-5"/>
--> It is expected that each knowledge base will express the POS
information according to this canonical set of POS labels.
</para>
</listitem>
<!--  moved into LexicalResourceWithRelation
<listitem>
<para> <code>enum TERuleRelation</code>: This enum value represents
a canonical mapping of lexical relations. Lexical rules from different
<code>lexicalResource</code> have different
<code>originalRelation</code>. However, all of them share this common
<code>TERuleRelation</code> which describes the relation in terms
of textual entailment. It is one of the two values:
<code>Entailment</code> which means that the lexical relationship from
LHS to RHS is entailment. <code>NonEntailment</code> means that the
lexical relationship from LHS to RHS cannot be entailment. Note that
<code>NonEntailment</code> means the knowledge resource is confident
that the relationship is not entailment (e.g. contradiction,
etc). Note that this enum only describes the lexical relation, not
entailment decision. For entailment decisions, there is a separate
enum <code>DecisionLabel</code> (<xref linkend="sec-4.2.1.6"/>). 
</para> 
</listitem>
--> 
</itemizedlist>
</section>
</section>

<section id="sec-4.5.2">
<title>Interface <code>LexicalResource</code></title>
<para><code>public interface LexicalResource&lt;I extends RuleInfo&gt;</code> 
</para>

<para>
A lexical resource is a collection of lexical rules of a certain type
(like WordNet, or VerbOcean) which can be queried. The interface
provides three query methods. Queries are specified by lemma and POS
pairs, and the results are returned as a list of
<code>LexicalRule</code> objects. 
<!-- The Java source code of the interface is listed in the <xref -->
<!-- linkend="c-5"/>.   -->
<code>LexicalResource</code> is a subinterface of
<code>Component</code> and adds the following methods:
</para>
<itemizedlist>
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt;
getRulesForLeft(String lemma, PartOfSpeech pos)</code>: Returns a list of lexical rules whose left side (the head of the lexical relation) matches the given lemma and POS. An empty list means that no rules were matched. 
If the user gives <code>null</code> POS, the interface will retrieve rules for all possible POSes. 
</para>
</listitem>
<!-- 
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt;
getRulesForLeft(String lemma, PartOfSpeech pos, TERuleRelation
relation)</code>: an overloaded method for
<code>getRulesForLeft</code>. In addition to the previous method, this
method also matches the <code>relation</code> field of
<code>LexicalRule</code> with the argument.
</para>
</listitem>
--> 

<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt;
getRulesForRight(String lemma, PartOfSpeech pos)</code>: Returns a list
of lexical rules whose right side (the target of the lexical relation)
matches the given lemma and POS. An empty list means that no rules
were matched.  
</para>
</listitem>
<!-- 
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt;
getRulesForRight(String lemma, PartOfSpeech pos, TERuleRelation
relation)</code>: an overloaded method for
<code>getRulesForRight</code>. In addition to the previous method,
this method also matches the <code>relation</code> field of
<code>LexicalRule</code> with the argument.  
</para>
</listitem>
--> 

<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRules(String
leftLemma, PartOfSpeech leftPos, String rightLemma, PartOfSpeech
rightPos)</code>: This method returns a list of lexical rules whose
left and right sides match the two given pairs of lemma and
POS. 
</para>
</listitem>
<!-- 
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRules(String
leftLemma, PartOfSpeech leftPos, String rightLemma, PartOfSpeech
rightPos, TERuleRelation relation)</code>: an overloaded method for
<code>getRules</code>. In addition to the previous method, this method
also matches the <code>relation</code> field of
<code>LexicalRule</code> with the argument.  
</para>
</listitem>
--> 
<listitem>
<para><code>void close()</code>: this method enables the
implementation to gracefully close underlying system resources (files, 
database connections, etc). Users of syntactic and lexical resources
are expected to call close() when the resource is no longer needed.   
</para>
</listitem>
</itemizedlist>

<para> The implementation of <code>getRules</code> methods must return
an empty list (not <code>null</code>) if no applicable rules are
found. </para>  

<para>Note that all lexical rules returned by this interface
represent entailments (LHS->RHS entailments). In this sense, the
methods only support querying of "entailments". If your lexical
resource supports additional relational queries, you can provide
them with the additional interface <xref   
linkend="LexicalResourceWithRelation"/>. 
</para> 
</section> <!-- end of subsection Interface LexicalResource --> 

<section id="LexicalResourceWithRelation">
<title>interface <code>LexicalResourceWithRelation</code> </title>
<para><code>public interface LexicalResourceWithRelation&lt;I extends RuleInfo, R extends RelationSpecifier&gt; extends LexicalResource&lt;I&gt;</code> 
</para>

<para>
The interface LexicalResource (<xref linkend="sec-4.5.2"/>) defines
the common method of querying and getting lexical entailment rules of
the given words. This abstraction is useful in the sense that it
abstracts various underlying lexical resources with the entailment
relation. This enables the caller of LexicalResource implementations
to query various knowledge resources in the same fashion.  
</para>

<para>
However, this comes with a price: the LexicalResource interface cannot
provide querying capability of relations others than entailment. For
example, user of that interface cannot query NonEntailment words of
the given term (terms that you are sure that is not entailment), nor
resource-specific relations (like synonym or hypernym of WordNet, or
Stronger-than or happens-before of VerbOcean, etc). These
resource-specific relations are reported back as part of the query
result (RuleInfo within LexicalRule), but cannot be directly asked for. 
</para>

<para>
<code>LexicalResourceWithRelation</code> is defined to recover this
capability. It permits lexical resource implementers to define
additional query methods with relations. It enables not only the
canonical relation queries but also queries with resource-specific 
relations.The interface extends <code>LexicalResource</code>, and
adds three methods. Essentially, each of the method has one additional
argument that represents the relation to be queried.  
</para>

<para>
<code>public interface LexicalResourceWithRelation&lt;I extends RuleInfo, R extends RelationSpecifier&gt; extends LexicalResource&lt;I&gt;</code> 
</para>
<itemizedlist>
<listitem>

<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRulesForLeft(String lemma,   PartOfSpeech pos, R relation) throws LexicalResourceException;</code> 
</para>
</listitem>
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRulesForRight(String lemma,   PartOfSpeech pos, R relation) throws LexicalResourceException;</code> 
</para>
</listitem>
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRules(String leftLemma,
PartOfSpeech leftPos, String rightLemma, PartOfSpeech rightPos, R
relation) throws LexicalResourceException;</code> 
</para>
</listitem>
</itemizedlist>

<para>Each of the method gets one additional parameter <code>R
relation</code> that specifies the relation to be fetched. For
example, if <code>relation</code> is "NonEntailment", the resource
will return rules that specifies "NonEntailment" (where LHS-&gt;RHS is
confidently cannot be entailment). If the <code>relation</code> holds
"Synonym", it means the query should return Lexical rules where LHS to
RHS is synonymy.  
</para>

<para>
Note that the relation is represented by a generic parameter
<code>R</code>. Each <code>R</code> is an extension of
<code>RelationSpecifier</code>, where the <code>R</code> can be
tailored for each resource. We adopt a simple hierarchy for this
<code>R</code>. The interface <code>RelationSpecifier</code> and
related objects are described in the following subsections.    
</para>
</section>

<section>
<title>Interface <code>RelationSpecifier</code> and its hierarchy </title>
<para>
The following figure shows the simple hierarchy of
<code>RelationSpecifier</code>. The interface <code>RelationSpecifier</code> stays in the top, and two interfaces (<code>CanonicalRelationSpecifier</code> and <code>OwnRelationSpecifier&lt;E&gt;</code>) extends this top interface. 
</para>

<programlisting>
                   RelationSpecifier 
                    /             \
                   /               \
CanonicalRelationSpecifier     OwnRelationSpecifier&lt;E&gt; 
</programlisting> 

<para>
The intention of adopting the hierarchy on relation specifier is to 
explicitly mark the class of relations that are supported by each
<code>LexicalResourceWithRelation</code>. For example, all lexical
resources that support canonical relation bears the same signature of
<code>R</code> (as <code>&lt;R extends
CanonicalRelation&gt;</code>). This is the same for resources that
support resource-specific relations (<code>R</code> as <code>&lt;R
extends OwnRelationSpecifier&lt;E&gt;&gt;</code>).      
</para>

<para>
Let's check each of the interfaces. 
</para>
<section>
<title><code>interface RelationSpecifier</code></title>
<para><code>public interface RelationSpecifier</code> 
</para>

<para>
This is an empty interface where it defines no methods. Extending or
implementing this interface means that the class is to be used as the
paramter <code>R</code> of <code>LexicalResourceWithRelation</code>. This interface is the
top of the relation specifier hierarchy, and intentionally left
empty. This means that you can design a speical RelationSpecifier
that can be used in <code>LexicalResourceWithRelation</code> if needed. 
However, in most cases, you will implement one or both of the
following sub-interfaces. 
</para>
</section>

<section>
<title>CanonicalRelationSpecifier</title>
<para><code>public interface CanonicalRelationSpecifier extends RelationSpecifier</code>
</para>

<para>
This interface defines a single method: 
</para>
<itemizedlist>
<listitem>

<para><code>public TERuleRelation getCanonicalRelation();</code> 
</para>
</listitem>
</itemizedlist>

<para>The method returns the canonical relation (as <code>enum
TERuleRelation</code>, <xref linkend="TERuleRelation"/>), where it
means this canonical relation is being queried upon. This return value
can be <code>null</code>, which means "don't care" (the query don't
care about canonical relation).  
</para>
</section>

<section id="TERuleRelation">
<title><code>enum TERuleRelation</code></title> 
<para> This enum value represents a canonical mapping of lexical
relations. Lexical rules of different <code>lexicalResource</code>
may have different original relations. However, they can support this 
common <code>TERuleRelation</code> which describes the relation in
terms of textual entailment. It can be one of the two values: 
<itemizedlist>
<listitem><para>
<code>Entailment</code> which means that the lexical relationship from
LHS to RHS is entailment. 
</para>
</listitem>
<listitem><para>
<code>NonEntailment</code> means that the lexical relationship from
LHS to RHS cannot be entailment.  
</para> 
</listitem> 
</itemizedlist>
Note that <code>NonEntailment</code> means the knowledge resource is
confident that the relationship is not entailment (e.g. contradiction,
etc). Also note that this enum only describes the lexical relation,
not entailment decision. For entailment decisions, there is a separate 
enum <code>DecisionLabel</code> (<xref linkend="sec-4.2.1.6"/>). 
</para> 
</section> 

<section>
<title><code>interface OwnRelationSpecifier</code></title>
<para><code>public interface OwnRelationSpecifier&lt;E&gt; extends RelationSpecifier</code> 
</para>

<para>
The interface defines a single method: 
</para>
<itemizedlist>
<listitem>

<para><code>public E getOwnRelation();</code> 
</para>
</listitem>
</itemizedlist>

<para>The method returns the resource-specific relation (as <code>E</code> which is
defined by a generic parameter). The returned <code>E</code> will be the
resource specific relation that is being queried upon. This return
value can be <code>null</code>, which also means "don't care". 
</para>

<para>
The paramter <code>E</code> is to be defined by each resource implementer to
represent resource specific relations. 
</para>
</section>

<section>
<title>Conformance on LexicalResource and LexicalResourceWithRelation </title>
<itemizedlist>
<listitem>

<para>All lexical resources must support the minimal interface
<code>LexicalResource</code>. This interface only returns lexical rules of
LHS-&gt;RHS entailment relation.  
</para>
</listitem>
<listitem>
<para>If the lexical resource supports canonical relation (TERuleRelation),
it should implement <code>LexicalResourceWithRelation</code> with a relation
specifier that implements <code>CanonicalRelationSpeicifier</code>. 
</para>
</listitem>
<listitem>
<para>If the lexical resource supports resource-specific queries, it
should implement <code>LexicalResourcewithRelation</code> with a relation
specifier that implements <code>OwnRelationSpecifier</code>. 
</para>
</listitem>
<listitem>
<para>If the lexical resource supports both canonical and
resource-specific queries, its relation specifier should implement
both <code>OwnRelationSpecifier</code> and <code>CanonicalRelationSpecifier</code>. 
Note that if both of the relation are specified, the query should be
interpreted with "AND", which means both of the relation constraints
should be satisfied. (For example, Entailment AND Synonym, or
NonEntailment AND meronym, etc)  
</para>
</listitem>
</itemizedlist>

<para>The following is a small code example that shows an implementation of
<code>LexicalResourceWithRelation</code>, which supports both canonical relation
and resource specific relation.  
</para>
</section>

<section>
<title>An Example of <code>LexicalResourceWithRelation</code> and <code>RelationSpecifier</code></title>
<para>Let's see an example for a clearer explanation. The following is a
partial (and artificial) implementation example of
<code>LexicalResourceWithRelation</code> where its <code>R</code> supports both
<code>CanonicalRelationSpecifier</code>, and <code>OwnRelationSpecifier</code>.   
</para>

<para>
The following is <code>RelationSpecifier</code> of this resource (German
WordNet). Note that <code>WordNetRelation</code> is an enum that has all WordNet
relations, and used as <code>&lt;E&gt;</code> of <code>OwnRelationSpecifier&lt;E&gt;</code>:  
</para>

<programlisting language="java">
public class GermaNetRelation implements CanonicalRelationSpecifier, 
                         OwnRelationSpecifier&lt;WordNetRelation&gt; 
{

   public GermaNetRelation(TERuleRelation canonicalRelation, 
                           WordNetRelation ownRelation)
   {
      this.canonicalRel = canonicalRelation; 
      this.ownRelation = ownRelation; 
   }

   public GermaNetRelation(TERuleRelation canonicalRelation) {
      this(canonicalRelation, null);
   }

   public GermaNetRelation(WordNetRelation ownRelation) {
      this(null, ownRelation); 
   }

   @Override // from canonical relation specifier 
   public TERuleRelation getCanonicalRelation() {
      return canonicalRel;  
   }

   @Override // from own relation specifier 
   public WordNetRelation getOwnRelation() {
      return ownRelation; 
   }

   private final TERuleRelation canonicalRel; 
   private final WordNetRelation ownRelation; 
}
</programlisting> 

<para>
GermaNet implementation would be defined with the following generic
parameters: 
<programlisting language="java">
public class GermaNetImplementation implements 
   LexicalResourceWithRelation&lt;GermaNetInfo, GermaNetRelation&gt; { ...
</programlisting>
</para> 

<para>
And the usage example would be like the followings: 
<programlisting language="java">
GermaNetImplementation germaNet = new GermaNetImplementation(); 

String lemma = "beautiful";  
PartOfSpeech pos = new GermanPOS("adjective"); 

// query for synonym of "Beautiful"
GermaNetRelation rel1 = new GermaNetRelation(WordNetRelation.SYNONYM); 
germaNet.getRulesForLeft(lemma, pos, rel1); 

// query for NONENTAILMENT terms to "Beautiful" 
GermaNetRelation rel2 = new GermaNetRelation(TERuleRelation.NONENTAILMENT);
germaNet.getRulesForLeft(lemma, pos, rel2); 

String lemma = "apple";  
PartOfSpeech pos = new GermanPOS("noun"); 

// query for ENTAILMENT and hypernym of "apple"
GermaNetRelation rel3 = new GermaNetRelation(TERuleRelation.ENTAILMENT,
                                             WordNetRelation.HYPERNYM);
germaNet.getRulesForLeft(lemma, pos, rel3); 
</programlisting> 
</para> 

</section> <!-- end of RelationSpecifier --> 
</section> <!-- end of Example subsubsection --> 

<!-- commented our, replaced by LexicalResourceWithRelation 
<section id="LexicalResource_OwnRelation">
<title>interface <code>LexicalResourceWithOwnRelation</code> </title>
<para>
<code>public interface LexicalResourceWithOwnRelations&lt;I extends RuleInfo, R extends java.lang.Enum&gt; extends LexicalResource&lt;I&gt;</code>
</para>

<para>
Motivation: The <code>LexicalResource</code> (<xref
linkend="sec-4.5.2"/>) interface defines a canonical method of
querying and getting lexical relations between words. The interface
allows users to retrieve lexical terms that are entailed by (or
contradictory to) the given term. This abstraction is useful in the
sense that it abstracts various underlying lexical resources with
entailment relation. This enables the caller of
<code>LexicalResource</code> implementations to query various
knowledge resources in the same fashion. 
</para>

<para>
However, this comes with a price: the <code>LexicalResource</code> interface
cannot provide querying capability of finer, resource-dependent
relations, since the implementations for individual resources map the
resource-dependent relations onto entailment and
non-entailment. Consequently, users cannot query WordNet for WordNet
relations (e.g. hypernymy, meronymy), or query VerbOcean for VerbOcean
relations (e.g. stronger-than, happens-before). These fine-grained
relations are reported back as part of query result, (<code>RuleInfo</code>
within <code>LexicalRule</code>), but cannot be directly asked for.
</para>

<para>
<code>LexicalResourceWithOwnRelations</code> is defined to recover this
capability. It permits lexical resource implementers to define query 
methods that use fine-grained relationships that are specific to a
resource. The interface extends <code>LexicalResource</code>, and adds three
methods. Essentially, they replace the argument of canonical relation
(<code>TERuleRelation</code>) to resource-specific local relation. 
</para>
<itemizedlist>
<listitem>

<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRulesForLeft(String lemma, PartOfSpeech pos, R fineGrainedRelation) throws LexicalResourceException;</code> 
</para>
</listitem>
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRulesForRight(String lemma, PartOfSpeech pos, R fineGrainedRelation) throws LexicalResourceException;</code> 
</para>
</listitem>
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRules(String leftLemma, PartOfSpeech leftPos, String rightLemma, PartOfSpeech rightPos, R fineGrainedRelation) throws LexicalResourceException;</code> 
</para>
</listitem>
</itemizedlist>

<para>The return values of the added queries are lists of <code>LexicalRule</code>,
identical to that of <code>LexicalResource</code>.
</para>

<para>
Note that <code>fineGrainedRelation</code> is an enum. Java Enum does not permit
inheritance, but all enums are implicit extension of
<code>java.lang.Enum</code>. Any normal enum can be parametrize the <code>R</code> of this
interface. Each resource implementation needs to provide this enum
class. For example, a lexical resource based on WordNet might be
parameterized with two classes like the following: 
<code>class WordNetResource implements LexicalResourceWithOwnRelation  &lt;WordNetInfo, WordNetRelation&gt;</code> , where <code>WordNetInfo</code> is an extension
of  <code>RuleInfo</code>, and <code>WordNetRelation</code> is an enum that holds WordNet 
relations. 
</para>

<para>
Note that, an EDA can still access an implementation of
<code>LexicalResourceWithOwnRelation</code> with <code>LexicalResource</code> interface,
since it is an extension of <code>LexicalResource</code>. 
For the above example, <code>LexicalResourceWithOwnRelation&lt;WordNetInfo,WordNetRelation&gt;</code>
is a <code>LexicalResource&lt;WordNetInfo&gt;</code>. 
</para>

<para>
Remarks about conformance: all lexical knowledge components must
implement <code>LexicalResource</code>.  It is recommended that lexical knowledge
components which wrap resources with fine-grained lexical relations
(like WordNet and VerbOcean) implement
<code>LexicalResourceWithOwnRelations</code>. Components that are based on 
simpler resources (like distributional lexical knowledge component)
are not expected to implement this interface. 
</para>
</section> --> <!-- end of subsection LexicalResourceOwnRelation --> 






</section> <!-- end of Interface of lexical knowledge components -->

<section id="sec-4.6">
<title>Interface of syntactic knowledge components </title>

<!-- <para> -->
<!-- This section deals with syntactic knowledge (for example, tree -->
<!-- rewriting rules). The basic unit of knowledge is a -->
<!-- <code>SyntacticRule</code>. A collection of such rules is described -->
<!-- by the interface <code>SyntacticResource</code>.  -->
<!-- </para> -->

<para> 
Some entailment relationships cannot be described well at the lexical
level, but require access to the syntactic level. Examples include
changes of verb voice, changes in a predicate's argument structure, or
proper paraphrase.
</para> 

<para> 
In the EXCITEMENT platform, we call syntactic level knowledge
<emphasis>syntactic rules</emphasis>, and a collection of such rules
with standard access methods a <emphasis>syntactic
rulebase</emphasis>. Similar to lexical rules, syntactic rules also
have two sides (LHS and RHS) and define the relationship between the
them (for example, LHS entails RHS, or LHS does not entail
RHS). Unlike in the case of lexical knowledge, each side (LHS / RHS)
is defined as a partial parse tree. The figure <xref
linkend="syntactic_rule1"/> shows a simple example.
</para> 

<figure id="syntactic_rule1">
<title>Example of a syntactic rule</title>
<mediaobject>
<imageobject>
<imagedata fileref="./figures/syntactic_rule_example1.jpg"
	   scalefit="1" width="85%" align="center"/> 
</imageobject>
</mediaobject>
</figure> 

<para> In the figure, two partial parse trees represent a simple
syntactic rule. The rule is about replacing "Microsoft acquires Yahoo"
to "Microsoft buys Yahoo". Note that both LHS and RHS are represented
as partial parse trees, which need to be matched with concrete input
parse tree. For example, the LHS will match the following sentence;
"Following the decisions of the new CEOs, Microsoft will acquire Yahoo
soon.", since the parse tree of the sentence has the partial parse
tree of the LHS. </para>

<para> Application of a syntactic rule takes place by replacing the
matched partial parse tree of the sentence to that of RHS. The rule
described in the figure will replace the verb with two arguments, and
declares that the rewritten tree has entailment relationship with
original tree. One can visualize a syntactic rule as a parse tree
rewriting rule with entailment relationship declaration. </para>

<para> A syntactic rule also has two additional fields that does not
exist in a lexical rule: variables and mappings. The following 
figure (<xref linkend="syntactic_rule2"/>) demonstrates them.</para> 
<figure id="syntactic_rule2">
<title>Variables and mappings of an syntactic rule instance</title>
<mediaobject>
<imageobject>
<imagedata fileref="./figures/syntactic_rule_example2.jpg"
	   scalefit="1" width="85%" align="center"/> 
</imageobject>
</mediaobject>
</figure> 

<para>A variable is a parse tree node that can match any dependency
(sub)tree whose root node matches its part of speech constraint. For
example, the LHS of the figure contains two variables. It matches any
dependency tree that contains an instance of the verb 'acquire' whose
subject and direct object are both proper nouns (POS: NP). Note that
these proper nouns can have arbitrary modifiers. Clearly, the
introduction of variables is crucial for the ability to represent
generalizable lexical-syntactic rules.
</para>   

<para>Correspondences between LHS and RHS nodes are established through
a bidirectional mapping. It specifies how the variable nodes of the
source tree will be copied into the target tree. The semantics of the
rule are that the complete dependency trees rooted in variable nodes
must be copied to the corresponding variable nodes in the target tree.
For example, consider the sentence "Software giant Microsoft acquired
Yahoo". If only the variable nodes themselves were copied, the result
would be "Microsoft bought Yahoo". 
</para> 

<section id="sec-4.6.1">
<title>Type <code>SyntacticRule</code> </title>
<para>
<!-- <code>public class
SyntacticRule&lt;Node,Node,BidirectionalMap&lt;Node,Node&gt;&gt;</code>
--> 
<code>public class SyntacticRule</code> 
</para>

<para>
The class represents an instance of a syntactic rule.
<!-- 
parametrized using two (potentially partially) lexicalized syntax
trees of type <code>Node</code> which are called as the left hand side
(LHS, original subtree) and the right hand side (RHS, the rewritten
subtree, which semantically entails the LHS). A third parameter is a
mapping that aligns nodes between the LHS and RHS to express
dependencies between the two structures. --> 
</para>


<section id="sec-4.6.1.1">
<title>Variables and access methods </title>
<itemizedlist>
<listitem>

<para><code>BasicNode leftHandSide</code>: LHS of this rule. A parse
tree represented with <code>BasicNode</code> objects. The value is set
by the constructor, and can be read by <code>getLeftHandSide()</code>.
</para>
</listitem>
<listitem>
<para><code>BasicNode rightHandSide</code>: RHS of this rule. A parse
tree represented on the basis of <code>BasicNode</code> objects.
</para>
</listitem>
<listitem>
<para><code>BidirectionalMap&lt;BasicNode,BasicNode&gt; mapNodes</code>: a bidirectional mapping between two parse tree nodes of type <code>BasicNode</code>. 
</para>
</listitem>
<!-- TODO? : add isExtraction ? --> 
<!-- no relation type in syntactic rule --> 
<!-- <para><code>TERuleRelation relation</code>: This variable holds an -->
<!-- enum value of <code>TERuleRelation</code> (<xref -->
<!-- linkend="sec-4.5.1.2"/>). It holds one of <code>Entailment</code> or -->
<!-- <code>NonEntailment</code>.  -->
<!-- </para> -->
<!-- <para><code>DecisionLabel relation</code>: This variable holds an enum -->
<!-- value of <code>DecisionLabel</code>(<xref linkend="sec-4.2.1.6"/>). It -->
<!-- is expected that only the top enum values of the enum hierarchy -->
<!-- (<code>Entailment</code> and <code>NonEntailment</code>) are used in -->
<!-- this variable. -->
<!-- </para> -->
</itemizedlist>
<para>
For each variable, a corresponding access method should be provided
(for example, getMap(), etc). If possible, the object should be
immutable (all variables as private final) so that values can be only
set by the constructors.
</para> 

</section>

<section id="sec-4.6.1.2">
<title>Related Objects </title>
<itemizedlist>
<listitem>

<para><code>BidirectionalMap&lt;K,V&gt;</code>: A map similar to
normal hash map, but it also has back-links to model a bidirectional
mapping. The specification does not specify the
implementation. Existing code is available from Apache commons,
Google, and the BIUTEE infrastructure.
</para>
</listitem>
<listitem>
<para><code>BasicNode</code>: This class represents a generic node in
a dependency parse tree. The specification adopts BIUTEE's syntactic
representation as common EXCITEMENT syntactic representation. It is
described in the next section.
</para>
</listitem>
</itemizedlist>

<para>
Note that the class <code>SyntacticRule</code> is described here
without the generic parameters. But it must be a generic class that is
parameterized by <code>BasicNode</code> and its related objects. The
generics are omitted here for the readability. 
</para> 
</section>

<section id="BasicNode">
<title>Basic Node: Common representation for dependency parse
tree</title>
<para>
To share a common representation for syntactic knowledge, a shared
syntactic representation is required.  The class
<code>BasicNode</code> provides the common syntactic representation of
EXCITEMENT. It represents a dependency parse tree node, linked to
other parse tree nodes. By acquiring the top node, it can also
represent a parse tree, or a partial parse tree.  </para>

<para>
The term "basic" hear means that it contains only the basic
information - information that is common to almost all languages. It
does not contain information that appear only on some languages like
grammatical role, morphological form, etc. It is expected that
specific language nodes will be implemented by extending the
<code>BasicNode</code>.  
</para> 

<para> <xref linkend="basic_node"/> gives a graphical overview of the
basic node. 
</para> 

<figure id="basic_node">
<title>Contents of a basic node</title> 
<mediaobject>
<imageobject>
<imagedata fileref="./figures/basic_node.jpg" scalefit="1" width="85%"
	   align="center"/> 
</imageobject>
</mediaobject>
</figure>

<para> 
A node basically holds two sets of member variables. One is about tree
itself (parent-children relation), and the other is information on
edges and nodes. 
<itemizedlist>
<listitem>
<para><code>children</code>: this member variable holds an array of
child nodes. They are nodes of the same type. Note that the node does
not explicitly keep its parent. </para> 
</listitem>
<listitem>
<para><code>antecedent</code>: this member variable holds a reference
to "duplicated node" in the dependency tree. For example, in a
sentence like "He managed to go", it is possible to generate a
duplicated node "He". The antecedent field of the duplicated one will
point the original node. 
</para> 
</listitem>
<listitem>
<para><code>info</code>: this member variable holds various
information of its edge (incoming edge from the parent), and the node
content.</para> 
</listitem> 
</itemizedlist>
</para> 
<para> 
The member <code>info</code> consists of two parts:
<code>edgeInfo</code> holds information on edge, and
<code>nodeInfo</code> has node content. <code>edgeInfo</code> holds
the following information.

<itemizedlist>
<listitem>
<para><code>relation</code>: this is an instance of data object that
represent the dependency relation. The instance holds two
variable. One is <code>itsStringRepresentation</code> that holds the
relation output of the dependency parser. And the other is
<code>type</code> which holds the an enum value that represents
dependency relationship. The enum <code>DependencyRelationType</code>
closely reflects the adopted UIMA dependency types (the subtypes of
<code>type.dependency.Dependency</code>).  
</para> 
</listitem>
</itemizedlist>

</para> 

<para> 
The <code>nodeInfo</code> holds the following information:
<itemizedlist>
<listitem>
<para><code>word</code>: this string holds the word (token) itself.</para> 
</listitem>
<listitem>
<para><code>lemma</code>: the lemma of this token</para> 
</listitem>
<listitem>
<para><code>namedEntity</code>: it holds a enum value that represents
a NER class. If this node is not a named entity, this value is
null. The enum type <code>NamedEntity</code> closely reflects the
adopted UIMA NER types (subtypes of
<code>ner.type.NamedEntity</code>). 
</para>
</listitem>
<listitem>
<para><code>syntacticInfo</code>: this variable holds information
about POS tag of this token. It holds two variables: the string output
of the POS tagger (<code>posTagString</code>) and the normalized POS
tag (<code>cannonicalPosTag</code>) that is equivalent to POS types of
UIMA CAS.</para>  
</listitem>
</itemizedlist>
Note that (not shown in the figure), <code>nodeInfo</code>
also provides two methods <code>isVariable()</code> and
<code>getVariableID()</code>. <code>isVariable()</code> method returns
true if and only if the node represents a variable of a syntactic
rule. If the node is a variable, <code>getVariableID()</code> returns
ID of the variable as an integer. (The ID is only for human readers
and rule visualizations -- actual rule matches and applications are
done by bidirectional mappings provided in the rule.) 
</para> 

<para> 
The <code>BasicNode</code> is implemented with two generic
parameters. One is the info type (that holds nodeinfo and edgeinfo),
and the other is node type itself (children and antecedent). Generic
parameters are omitted in the text paragraph for readability, but they
are described in the actual class code. 
<!-- appendix source code in <xref -->
<!-- linkend="c-6-BasicNode"/>.  -->
<!-- As the first version of implementation, -->
<!-- <code>BasicNode</code> and all related objects will be imported from -->
<!-- BIUTEE to the EXCITEMENT project.  -->
</para>


</section>
</section>

<section id="sec-4.6.2">
<title>interface <code>SyntacticResource</code> </title> 
<para> A syntactic resource is a collection of syntactic
rules. For syntactic rule collections, it is not practical to
provide simple access interfaces like <code>getLeftForPOS</code> for
lexical knowledge. Due to the exponential number of subtrees in any
text and hypothesis, naive querying based on the input is infeasible.
Instead, <code>findMatches()</code> method is defined to outline
common behavior of platform syntactic rules. </para>

<section id="sec-4.6.2.1">
<title>Methods </title>
<para>
<code>SyntacticResource</code> is a subinterface of
<code>Component</code> and adds the following method:
</para>
<itemizedlist>
<listitem>
<para><code> List&lt;RuleMatch&gt; findMatches(BasicNode currentTree)
</code>: The interface takes in a parse tree (which is represented in
common parse tree nodes). The rule base must return all possible rules
that can be applied into the tree, as a list of <code>RuleMatch</code> 
object. Note that the returned match holds information of not only
rules (instance of <code>SyntacticRule</code> but also the location
of the place where the rule should be applied to. The implementation
must return an empty list (not <code>null</code>), if no applicable
rules are found. </para> 
</listitem>
<listitem>
<para><code>List&lt;RuleMatch&gt; findMatches(BasicNode textTree,
BasicNode hypothesisTree)</code>: This overloaded version of
<code>findMatches</code> method gets two trees instead of one. The two
trees are text and hypothesis tree, and the method tries to find
matches such that LHS matches the text tree and RHS matches the
hypothesis tree. 
</para>
</listitem>
<listitem>
<para><code>void close()</code>: this method enables the
implementation to gracefully close underlying system resources (files, 
database connections, etc). Users of syntactic and lexical resources
are expected to call close() when the resource is no longer needed.   
</para>
</listitem>
</itemizedlist> 

<para> The overloaded second method is provided for efficiency. Since it
might be too expensive to find and apply all possible matches, the
overloaded method only returns the rules that also match the
hypothesis. This way, the user of the knowledge base can applies rules
that directly make the text more similar to the hypothesis. The
drawback of this approach is that it misses some rules that can make
text more similar to hypothesis. For example, it will miss cases where
subsequently applying two or more rules that make text more similar to
hypothesis.   
</para>
</section> 

<section id="sec-4.6.2.3">
<title>Related Objects </title>
<para>
<itemizedlist>
<listitem>
<para><code>RuleMatch</code>: this simple object represents a match of
a syntactic rule on a parse tree. It has two variables. Member variable
<code>rule</code> is a <code>SyntacticRule</code>, which holds the
rewriting rule. The other variable <code>mapLHStoTree</code> is a
bidirectional mapping of <code>BasicNode</code>. The variable holds
mapping info between each LHS node of the <code>rule</code> and the
corresponding node of the input parse tree. 
</para>  
</listitem>
</itemizedlist> 
</para> 
</section> 

</section> 
</section>

<section>
<title>Concurrent Processing </title>
<section>
<title>The issue of concurrent processing </title>
<para>
Modern computer hardware is very well prepared for concurrent and
parallel processing. Even modest PCs now have multiple cores with
multithreading capability. Given users' requirements of quick or even
real-time processing, it is important that the EXCITEMENT platform
supports concurrent processing.
</para>

<para>
The EXCITEMENT architecture (as seen in <xref
linkend="Entailment_Core"/>) can incorporate concurrent processing at
two different levels. We will call them concurrent component
execution, and concurrent EDA execution. They have different
advantages and disadvantages.
</para>

<para><emphasis>Concurrent component execution</emphasis>. Imagine an
EDA that requires the results of three sub-components for its
entailment decision (a typical situation for TIE or EDITS). Without
concurrent processing, the EDA must call three sub-components
sequentially and has to postpone its decision to when all three
results are available. Concurrent component execution can reduce the
total running time by reducing the time needed to produce a single TE
decision.
</para>

<para><emphasis>Concurrent EDA execution</emphasis>. Imagine an EDA
which must process a set of textual entailment problems. If the time
needed to process the set is <code>n</code>, we can reduce the
required time to <code>n/m</code> by running <code>m</code> threads
for the EDA. This level of concurrency will reduce the time to produce a
<emphasis role="bold">set</emphasis> of TE decisions by concurrent
processing of the selected EDA. 
<!-- Gil: I changed the sentence. removed "independent multiple EDAs"  
Note that single engine runs multiple threads, it isn't multiple
engines. Running multiple engine is never discussed in anywhere.--> 
 
<!-- Gil: explained it in the e-mail ... 
[SP: Can different EDA instances re-use the
same components if they are thread-safe? That would require a "global
state" shared among several EDAs. Well, maybe not - we can imagine a
class method Component.getInstance() which checks whether it already
has an instance of itself or, if not, builds one. That would make it
possible to share components among EDAs. ]
--> 
</para>
</section>

<section>
<title>Our approach on concurrent processing </title>
<para>We have decided on the following contract for concurrent
processing.
</para>
<itemizedlist>
<listitem>

<para>All components must declare clearly whether they are
<emphasis>thread-safe</emphasis>: If a module is thread-safe,
instances of this module can be called from multiple threads. If it is
not thread-safe, each thread needs its own instance. Thus,
each component provider must carefully document the thread safety. We 
have adopted a Java annotation for this (<code>@ThreadSafe,
@NotThreadSafe</code>, see <xref linkend="code_annotations"/>). 
<!-- Gil: checked [SP: please check reformulation] --> 
</para>
</listitem>
<listitem>
<para>No additional interface for concurrent component execution: We
decided that running components concurrently is the responsibility of
the EDA. Thus, we do not define additional concurrent interface for
components. Once the preparation of multiple threads for concurrent
component calling is handled by the EDA code, no additional interface
is needed on the component side. Whether an EDA calls a component
concurrently or sequentially, it will use the same interface. Having
thread-safety correctly marked for the component is sufficient.  
</para>
<para>
Amount of memory and number of CPU cores would be limiting factor for
general concurrent running. To help our users, each EDA should clearly
document its memory requirement for each run, also with regards to the
input size, and number of concurrent runnings. With this information
documented,  the users will be able to prepare a good configuration. 

<!-- Gil: short paragraph added,  
the followings questions are answered 
via an e-mail.--> 
<!-- [SP: memory consumption is not mentioned here although it will -->
<!-- probably be a major issue for many end users. Let's spend a paragraph -->
<!-- on discussing this point.... Let me see if I have the right -->
<!-- understanding. (1) If a component is thread safe, then using multiple -->
<!-- instances of it carries a relatively small overhead. (2) If a -->
<!-- component is not thread safe, then using n instances will lead to -->
<!-- n-time memory consumption. (3) using m EDAs concurrently will in -->
<!-- principle also lead to m-time memory consumption - however if -->
<!-- components can be shared, the practical overhead will be lower. Is -->
<!-- that correct?] -->
</para>
</listitem>
<listitem>
<para>An interface for concurrent EDA execution: Concurrent
processing of multiple TE problems needs a new interface. The EDA
interfaces defined in <xref linkend="sec-4.2"/> only process a single
TE problem. The new interface makes it possible to process a set of TE
problems concurrently, returning multiple decisions. The interface is
defined in the next subsection. 
<!-- Gil: checked [SP: please check reformulations] --> 
</para>
</listitem>
</itemizedlist>
</section>

<section id="EDAConcurrentProcessing">
<title><code>interface EDAConcurrentProcessing</code> </title>
<para>
The goal of this interface is to provide an access method for EDAs
(and/or EDA wrappers) that can process a set of entailment decision
problems concurrently.
</para>

<para>
<code>List&lt;TEDecision&gt; processDataSetConcurrently (List&lt;JCas&gt; casList)</code> 
</para>

<para>
The interface receives a set of TE decision problems as a list of
JCAS. Each CAS object holds an entailment problem (as defined in <xref
linkend="TETypes"/>). The result is returned as a list of
<code>TEDecision</code> objects. The interface is not an asynchronous
interface: it will block until it process all the given problem list,
and return the results only after all processing is done.
</para>

<para>
The expected behavior of implementation of this interface is to
process the given dataset concurrently with a number of threads, using
general Java concurrent capabilities like Executors and thread
pools. The number of threads and other configurations should be
defined in the common configuration. Proper initialization (for
example, initializing multiple instances for non thread-safe
components) should be ensured by the implementation so that the user
does not need to care about sub-components and how they are being
run. 
<!-- Gil: checked [SP: check reformulations]-->
</para>

<para>
This interface can be directly implemented by an EDA (i.e., a class
that already implements EDABasic and/or other interfaces). It can be
also implemented by a concurrent running wrapper (a "runner") for the
EDA, if the implementation of this interface does not lend itself
naturally to the internal structure of the EDA.
</para>
</section>

<section>
<title>Future enhancements </title>
<para>The WP3 members have agreed that we will approach this issue
with incremental steps. We can imagine a set of future improvements
including:
</para>
<itemizedlist>
<listitem>
<para>Asynchronous interfaces 
</para>
</listitem>
<listitem>
<para>Generic concurrent "runner" that can run any single-thread EDA of
<code>EDABasic</code> with multiple EDA instances. 
</para>
</listitem>
<listitem>
<para>Different concurrent approaches for multiple text and/or multiple
hypothesis cases. 
</para>
</listitem>
</itemizedlist>

<para>Additional concurrent processing supports will be realized as the
platform matures. 
</para>
</section>
</section>

<section>
<title>Initialization and metadata check</title>
<para>
</para>

<section id="sec-4.7.1">
<title>Recommended policy on metadata check</title> 
<para> Recall that a central goal of the EXCITEMENT platform is to
provide a testing ground for various pluggable components that decide
textual entailment. This is done by providing a set of common
interfaces, and common data representations. Another requirement is to
provide multilingual support. </para>

<para> From this perspective, compatibility check becomes a necessity,
since components do not know in what context they are being
called. Each component should provide a minimum level of compatibility
check, on its configurations as well as on its inputs. This subsection
describes recommended policy of metadata checking for the EDA, the
core components, and between the EDA and the core components.
</para>

<para> Compatibility checks can be classified into two groups. One is
<emphasis role="bold">checks at startup time</emphasis> (configuration
setting and initialization time). The other is <emphasis
role="bold">checks at data processing time</emphasis>. The general
guideline is that EDAs should do both types of checks, and components
should at least do the startup time check. </para>

<para> An EDA must perform a compatibility check at its initialization
time. This is a two-step process. First, it should check the provided
configuration and check that the provided configuration is compatible
with the EDA. For example, the language to be processed is supported,
and parameters of the EDA is valid, etc. Second, the EDA must
initialize its direct components (components that will be directly
called by the EDA). Each component, in turn, will do their own checks,
using the information from the common configuration file (or
equivalent arguments). Likewise, if a component uses a
sub-component, it will also initialize the sub-component. </para>  

<para> Thus, two types of metadata check failure can happen at the EDA
initialization time. First, the EDA itself can report an exception,
like inability to process a certain language, inability to provide a
mode (like multi-text entailment), missing parameters, etc. The
sub-components of the EDA can report exceptions as well. In this case,
the EDA must hand through the exception to the user code. Thus, the
successful completion of the EDA initialization must be interpretable
to mean that all sub components are successfully initialized and are
ready to process input. </para>

<para> An EDA must also perform a compatibility check at the data
processing time, when its <code>process</code> method is called. The
input to EDA <code>process()</code> is a CAS (as JCas object). EDA
must check the validity of the input. At least two things should be
checked, namely its language (meta data at document annotation type of
CAS), and the existence of the analysis layers required by the
components (like POS tagging, or dependency parsing, etc).
</para>

<para> Components do not need to do additional checks at the process
time. Once a component is properly configured and initialized with a
configuration, it is the EDA's responsibility to use the component
properly within its capabilities. However, a component may choose to
provide meta data checking at processing time. </para>
</section>

<section id="reconfigurable">
<title>Interface <code>Reconfigurable</code></title>
<para>
Some components may need the ability to reconfigure. For example, a
user of a distance calculation component may wants to compute 10
distance values, by using 10 different "weighting schemes" using the
same underlying distance calculation component. One way of doing this
would be to generate ten instances of the same component. However,
this might not be desirable (e.g. if the component does not permit
more than a single instance, or if the initialization of the component
takes a lot of time). </para>
<para>
The interface <code>Reconfigurable</code> provides a way to modify the
component configuration at runtime. The term "reconfiguration" here
means changing some of the configurable parameters of a component,
without re-initializing all resources, or changing other settings that
may remain constant.
</para> 

<para>Any entailment core component that supports reconfiguration
should implement this capability though this interface. This also
includes EDAs. If EDA needs to support online reconfiguration, it
should support the capability with this interface. Note that when an
EDA provides this interface, the EDA should also update the states of
its sub-components according to the configuration method argument. It
is the responsibility of EDA implementers to ensure that configuration
changes are handed through to sub-components, if applicable. This may
mean simply reconfiguring some sub-components (which support this) and
re-initializing others (which do not). 
<!-- Gil:checked [SP: check revision] --> 
</para>  

<section>
<title>Methods of Interface Reconfigurable</title> 
<para><code>public void reconfigure(CommonConfig config)</code>
</para> 

<para>The interface provides a single method,
<code>reconfigure()</code>. The method gets the same single argument
(an instance of <code>CommonConfiguration</code>), but the contract is
different to first-time initialization. Instead of initializing all of
the passed configuration value, the implementation must check the
passed configuration and only reconfigure the changed values.   
</para> 

<para>Note that it is the component's responsibility to check the
consistency of the passed configuration value. If the passed value is
inconsistent (for example, configuration values that cannot be
reconfigured are different from the one given at the first
initialization), the implementation should raise an exception. Also,
any component that supports this interface must clearly state in its
documentation which configuration parameters are reconfigurable, and
which are not. 
</para> 
</section> 
</section>

<section id="sec-4.7.3">
<title>Component name and instance name</title>
<para> <!-- All entailment core components and EDAs provide
<code>initialize()</code> methods. Components may provide the
<code>reconfigure()</code> method as well. The methods uses a
<code>CommonConfig</code> instance as the argument. --> 
The central configuration scheme assumes that each component knows its
own name, and it can retrieve corresponding configuration data from
common configuration by querying the configuration with its name. 
</para> 

<para><emphasis>Component name</emphasis> is a <code>String</code>
value that is designed to be read and written by users. This name must
be able to uniquely identify a component or EDA within the EXCITEMENT
framework. This name will be used in the configuration files to denote
a section that describes the configuration for the component. All
entailment core components and EDAs must have this component name
string. Conversely, for each component that is initialized there must
be a corresponding subsection in the configuration file. The
components share a common way of access the names (<code>String
getComponentName</code>). To see the use case of names within
configuration interface, see <xref linkend="sec-5.1"/>.
</para>

<para><emphasis>Instance name</emphasis> is a <code>String</code>
value that is needed for components that permits <emphasis>multiple
instances with different configurations</emphasis>. This name will be
used in the configuration files to denote a subsection that describes
the configuration for the instance. Conversely, for each instance that
is initialized there must be a corresponding subsection in the
configuration file. The components share a common way of access the
names (<code>String getInstanceName</code>). 
<!-- To see the use case of
names within configuration interface, see <xref
linkend="sec-5.1"/>.--> 
Note that this string can be null if and only if the component does
not permit multiple instances with different configurations. 
</para>

<para>
The specification do not describe how the name are stored internally
in the component implementations. It is expected that the platform
implementation efforts will come up with a common best practice to
keep the names in component implementations.
</para> 
  
</section> 


</section> <!-- end of 4.7 -->  

<!-- start of context sensitive lexical resource --> 
<section id="context_sensitive_lexical_resource">
<title>Context Sensitive Lexical Resource</title>
<section>
<title>Basic requirements</title>
<para>The lexical resource interface (<code>LexicalResource</code>) is imported from 
BIUTEE to EOP, and it is well-tested by both BIUTEE and other EOP
EDAs. It is expanded to include "resource-specific" relations
(LexicalResourceWithOwnRelation) if a resource can support, and
currently the interfaces are quite stable. 
</para>

<para>
However, the interfaces are not providing any means of passing the
context from EDA to the resource. Thus, the existing interfaces are
not adequate to represent "context-sensitive" lexical resource. So we
need to define one extension that permits context-passing, and all
related matters. 
</para>

<para>
Let's briefly outline current assumptions and requirements before
outlining the actual interface.  
</para>
<itemizedlist>
<listitem>
<para>We use the same return type: no change on the result of the queries
  (list of LexicalRule).    
</para>
</listitem>
<listitem>
<para>We make this interface as an "extension" interface. A resource
  still needs to provide basic LexicalResource interface. The new
  interface adds an additional set of methods that can behave
  "context-sensitive" mode. 
</para>
</listitem>
</itemizedlist>
<para>
The followings are requirements, rather than assumptions. 
</para>
<itemizedlist>
<listitem>
<para>Form of context should not be limited: it can be anything. Thus,
  passing the T-H pair itself and all its annotations would be
  ideal.  
</para>
</listitem>
<listitem>
<para>Capability to pass "candidates" are highly desirable: context
  sensitive resource is not a static resource, and requires dynamic
  calculation. Thus, "limitation" of rule calculation target is very
  desirable for its efficiency. This can be done by passing a set of
  candidates that limits RHS or LHS. (e.g. limit RHS or LHS with this
  set of terms)  
</para>
</listitem>
<listitem>
<para>"position-only" query is also quite desirable. (I want to get
  a set of rules, if any, between term<subscript>a</subscript> in location<subscript>a</subscript> and
  location<subscript>b</subscript>. I don't care about what is the current term in
  location<subscript>b</subscript>. )  
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>Interface outline</title>
<para>The following interface outlines an interface that satisfies
all of the above assumptions and requirements. 
</para>
<section>
<title><code>Interface LexicalResourceWithContext extends LexicalResource</code></title>
<para>
The interface adds three methods to the usual <code>getRules</code>
family. Each added method (<code>getRulesLeft</code>, <code>getRulesRight</code> and
<code>getRules</code>) overrides those methods in the basic interface, with added
arguments that passes the context of the term in interest. Among the
three added methods, <code>getRules</code> is the most general (and powerful)
one that can pass two contexts (both of Text and Hypothesis), while
<code>getRulesForLeft</code> and <code>getRulesForRight</code> are dealing with one side.  
</para>
<section>
<title>method <code>getRules</code> family added by <code>LexicalResourceWithContext</code></title>
<para>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRules(String leftLemma,
PartOfSpeech leftPos, String rightLemma, PartOfSpeech rightPos, JCas
context, int lemmaLBegin, int lemmaRBegin,
List&lt;Tuple&lt;String,PartOfSpeech&gt;&gt; candidates) throws
LexicalResourceException;
</para>

<para>
Let's see the expected usage of the method with an example. The T-H
pair is given as the followings.
</para>

<para>
<programlisting>___01234567890123456789012345678901  -- CAS SOFA position
T: John walked his dog in the park.
H: John took his pet for a walk.
</programlisting>
</para>

<para>
Let's assume that a caller of the resource is interested in "dog" -
"pet" part of the T-H pair. The following examples all assumes this
case, with the above T-H pair.
</para>

<para>
Example #1:
<code>getRules("dog", noun, "pet", noun, aJCas, 16, 14, null);</code>
</para>
<itemizedlist>
<listitem>
<para>this call specifically asks the resource to check relationship
  between (dog, N) -&gt; (pet, N); in the context of the annotated T-H
  pair (JCas aJCas); position 16 of Text -&gt; position 14 of
  Hypothesis.
</para>
</listitem>
<listitem>
<para>(Note that candidate list is null, which basically means consider
  all candidates --- however, since lemma of both sides is given, list
  of candidates are not meaningful in this case. The resource will
  only consider dog -&gt; pet, within the context).
</para>
</listitem>
</itemizedlist>
<para>
Example #2:
<code>getRules("dog", noun, null, null, aJCas, 16, 14, candidates);</code>
where <code>candidates</code> are: <code>[ ("pet", noun), ("animal", noun),... (lemma_n, pos_n) ]</code>
</para>
<itemizedlist>
<listitem>
<para>This call asks the resource to check relation "dog" -&gt; candidates
  (which holds pet, animal, etc); in the context of annotated T-H pair
  aJCas; position 16 of T -&gt; position 14 of H.
</para>
</listitem>
<listitem>
<para>Note that, candidate is non-null; which dictates that the resource
  will consider only those candidates as possible "filler" of right
  lemma/pos (which are null).
</para>
</listitem>
<listitem>
<para>If the candidates variable is "null"; the resource will try to look
  for all rules "dog -&gt; (any word)": this might be a complex
  operation and the caller should expect slower process, compared to
  the candidate given call case.  
</para>
</listitem>
</itemizedlist>
<para>
Example #3:
<code>getRules(null, noun, null, noun, aJCas, 16, 14, candidates);</code>
where <code>candidates</code> are: <code>[ ("pet", noun), ("animal", noun),... (lemma_n, pos_n) ]</code>
</para>
<itemizedlist>
<listitem>
<para>This call asks the resource to check possible rules that can be
  used on the context of position 16 of text -&gt; position 14 of
  hypothesis, as nouns.  
</para>
</listitem>
<listitem>
<para>Note that both lemma are null, but the candidates are
  given. Thus, it will use all of the candidates, as possible filler
  for those null lemmas.
</para>
</listitem>
</itemizedlist>
<para>
Example #4:
<code>getRules(null, null, null, null, aJCas, 16, 14, candidates);</code>
where <code>candidates</code> are: <code>[ ("pet", noun), ("animal", noun), ... (lemma_n, pos_n) ]</code>
</para>
<itemizedlist>
<listitem>
<para>An extreme call case, where only the context is given (as the
  TH-pair and position) with a set of candidates.
</para>
</listitem>
<listitem>
<para>The resource will try to find rules that can fill (left -&gt; right),
  where left location and right location is known.
</para>
</listitem>
<listitem>
<para>The candidates are given in this case -- thus the resource will
  only regard those candidates as the possible 'fillers' for the
  positions.
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title><code>getRulesLeft</code> family added by <code>LexicalResourceWithContext</code></title>
<itemizedlist>
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRulesForLeft(String lemma,PartOfSpeech pos, JCas context, int lemmaLBegin,List&lt;Tuple&lt;String,PartOfSpeech&gt;&gt; candidates) throws LexicalResourceException;</code>
</para>
</listitem>
</itemizedlist>
<para>
Let's see some more examples for this case. Note that the methods
does <emphasis role="bold">not</emphasis> care about Hypothesis side, and it only sees Text
side. Thus, the meaning of a call is "what are the lexical rules that
replace the term in its own context?".  
</para>

<para>
<programlisting>___01234567890123456789012345678901  -- CAS SOFA position
T: John walked his dog in the park.
H: [ don't care ]
</programlisting>
</para>

<para>
Example #1. <code>getRulesForLeft("dog", noun, aJCas, 16, null)</code>
</para>
<itemizedlist>
<listitem>
<para>get me all rules that you know (note that null candidates), which
  can be ("dog/Noun" -&gt; term), in the given context of Text.
</para>
</listitem>
</itemizedlist>
<para>
Example #2. <code>getRulesForLeft("dog", noun, aJCas, 16, candidates)</code>
where candidates are: <code>[ ("pet", noun), ("animal", noun), ... (lemma_n, pos_n) ]</code>
</para>
<itemizedlist>
<listitem>
<para>get me rules where the possible candidates are given as
  <code>candidates</code>, on the term dog, as appears with the context given in
  aJCas Text part pos 16.
</para>
</listitem>
</itemizedlist>
<para>
Example #3. <code>getRulesForLeft(null, null, aJCas, 16, candidates)</code>
where candidates are: <code>[ ("pet", noun), ("animal", noun), ... (lemma_n, pos_n) ]</code>
</para>
<itemizedlist>
<listitem>
<para>get me rules where the possible candidates are given as
  <code>candidates</code>, that can be used in the aJCas pos 16. Note that this
  call does not specify lemma of left!
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title><code>getRulesRight</code> family added by <code>LexicalResourceWithContext</code></title>
<itemizedlist>
<listitem>
<para><code>List&lt;LexicalRule&lt;? extends I&gt;&gt; getRulesForRight(String lemma,PartOfSpeech pos, JCas context, int lemmaRBegin,List&lt;Tuple&lt;String,PartOfSpeech&gt;&gt; candidates) throws LexicalResourceException;</code>
</para>
</listitem>
</itemizedlist>
<para>
Let's see some more examples for this case. Note that the methods
does <emphasis role="bold">not</emphasis> care about Text side, and it only sees the Hypothesis
side. Thus, the meaning of a call is "what are the lexical rules that
can applied to the term in its own context?".  
</para>

<para>
<programlisting>___01234567890123456789012345678901  -- CAS SOFA position.
T: [ don't care ]
H: John took his pet for a walk.
</programlisting>
</para>

<para>
Example #1. <code>getRulesForRight("pet", noun, aJCas, 14, null)</code>
</para>
<itemizedlist>
<listitem>
<para>get me all rules that you know (note that null candidates), which
  can be valid as (term -&gt; "pet/Noun"), in the given context of the
  Hypothesis.  
</para>
</listitem>
</itemizedlist>
<para>
Example #2. <code>getRulesForRight("pet", noun, aJCas, 14, candidates)</code>
where candidates is: <code>[ ("dog", noun), ("cat", noun), ... (lemma_n, pos_n) ]</code>
</para>
<itemizedlist>
<listitem>
<para>get me rules where the possible candidates are given as
  <code>candidates</code>, on the target term "pet" as appears with the context
  given in aJCas Hypothesis pos 14.
</para>
</listitem>
</itemizedlist>
<para>
Example #3. <code>getRulesForRight(null, null, aJCas, 14, candidates)</code>
where candidates is: <code>[ ("dog", noun), ("cat", noun), ... (lemma_n, pos_n) ]</code>
</para>
<itemizedlist>
<listitem>
<para>get me rules where the possible candidates are given as
  <code>candidates</code>, that can be used in the aJCas Hypothesis pos 16. Note
  that this call does not specify lemma of left!
</para>
</listitem>
</itemizedlist>
</section>
</section>
</section>
</section>

<!-- end of context sensitive lexical resource --> 

<!-- start of phrase level resource --> 
<!-- 
<section id="phrase_level_resource">
<title>Phrase level knowledge resource</title>
<para>
TO BE ADDED
</para> 
</section>
--> 
<!-- end of phrase level resource --> 


<!-- start of annotator & alignment --> 
<section id="annotator_component">
<title>Annotator component</title>
<section>
<title>Description</title>
<para>As described in the section 3 (LAP and type system), EOP relies on CAS
as the main data structure to keep various levels of annotations. From
LAP level, they are generic language processing results like POS,
lemma, syntactic dependencies, NER, SLR and etc. As described in the
section, CAS type system can express (with new extensions and
additions of types), and add almost any data related to the input
pair.  
</para>

<para>
The expressive power of CAS and its annotations are not limited to
generic processing like parsing, or SLR. For example, consider a new
annotation type that annotates partial entailment relation, or
partial contradiction relations. Imagine that the component is able
to determine partial contradiction with some confidence. (say, the
time duration of the adverb phrase of the text cannot match another
adverb phrase in hypothesis, etc). This type of information should
be determined and passed to the total (full) entailment decision
algorithm. If we want to express such data, in a common way, which
would be the best within the platform? As annotations within CAS, is a
natural data type for such a component. The component analyzes the
given CAS, determines what the component is supposed to do, and add
what is determined by the component in terms of specific annotations
(e.g. in the above example, phrase level contradiction). 
</para>

<para>
We define this kind of component as a separate type of component, and
call it the Annotator component. An annotator component gets one CAS,
analyzes the given CAS and add additional information in forms
annotation. The added annotation gives extra information for EDAs,
which would help EDA's decision on entailment. 
</para>

<para>
What is the difference between a <code>AnnotatorComponent</code> and a LAP
component? It seems that both adds annotations in CAS. The following
list outlines the major differences. In general, we expect it would
be easy to figure out where a new annotation adding module to be
added. 
</para>
<itemizedlist>
<listitem>
<para>LAP components annotator provides generic annotations, such as POS,
  NER and syntactic structures. Annotator component provides more
  textual entailment specific annotations. 
</para>
</listitem>
<listitem>
<para>LAP annotates each view separately, each as a text. Annotator
  component annotate the given CAS as a T-H pair (or
  pairs). Annotator component treats the CAS as entailment pair data,
  not just two set of textual input. 
</para>
</listitem>
<listitem>
<para>LAP components belong to LAP. They cannot access CORE components
  like lexical or syntactic knowledge resources. Annotator component
  is part of CORE, and actively utilizes other CORE components. 
</para>
</listitem>
</itemizedlist>
<para>
We also define sub-types of Annotator component, to identify annotator
components by their types and roles. In the version 2.0 of the
specification, only the <code>AlignmentComponent</code> is the subtype of
<code>AnnotatorComponent</code>. 
</para>
</section>

<section>
<title>Interface <code>AnnotatorComponent</code></title>
<para>The interface defines only one method. 
</para>
<itemizedlist>
<listitem>
<para><code>public void annotate(JCas aJCas)</code>: the method gets one JCas. Once
  the annotate process is done, the given JCas enriched by the added
  layer of annotations. If the annotator component was not able to
  add annotations (for example, needed LAP annotation like lemma was
  missing, or some failure of activating resources, etc), the
  component must raise a proper exception. If the call is successfully 
  returned, it always means the process was successful --- even though
  there were no added annotations (e.g. contradiction annotator, but
  there was no contradiction). 
</para>
</listitem>
</itemizedlist>
</section>
</section>

<section id="alignment_component">
<title>Alignment component</title>
<section>
<title>Interface <code>AlignmentComponent</code></title>
<para>Alignment component is a sub-type of annotator component. The
component interface does not add any new method. This (empty)
interface is defined as an independent interface mainly to serve the
purpose of identifying alignment components among alignment
components. 
</para>

<para>
All components that implement <code>AlignmentComponent</code> <emphasis role="bold">must</emphasis> annotate
according to the specific CAS types that are designed for alignment
annotations within EOP, which are described in the following
section.  
</para>
</section>

<section id="alignment_cas_type">
<title>CAS types for Alignment annotation</title>
<para>Spec 1.1 defined <code>AlignedText</code> CAS type. The type had been designed to
express surface level of alignments (token, and phrase levels). The
simple type was good for those, but it is not appropriate for aligning
more complex annotations, such as nodes, trees, graphs, or any future
data that will be added for EOP CASes.  
In this section, we define a new, more general annotation types. The
new types are designed for alignment representation on any
annotations. 
</para>

<para>
The design goal for the new types are permitting maximum flexibility, 
while maintaining simple types that is generic enough. We define two
types for this. 
</para>
<itemizedlist>
<listitem>
<para><code>excitement.alignment.Target</code>
</para>
<itemizedlist>
<listitem>
<para>CAS annotation type that can point one or more annotations
    (tokens, parse nodes, NER nodes, or any annotations) 
</para>
</listitem>
<listitem>
<para>A list that groups annotations in one View.
</para>
</listitem>
<listitem>
<para>The purpose is to allow dynamic alignment of material, including
    structures made by multiple annotations. 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>excitement.alignment.Link</code>
</para>
<itemizedlist>
<listitem>
<para>CAS type that links two <code>Target</code>.   
</para>
</listitem>
<listitem>
<para>Multi-view type: a <code>Link</code> connects one target in T (<code>TextView</code>),
    the other target in H (<code>HypothesisView</code>). 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<para>
We make no assumptions regarding what annotations are aligned by
<code>Link</code> and <code>Target</code> annotations. One <code>Target</code> can be linked by an
arbitrary number of <code>Link</code>, also a <code>Target</code> can group an arbitrary
number of <code>Annotations</code>. Note that <code>uima.tcas.Annotation</code> is the
super type of almost all CAS annotation data. Since a <code>Target</code> can
group <code>Annotation</code>, it can group any type of annotations in CAS. 
</para>

<para>
You can find the formal definitions of the two CAS types in the
following sections. Their definitions are pretty straightforward, but
please take a look on "notes on usage" of each type for its begin-end
behavior, before using the types. 
</para>
<section>
<title><code>alignment.Target</code></title>
<itemizedlist>
<listitem>
<para>Name: <code>eu.excitementproject.type.alignment.Target</code>
</para>
</listitem>
<listitem>
<para>is-a: <code>uima.tcas.Annotation</code>
</para>
<itemizedlist>
<listitem>
<para>inherits feature <code>begin</code> and <code>end</code>
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>targetAnnotations</code> (<code>FSArray</code> [ <code>Annotations</code> ]): This is a
    <code>FSArray</code> that can hold one or more annotations. A target should
    mark one or more annotations 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>Note on usage
</para>
<itemizedlist>
<listitem>
<para><code>begin</code> holds the minimum <code>begin</code> value among annotations in
    <code>targetAnnotations</code>. 
</para>
</listitem>
<listitem>
<para>Likewise, <code>end</code> should point the maximum end among annotations. 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<section>
<title><code>alignment.Link</code></title>
<itemizedlist>
<listitem>
<para>Name: <code>eu.excitementproject.type.alignment.Link</code>
</para>
</listitem>
<listitem>
<para>is-a: <code>uima.tcas.Annotation</code> 
</para>
<itemizedlist>
<listitem>
<para>inherits feature <code>begin</code> and <code>end</code> 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>textSideTarget</code> (<code>aligment.Target</code>): this feature points one
    <code>Target</code> in <code>TextView</code>. Mandatory, and should not be null. 
</para>
</listitem>
<listitem>
<para><code>hypotehsisSideTaget</code> (<code>alignment.Target</code>): this feature points
    one <code>Target</code> in <code>HypothesisView</code>. Mandatory, and should not be
    null.  
</para>
</listitem>
<listitem>
<para><code>type</code> (<code>String</code>): a string that describe the type of the
    link. (e.g. "Lexical Alignment", "Dependency Sub-tree", etc). Note
    that we do not attempt to group types of different
    alignments. The <code>type</code> is merely a string, that identifies what
    kind of module added the link. 
</para>
</listitem>
<listitem>
<para><code>linkStrenth</code> (<code>Double</code>): a double value that ranges between [-1,
    1]. A plus-valued link means that this is a positive
    alignment. In TE context, this positive value means positive
    local entailment. The higher the value is, the more confident the
    annotator component is. Minus value means that this is a negative 
    alignment. That is, the annotator is confident that this cannot
    be a local entailment (essentially means local contradiction). 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>Note on usage
</para>
<itemizedlist>
<listitem>
<para>Indexing of the <code>Link</code> within CAS: All annotations must be
    indexed to the CAS or CAS Views to be accessible. By convention
    we define that a <code>Link</code> instance should be indexed on
    <code>HypothesisView</code>. So iteration over the <code>HypothesisView</code> will get
    all alignment <code>Link</code> instances within the CAS. 
</para>
</listitem>
<listitem>
<para><code>begin</code> and <code>end</code>: Also as a convention, both span values should
    hold the same value to that of <code>hypothesisSideTarget</code>. Again,
    this is also for generalizing accessing of <code>Link</code> instances. 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<section>
<title>Note on the deprecated old type</title>
<para>Please note that old <code>AlignedText</code> type is deprecated, and no longer
used. Even for surface level of alignments, <code>AlignmentComponent</code> must
only use <code>alignment.Link</code> and <code>alignment.Target</code>.  
</para>
</section>
</section>
</section>

<!-- end of alignment component --> 

<!-- start of interface trainable --> 
<section id="interface_trainable">
<title>Interface <code>Trainable</code></title>
<section>
<title>Description of the interface</title>
<para>A RTE system generally requires the process of training: actual
content of training can vary, but a working RTE engine requires
various parameters, or knowledge to make a good entailment
decision. Such parameters are normally acquired via a training data,
and then they are stored in a model. 
</para>

<para>
In the earlier versions of the specification (pre-2.0), the training
capability of RTE engine was only defined on the top level, on
EDA. EDA has <code>startTraining</code>, and <code>initialize</code>. The two methods
works with configurable values (in the form of common
configurations), and starts training with the given configuration and
generate a new model(<code>startTraining</code>), or load a pre-existing model
(<code>initialize</code>). 
This choice of top-level-only training is reasonable for systems where
there is only one entry point for training. For example, TIE, EDITs
and BIUTEE worked well with this setup. An instance of the EDAs only
uses one model per EDA (per EDA configuration). 
</para>

<para>
However, not all training behavior of RTE systems can be mapped with
this way. An example is alignment-based approach. Alignment is an
essential step for alignment-based RTE systems. This monolingual
alignment process can be expressed as a component (as explained in
annotation component) that can be used by multiple EDAs, or as of
aligner module itself. Which means that trained parameters of the
component is independent to a specific EDA, and it should be saved as
its own model. 
</para>
<para>
Our approach on "trainable component" is again minimal, similar to
our definition of the training method on EDA. We define a common
starting point for training. Each component that can produce a model
and training capability should implement the <code>Trainable</code>
interface. This interface provides a common entry point for
initiating the training process. Each training process (and their
required data) can vary greatly. Those varying options will be
provided in the configuration. 
</para>

<para>
Note that we do not define common model storage methods (e.g. what to
save, where to save, what kind of format the model file has,
etc). This is provided by each component, and each component that
provides this interface must document the required configurable values
in its JavaDoc documents. Thus, this interface only provides common
starting point for training. Although this is a minimal contract, the
interface enables several common behavior. 
</para>
<itemizedlist>
<listitem>
<para>All trainable components are recognizable with this interface. 
</para>
</listitem>
<listitem>
<para>Each trainable component shares the same starting point. Thus, when
  an EDA wants to train multiple <code>Trainable</code>
  component instances, it can do so with one valid common
  configuration and iterating over trainable components by calling the
  method provided by  <code>Trainable</code> interface.  
</para>
</listitem>
<listitem>
<para>The interface forces all <code>Trainable</code> to support Common-config. 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>Methods of the interface</title>
<para>The interface only provides one method. 
</para>

<para>
<code>void startTraining(CommonConfig configuration)</code>
</para>

<para>
Calling this method makes the component to start the training process,
as defined in the configuration values. Once the training process is 
finish, the method will return without any return value, but the
training result will be written in a designated position in the
configuration. 
</para>

<para>
Note that once <code>startTraining()</code> is finished, the component instance
does not need to comeback to "prediction (or work)" mode. For
example, let's assume we have an alignment component. Normal
(prediction) mode call would be <code>annotate()</code> method as defined in the
alignment component. However, Once <code>startTraining()</code> method is called
and model is saved via the method, the instance do not need to be
able to process further <code>annotate()</code> call. Component writers can
consider <code>startTraining()</code> as a one-way mode change command for the
component to training mode. This assumption is added to make actual
implementation of trainable components simpler. 
</para>

<para>
Also note that we do not provide <code>initialize()</code> method in this
interface, in contrast to <code>EDABasic</code> interface. 
</para>
</section>
</section>

<!-- end of interface trainable --> 



<!-- start of SDA --> 

<section id="SDA">
<title>Semantic Similarity Decision Algorithm</title>
<section>
<title>Description of the component</title>
<section>
<title>Semantic Textual Similarity task</title>
<para>Semantic Textual Similarity (STS) is a task of determining the
semantic similarity between a pair of textual data. The goal is
described as "given two textual input, find out the degree of semantic
equivalence between the two inputs." (<ulink url="http://ixa2.si.ehu.es/sts/">http://ixa2.si.ehu.es/sts/</ulink>) 
The task is related to both Textual Entailment and Paraphrase, but it
is different in a way. Unlike Textual Entailment, STS task is not
directional. For example, in TE, "a car" entails "a vehicle", but not
the other way around. In STS, it is a symmetric relation. Also, the
result of STS is graded similarity, not categorical decision (e.g. the
pair [riding a vehicle, riding a car] is more similar than [riding a
wave, riding a car]). 
</para>

<para>
STS task has been evolving with SemEval tasks, since 2012. (xref
SemEval-2012 Task 6). The task sets provide concrete training/test
set similar to RTE dataset. In the task data, the similarity degree
is represented in a (continuous) scale of real number between 0.0 
to 5. Degree of 0 means there is no relation at all, while degree of
5.0 represents semantic equivalence. 
</para>

<para>
STS is a separate task where its goal is different to TE
task. However, there are many potential of possible common
contributions. For example, the assumption of EDITS EDA is actually
based on similarity (e.g. if T and H are not related, they can't be
entailment), and many RTE systems and STS systems can actually share 
various common processing components (e.g. distance components)
and/or static components (e.g. knowledge resources). 
We believe that supporting STS systems within EXCITEMENT open
platform has potential of future collaboration and sharing of useful
components and modules that might benefit both communities. 
</para>
</section>

<section>
<title>Supporting STS system in EXCITEMENT platform</title>
<para>In the specification version 2.0, we start supporting STS systems by
first adopting the top level interfaces. 
By top level, it means the same level as EDA level. The following
figure shows the conceptual drawing of where the newly defined
top-level STS module lies. 
</para>

<figure id="sda_flow">
<title>Top level data flow of SDA</title> 
<mediaobject>
<imageobject>
<imagedata fileref="./figures/SDAflow.jpg" scalefit="1" width="90%" align="center"/>
</imageobject>
</mediaobject>
</figure>

<para>
The figure is very similar to the top level figures for
<code>EDABasic</code> interface. Text-pair is given to LAP, and the
LAP generates CAS output which holds the annotated pair. However,
instead of EDA, here comes the newly defined SDA (Similarity Decision
Algorithm). The SDA represents the STS task in the top-level abstract,
where the input is annotated pair data (in CAS), and the output is new
Similarity Score result data type that represents STS similarity
output (<code>SemanticSimilarityDecision</code>). 
</para>

<para>
One interesting aspect here is that we reuse the same CAS and same
data types. Note that some names in CAS assumes TE-style inputs (for
example, view names are designated as "Text", and "Hypothesis"), but
LAP-output is generally (almost always) neutral to the task. STS
systems simply can consider "Text" of input pair as "s1 (sentence
1)", and "Hypothesis" part as "s2 (sentence 2)". Note that most of
the LAP annotations are not aware of two views (text and hypothesis),
and task-neutral.  
</para>

<para>
Thus, CAS for EDA and SDA are almost identical. The only difference on
CAS level is the gold annotation that is required for training
part. EDA uses <code>gold</code> value annotated with <code>EntailmentPair</code> annotation
type. However, SDA does not utilize this gold value. Instead, there is
a new CAS type defined for SDA. <code>SemanticSimilarityPair</code>, which is an
extension of <code>EntailmentPair</code>, and holds <code>goldSimilarityValue</code> that
scales between 0 to 5. Note that We choose to extend
<code>SemanticSimilarityPair</code> from <code>EntailmentPair</code>, so on the processing
side (once the model is learned), SDA can share CASes that are
prepared for EDAs without any modifications. 
</para>
</section>
</section>

<section id="SDABasic">
<title>Interface SDABasic</title>
<para><code>public interface SDABasic&lt;T extends SemanticSimilarityDecision&gt;</code>
</para>

<para>
This interface supports basic capabilities for STS task. It defines 4
methods, similar to <code>EDABasic</code> interface. 
</para>
<itemizedlist>
<listitem>
<para><code>public void initialize (CommonConfig config)</code>: This method will be
  called by the top level programs as the signal for initializing the
  SDA. All initialization of an SDA like setting up sub-components and
  connecting resources must be done in this method. An SDA
  implementation must check the configuration and raise exceptions if
  the  provided configuration is not compatible. Initialize is also
  responsible for passing the configuration to common
  sub-components.  
</para>
</listitem>
<listitem>
<para><code>public T process (JCas aJCas)</code>: This is the main access point for
  the top level. The top level application can only use this method
  when the SDA is properly configured and initialized. Each time this
  method is called, the SDA should check the input for its
  compatibility. Within the EXCITEMENT platform, SDA implementations
  are decoupled with linguistic analysis pipelines, and you cannot
  blindly assume that CAS input is valid. SDA implementation must
  check  the existence of proper annotation layers corresponding to
  the configuration of the SDA. The similarity decision is returned as
  an object that extends <code>SemanticSimilarityDecision</code>  interface which
  essentially holds the similarity as a float value. 
</para>
</listitem>
<listitem>
<para><code>public void shutdown()</code>: This method provides a graceful exit for
  the SDA. This method will be called by top-level as a signal to
  disengage all resources. All resources allocated by the SDA should
  be released when this method is called.
</para>
</listitem>
<listitem>
<para><code>public void startTraining(CommonConfig c)</code>: startTraining interface
  is the common interface for EDA training. The interface signals the
  start of the training with the given configuration c. 
</para>
</listitem>
</itemizedlist>
<section id="semantic_similarity_decision">
<title>Type <code>SemanticSimilarityDecision</code></title>
<para>This interface represents the return value for <code>SDA</code> <code>process()</code>
results. It only holds the basic information, and SDA implementers are
expected to extend it to hold additional information for their SDA. It
defines two methods. 
</para>
<itemizedlist>
<listitem>
<para><code>public double getSimilarityValue()</code>: This method returns the
  similarity value decided by the SDA.  
</para>
</listitem>
<listitem>
<para><code>public String getPairId()</code>: This method returns Pair id as
  described in the CAS. 
</para>
</listitem>
</itemizedlist>
</section>

<section id="limit_of_SDA_in_2.0">
<title>Limitation of STS task support in the specification version 2.0</title>
<para>Please note that for the moment (ver. 2.0), we only have top-level
STS support only. The specification 2.0 is yet to resolve the
component reusing issue. It is not so simple to actually reuse
EXCITEMENT core components in SDA. This is because of the fact that
many component types implicitly assumes T -&gt; H directional
processing. For example, Lexical resources and Syntactic resources are
asymmetric from its very definition. (LHS entails RHS.) It is also
similar for Distance components: although this is not as explicit as
knowledge resources, but they also assumes directed distance from T to
H (e.g. edit distance from T to H with asymmetric calculation).   
</para>

<para>
How do we want to define and harmonize components to be reused in
both EDA and SDA? For example, do we want to additionally define
symmetric versions of lexical resources? This is an open issue
without easy answers. In the specification version 2.0, we do not try 
to resolve this issue yet. For the moment, we only provide top level
for STS with SDA interface.  
</para>
</section>
</section>
</section>

<!-- end of SDA --> 




</section> <!-- end of section 4 --> 


<!-- <section> -->
<!-- <title>Common Interfaces of Core Engine</title> -->
<!-- <para>{This section will hold everything related to the interfaces within core engine, including knowledge components. They will be divided into subsections}</para>  -->
<!--    <section> <title> Requirements of Core Components </title>  -->
<!--    <para> {To Be Written: How and why we decided on current interfaces} </para>    </section> -->

<!--    <section> <title> EDA (Entailment Decision Algorithm) Interfaces</title>  -->
<!--    <para> {TBA} </para>  -->
<!--    </section>  -->

<!--    <section> <title> Mode Helper Interfaces </title> -->
<!--    <para> {TBA} </para>  -->
<!--    </section>  -->

<!--    <section> <title> Interfaces of Distance Calculation Components</title>  -->
<!--    <para> {TBA} </para>  -->
<!--    </section>  -->

<!--    <section> <title> Lexical Knowledge Resource Interfaces</title> -->
<!--    <para> {TBA} </para>  -->
<!--    </section> -->

<!--    <section> <title> Lexico-Syntactic Knowledge Resource Interfaces</title>  -->
<!--    <para> {TBA} </para>  -->
<!--    </section> -->

<!-- </section> -->

<section> 
<title>Common Data Formats </title> 

<section id="sec-5.1">
<title>Common Configuration </title>

<section id="sec-5.1.1">
<title>Requirements of Entailment Core Common Configuration </title>

<para>In order to make an easy combination of EDAs and components
possible, the configurations of all entailment core components should
be stored and accessed in a uniform manner. A framework for the
EXCITEMENT common configuration must meet the following requirements:
</para>
<itemizedlist>
<listitem>
<para>The common configuration holds "all configurations for all things"
in the Entailment Core. 
</para>
</listitem>
<listitem>
<para>Its fundamental functionality is an attribute-value list (aka
hash table, aka dictionary) with typed values (Strings, Numbers).
</para>
</listitem>
<listitem>
<para>This configuration exist as an in-memory object, as well as in
human-readable and -modifiable file(s).
</para>
</listitem>
<listitem>
<para>Each individual module (EDA and components) can access the
provided in-memory configuration.
</para>
</listitem>
<listitem>
<para>Independence 1: Each component has a dedicated region in the
common configuration. A region means "a part of the configuration
object that is devoted to a component". Each region is unique and
unambiguous, and they are one-to-one relationship with core
components. Each region has its own namespace.  It should not be
affected by name-value pairs of other regions.
</para>
</listitem>
<listitem>
<para>
Independence 2: Components can change their own configuration over the
course of their runtime without having to update the central
configuration object. Thus, other components should avoid using the
configuration of a component to make assumptions about its runtime
configuration. This caveat explicitly does not apply to the
configuration of the LAP, which we assume to remain unchanged.
</para>
</listitem>
<listitem>
<para>Support for multiple instances: Some components need to be
deployed in multiple instances, with different configurations. The
common configuration should be able to support such cases.
</para>
</listitem>
<listitem>
<para>Support for global information: There is also a special "global"
region. This region does not correspond to a component, but defines
<emphasis>platform-wide</emphasis> options, like current language, the
selected top-level EDA, or other global options. Note: this section
does <emphasis>not</emphasis> hold information about selected
components; this information has its place within the EDA
section/subsection. See <xref linkend="sec-5.1.5"/>.
</para>
</listitem>
<listitem>
<para>Support for import, variables, and system environments: It is
assumed that the XML configuration file will support file import
(ability to store configurations in a set of files), variable
support (within the configuration XML file, not within common
configuration memory object), and inclusion of system environment
variables.  
</para>
</listitem>
</itemizedlist>
</section>

<section id="sec-5.1.2">
<title>Overview of the common configuration </title>

<para>
This specification assumes that the platform shares a single
implementation of configuration access. 
<!-- There are several stable -->
<!-- implementations which satisfies the technical assumptions of -->
<!-- configuration library that is described above. Apache common config -->
<!-- <biblioref linkend="apachecommonsconf"/>, or JConfig <biblioref -->
<!-- linkend="jconf"/>, supports them. This specification does not assume a -->
<!-- specific underlying library; we assume that the minimal functionality -->
<!-- that we describe can be provided by several standard implementations. -->
<!-- </para> -->

<!-- <para> -->
We start with a set of design decisions that follow from the
requirements above.
</para>

<itemizedlist>
<listitem>
<para>
Components need to be able to recognize relevant sections in the
configuration. Thus, each component class must have a
<emphasis>component name</emphasis>.  This name should be easy for
users to read and write in a configuration file.  At the same time,
individual instances of components require an <emphasis>instance
name</emphasis> to distinguish among multiple instances. We recommend
that component and instance names are human-readable rather than
UUID-like.
</para>
<para>
The common configuration object is able to return the applicable
region of the configuration object for a component and for a component
instance. The global section, with its special status, should be named
<code>PlatformConfigurationRegion</code>.
</para>
<!-- SP outdated
<para>
(Footnote: We assume that recommendations about the shape of component
and instance names will form part of the coding guidelines for EXCITEMENT.)
</para> -->
</listitem>
<listitem>
<para>
Hierarchical data storage: The common configuration data structure is
a recursive attribute-value list.  That is, attributes cannot only
have types atoms as values, but also attribute-value lists
themselves. We foresee at least two levels: the level of "sections"
and the level of "subsections". These levels correspond directly to
components and instances: Sections contain information about
components and are labeled with components IDs. Subsections contain
information about instances and are labeled with instance IDs. 
</para>
<para>
Note that (unlike in the existing EDITS configuration), the plain
existence of a section or a subsection does not automatically means
initialization of the component corresponding to that
configuration. For example, a configuration file might have
configuration sections of three EDAs, and choose one EDA to run, by
specifying that EDA in the framework section as main EDA. This also
makes it permissible to specify different "possible" or "recommended"
configurations of a component as subsections in the configuration,
only one of which is finally initialized.
</para>
</listitem>
<listitem>
<para>Storage in XML format: The human-readable version of the common
configuration will be stored and read as XML format. Users can edit
the XML file as ordinary XML file. Since names are supposed to be
unique, a name collision leads to an exception when the XML
serialization of the configuration object is loaded. 
</para>
</listitem>
<listitem>
<para>
Typing: All objects in XML are strings. The configuration currently
does not know about the value types for its keys. Rather, we achieve
typing by providing different access functions to the
configuration. It is currently the user's responsibility to ask the
configuration for the value of a key as a specific type.
</para>
</listitem>
<listitem>
<para>
The common configuration object specifies the behavior of components
<emphasis>at initialization and/or reconfiguration
time</emphasis>. The common configuration object is passed to each
component as the argument of the constructor and/or 
<code>reconfigure()</code> methods. Each component must read the
configuration and initialize and/or reconfigure itself
accordingly. 
</para>
</listitem>
</itemizedlist>


<para><xref linkend="common_config" /> shows a conceptual
overview of common configuration object. On the left hand side, the
common configuration object is shown as a big table with hierarchy. It
has two depths, sections and subsections. Each section is
corresponding to a "region" for a specific entailment
component. Actual configurations values are represented as lists of
"(Name,Value)" pairs. A set of name-value pairs are called as a
name-value table in this section.
</para>

<figure id="common_config">
<title>Overview of Common Configuration</title> 
<mediaobject>
<imageobject>
<imagedata fileref="./figures/common_config.jpg" scalefit="1" width="80%" align="center"/>
</imageobject>
</mediaobject>
</figure>

<para>
On the right hand side of the figure, the access of configuration
values are described on a conceptual level. A component can access an
instance of the common configuration object with
<code>getSection()</code> or <code>getSubSection()</code> methods for
components and their instances, respectively. A successful call
returns a name-value table. Each value associated with a name can be
accessed by a get method.
</para>

<para>
Each section and subsection is represented as a name-value table. Once
retrieved as a table, there is no differences between subsection and
section. Note that one cannot access subsections of a section from a
name-value table. A name-value table only holds the list of name-value
pairs. The table is a typed key-value list. Thus, a value (which was
written in an XML file as a string) can be accessed with
<code>getString(name)</code>, <code>getInteger(name)</code>, or
<code>getDouble(name)</code>. The XML strings will be converted
automatically into the requested type. 
</para>

<!-- <para> -->
<!-- As an in-memory object, an instance of common configuration object is -->
<!-- a single big block. However, on the XML file level, they can actually -->
<!-- come from more than single sources. For example, a section might exist -->
<!-- in in a separate file and may have imported in the main XML file. This -->
<!-- type of import support is already well implemented in existing -->
<!-- configuration libraries. -->
<!-- </para> -->

<para>
As an in-memory object, all name-value pairs are simply seen as a pair
of a name (string) and an associated value. However, in XML file
level, they can actually come from variables defined in the XML file
(like, <code>&lt;property
name="something"&gt;&amp;variable&lt;/property&gt;</code>). Also, the
configuration file should easily encode current system environment
values in the XML configuration file (For example, it should permit
expressions that uses $PATH variable, like <code>&lt;property
name="mypath"&gt;{$PATH}/etc&lt;/property&gt;</code>). Many
configuration management libraries already support such features.
(Note. The above pseudo-XML code is given only as an example. The
specification does not assume anything about how the name-value pairs
are represented in XML.)
</para>

<para>
For all entailment core components, the configuration is delivered as
a whole (single big block contains all pairs) via
<code>initialization()</code>. It is the responsibility of the
initialization (thus of its implementers) to retrieve and use the
relevant sections (by using getSection or getSubSection).
</para>

<para>
Instance configuration areas (SubSections) are only needed for the
components that support multiple instances with different
configurations. If all instances of a component have the same
configuration, the component do not use instance configuration and
uses only the component configuration. For example, knowledge
components generally have no need to have different configuration
even if they have multiple instances. 
</para>
<para>
However, some components must have multiple instances with different
configurations. Let's assume there is a distance calculation component
that is shipped with two parameters. One is a <code>path</code> to a
static resource (say, a dictionary), and the other is a numeric
parameter <code>alpha</code>. Assume that the EDA needs to run two
instances: one with alpha as 1.0, the other with alpha as 2.0. By
having instance-wise configurations, the EDA can run two instances of
the distance calculation component, each with different
configuration. In this example, parameter <code>path</code> will stay
in the component section, and parameter <code>alpha</code> will be
written in the instance subsection. 
</para> 

<para> 
Note that there is no automatic inheritance of section-level
information at the subsection level. That is, component instances will
typically have to query both the section level for component-wide
configuration and the subsection level for their own instance
configuration. (In the above example, parameter <code>path</code> is
not visible to the name-value table of the instance subsection.) 
</para>
</section>

<section id="sec-5.1.3">
<title>Interfaces related to Common Configuration </title>
<section>
<title>Class <code>CommonConfiguration</code> </title>
<para>The section describes the public interfaces that need to be
exposed to component authors. (Note that for the moment, the
specification does not provide any method that can iterate over
sections. For example, one cannot query a common configuration object
to get all section names. This was intentional in the current
version.)
</para>

<!-- <section> -->
<!-- <title>method <code>loadConfiguration()</code> </title> -->
<!-- <para><code>void loadConfiguration(File)</code> -->
<!-- This method loads a configuration from an XML File. If the target  -->
<!-- file is not valid (invalid XML or missing mandatory section), the call will raise an exception.  -->
<!-- </para> -->

<!-- <para> -->
<!-- Note that this <code>loadConfiguration()</code> is not supposed to be -->
<!-- called by core components. The <code>EngineStartup</code> component -->
<!-- (section []) will get the configuration file path and load the file -->
<!-- with this call. And then, <code>EngineStartup</code> will generate the -->
<!-- selected EDA and and pass the configuration as the argument of -->
<!-- <code>initialize()</code>. -->
<!-- </para> -->
<!-- </section> -->

<section>
<title>constructor <code>CommonConfiguration()</code> </title>
<para><code>CommonConfiguration(File)</code>
Common configuration provides a constructor that loads a configuration
from an XML File. If the target file is not valid (invalid XML or
missing mandatory section), the call will raise an
exception. CommonConfiguration will also provide a constructor with
empty arguments, which can be used to generate a new configuration
file. 
</para>
</section>

<section>
<title>method <code>getSection()</code> </title>
<para><code>public NameValueTable getSection(String component
Name)</code> This method returns the name-value table that is
associated with the <code>componentName</code>. If there is no such
section, the method will raise an exception.
</para>
</section>

<section>
<title>method <code>getSubsection()</code> </title>
<para><code>NameValueTable getSubSection(String componentName, String
instanceName)</code> This method returns the name-value table that
is associated with the <code>componentName</code> and
<code>instanceName</code>.  
</para>
</section>

<section>
<title>method <code>saveConfiguration()</code> </title>
<para><code>void saveConfiguration(File)</code> This method saves
current configuration to an XML file. It will save whole values as a
single XML file. Note that this save method should provide a safety
mechanism that will prevent overwriting existing XML
configurations (ie. only permitting generating new configuration
files, etc). 
</para>

<para>
Note that <code>saveConfiguration()</code> method is provided mainly
for user level or transduction layer level access. The methods are not
expected to be called from a entailment core component.
</para>
</section>


<section>
<title>method <code>getConfigurationFileName()</code> </title>
<para>
<code>String getConfigurationFileName() </code> This method is a
convenience method that returns the full path name of the current
configuration file. Will return null, if the configuration is not
originated from a file and never saved before. 
</para>
</section>
</section>

<section>
<title>class <code>NameValueTable</code> </title>
<para>All configuration parameters are stored as name-value pairs in a
table of class <code>NameValueTable</code>. The table can be read by a
set of access functions.
</para>
<section>
<title>get methods </title>
<para><code>public String getString(String name)</code></para>
<para><code>public Integer getInteger(String name)</code></para>
<para><code>public Double getDouble(String name)</code> </para> 
<para><code>public File getFile(String name)</code></para> 
<para><code>public File getDirectory(String name)</code></para> 
<para><code>...</code></para> 

<para>
Configuration data is stored as text strings in the XML files. XML
parsers can recognize XML primitive types like string, boolean,
decimal, double, etc. In this specification, we only show get methods
for a few basic types, like string, integer, double and File. Note
that the actual implementation can provide many more (like get methods
that will return enum, list of enums or other basic types, etc),
depending on the need of the Component writers.  
</para>

<para>
All get methods have a single string argument, the name part of a
name-value pair. A get method returns the corresponding value from the
name-value pair. Each get method will try to convert the XML value
into the requested type. If the conversion fails, the get method will
raise a conversion exception (one of ConfigurationException).
</para>
</section>

<section> 
<title>Set methods </title>
<para><code>public setString(String name, String value)</code></para>
<para><code>public setInteger(String name, Integer value)</code></para>
<para><code>public setDouble(String name, Double value)</code></para>
<para><code>public setFile(String name, File value)</code></para> 
<para><code>public setDirectory(String name, File value)</code></para>
<para><code>...</code></para> 
<para>
Set methods are provided for editing existing values or writing new
values. The values added/modified by set methods will only affect the
XML file by <code>saveConfiguration()</code>.
</para>

<para>
Note that set methods are provided mainly for user level or
transduction layer level access. The methods are not expected to be
called from a entailment core component. 
</para>
</section>
</section>
</section>

<section id="ConfigurationXMLFileFormat">
<title>Common Configuration XML file format </title> 
<para> This section first outlines the adopted XML configuration
format with an example. Then, it iterates a few issues around
configuration names and GLOBAL section (PlatformConfiguration). </para>  

<para> Let's first see an example file that follows the proposed file
format. It has a few sections (components) within it. Each name-values
are represented with a <code>property</code> element. The element has
one attribute (<code>name</code>), and actual value is written as
element value within the property element.  
</para> 

<programlisting> 
&lt;?xml version="1.0" encoding="utf-8"?&gt; 
&lt;!DOCTYPE configuration [
&lt;!ENTITY myVar "Some common #PCDATA that can be reused... "&gt; 
]&gt; 

&lt;configuration&gt;
&lt;section name="PlatformConfiguration"&gt;
&lt;property name="activatedEDA"&gt;core.MyEDA&lt;/property&gt; 
&lt;property name="language"&gt;EN&lt;/property&gt; 
&lt;/section&gt;

&lt;section name="PhoneticDistanceComponent"&gt;
&lt;property name="KlingonDictionaryPath"&gt;$RESOURCE/VD/KDict.cvs&lt;/property&gt;
&lt;property name="beta"&gt;0.1&lt;/property&gt; 

&lt;subsection name="instance1"&gt;
&lt;property name="consonantScore"&gt;1.0&lt;/property&gt; 
&lt;property name="vowelScore"&gt;0.6&lt;/property&gt;
&lt;property name="alpha"&gt;0.17663311&lt;/property&gt; 
&lt;/subsection&gt; 

&lt;subsection name="instance2"&gt;
&lt;property name="consonantScore"&gt;0.6&lt;/property&gt; 
&lt;property name="vowelScore"&gt;1.0&lt;/property&gt;
&lt;property name="alpha"&gt;0.17663311&lt;/property&gt; 
&lt;/subsection&gt; 

&lt;/section&gt; 

&lt;section name="core.MyEDA"&gt; 
&lt;property name="myLongKey"&gt;&amp;myVar;&lt;/property&gt; 
&lt;property name="someOption"&gt;PhoneticDistanceComponent, 
                       EditDistanceComponent&lt;/property&gt; 
&lt;/section&gt; 

&lt;/configuration&gt; 
</programlisting> 

<para> Note that, 
<itemizedlist>
<listitem><para>All section names must be unique (globally).</para></listitem>
<listitem><para>All subsection names must be unique within the section.</para></listitem>
<listitem><para>All property names are unique in each table
(section/subsection)</para></listitem> 
</itemizedlist>
If any violation is observed (including those and possible others), CommonConfig must raise an exception while loading the file.   
</para>

<para> A small note on configuration value names and
<code>PlatformConfiguration</code> (Global) region:  
<itemizedlist>
<listitem><para><code>PlatformConfiguration</code> section: This
global section of the common configuration holds some configuration
data that will be shared among all components and EDAs. For the first 
prototypes, we will only adopt two values. <code>activatedEDA</code>
holds the name of the EDA that is selected in this
configuration. <code>language</code> holds the language of the current
configuration.</para> </listitem>  
<listitem><para>Default
configuration: Each EDA implementer must provide a suitable default
configuration, so the user can start using the EDA with relative
ease. </para></listitem>  
<listitem><para>Names within a section (component): Each name within
each component configuration section is independent. The component
implementer can use the name that is suitable for the module. In
the future, we might iterate over configuration names, and we will try
to normalize common names, if such need arises. </para>
</listitem>  
</itemizedlist> 
</para> 
</section>

<section id="sec-5.1.4">
<title>Extending the common configuration features </title>
<para>This section defines is a minimalist approach to configuration
management. We leave possible extensions (like default values or
possible ranges) to future versions.
</para>
</section>

<section id="sec-5.1.5">
<title>Component selection</title>
<para>The responsibility for component selection -- i.e., the decision
which components to activate for a given run of the engine -- could be
assigned to different layers: to the user level code, to the
initialization helper, or to the top-level EDA. We make it a
responsibility of the EDA, in order to allow EDAs to "hide" some
complexity to its users. 
</para>
<para>
Consequently, the selection which components to use forms part of the
configuration of the EDA and is specified in the EDA section and/or
subsection. We expect EDAs to specify how the set of components to be
activated is specified as a configuration option. (Note that currently
the configuration does not lists). It is the responsibility of the
EDA, not of the user level code, to initialize these components.
</para>
</section>

</section>  <!-- end of section 5.1 --> 

<section id="sec-5.2">
<title>Input file format </title>
<section id="sec-5.2.1">
<title>Role of input data </title>
<para>This section describes the raw input data. By "raw input data"
we mean text-hypothesis pairs without linguistic analysis layers. The
RTE dataset formats (RTE1-5) are the most widely used file format for
this purpose. 
</para>

<para>
The internal EXCITEMENT entailment problem representation is the CAS
representation described in Section 3. The raw input data formats only
serve as as basis from which the CAS representations is created.  Each
linguistic analysis pipeline (LAP) <emphasis>must</emphasis> provide
readers for the RTE dataset formats that produce CAS objects from
corresponding files. All RTE formats to be supported are listed in
<xref linkend="appendix_input_format"/>. 
</para>
<para>
NB. RTE1-5 only support the encoding of "classical" (single H, single
T) entailment problems. That is, LAPs are only required to deal with
classical entailment problems. Support for multi H-T or T-multi H
problems is optional. Each LAP should specify clearly in its
documentation which additional problem types it supports and what file
format it expects or these problems (such as RTE-6 or later).
</para>

<para>
The following section describes the RTE data formats, and adds a
simple modification.
</para>
</section>

<section id="sec-5.2.2">
<title>RTE challenge data formats and the supported data
format. </title>
<para>The RTE challenge data formats are the most well known and
widely used data format among textual entailment community. RTE-1 to
RTE-5 formats are focused on single T-H pairs. 
</para>

<para>
One problem of RTE format is the lack of language marking. Language
designation is important in the EXCITEMENT platform. Thus we adopted a 
tiny modification to RTE format. The following is the DTD of RTE-5
main task data representation.  
</para>

<programlisting>&lt;!ELEMENT entailment-corpus (pair+)&gt;
&lt;!ELEMENT pair (t,h)&gt;
&lt;!ATTLIST pair
         id CDATA #REQUIRED
         entailment (ENTAILMENT|CONTRADICTION|UNKNOWN) #REQUIRED
         task (IR|IE|QA) #REQUIRED &gt;
&lt;!ELEMENT t (#PCDATA)&gt;
&lt;!ELEMENT h (#PCDATA)&gt;
</programlisting> 

<para>
It defines an XML format that holds top element
<code>entailment-corpus</code>. The element can have one or more <code>pair</code> 
elements, which have t and h as string data. A <code>pair</code> must have a set
of attributes. Here they are <code>id</code> (identifier of the pair, as string),
<code>entailment</code> (the entailment decision), and <code>task</code> (as one of information
retrieval, information extraction, or question answering). 
</para>

<para>
We modify the DTD as follows:
<programlisting>&lt;!ELEMENT entailment-corpus (pair+)&gt;
&lt;!ATTLIST entailment-corpus
          lang CDATA #IMPLIED
          channel CDATA #IMPLIED&gt;
&lt;!ELEMENT pair (t,h)&gt;
&lt;!ATTLIST pair
          id CDATA #REQUIRED
          entailment (ENTAILMENT|NONENTAILMENT|CONTRADICTION|
                          PARAPHRASE|UNKNOWN) #REQUIRED
          task (IR|IE|QA|SUM) #IMPLIED &gt;
&lt;!ELEMENT t (#PCDATA)&gt;
&lt;!ELEMENT h (#PCDATA)&gt;
</programlisting> 
</para> 
<para>
Now the top element <code>entailment-corpus</code> has an optional
attribute <code>lang</code> and <code>channel</code>. This attribute
holds the language identification string according to ISO 639-1
<biblioref linkend="langid"/>. For example, "EN" for English, "DE" for
German, and "IT" for Italian. Since it is an optional (designated as
#IMPLIED) attribute, existing RTE-5 XML data will be processed as a
valid XML for this DTD. In that case, no language checking will take
place. This is the same for <code>channel</code> value. The value
records the input channel (source of the input like e-mail, transcribed
phone call, etc), and it is an optional value. Also, the possible
values of entailment relationship are extended to match those of <xref
linkend="sec-4.2.1.6"/>. 
</para> 
<!-- TODO Mention that task field is now optional? -->

<para> 
Support for this xtended RTE-5 format is mandatory. EDA implementers
must support processing of the format. Other RTE formats are
optional. EDAs (and their LAPs) may support them. 
</para> 

<para>
At the current stage (non-decomposed pipelines), each LAP will have to
implement its own readers. (It is permissible to have one reader that
can deal with all RTE1-5 formats, given the large similarities between
the formats.) In the future, we foresee that RTE1-5 readers will be
provided as a "collection reader" component of UIMA component, and it
is expected that such components will be implemented only once and
shared among all EDAs and EDA implementers.
</para>

</section>
</section>

</section> <!-- end of Section 5, common data format --> 



<section>
<title>Further Recommended Platform Policies </title>

<section id="sec-6.1">
<title>Coding Standard </title>
<para>This section describes the coding standard for the EXCITEMENT
platform. You can also find the latest coding standard from the
project Wiki: <ulink 
url="https://github.com/hltfbk/Excitement-Open-Platform/wiki/Coding-Guidelines">
EOP Wiki: Coding Guidelines </ulink> 
</para>

<section id="sec-6.1.1">
<title>Documentation </title>
<itemizedlist>
<listitem>

<para>Every class / interface / enum should include a main comment in its
beginning, describing: 
</para>
<orderedlist>
<listitem>

<para>the purpose of the class
</para>
</listitem>
<listitem>
<para>its contents
</para>
</listitem>
<listitem>
<para>its usage
</para>
</listitem>
<listitem>
<para>and how it is related to other classes.
</para>
</listitem>
</orderedlist>
</listitem>
<listitem>
<para>The main comment should include also the author name and the date
when the class was created first. 
</para>
</listitem>
<listitem>
<para>Each method must be paired with a comment describing its
purpose, usage, parameters, return value. In particular, the comment
must make explicit as any policies on its use beyond its type
signature.
</para>
</listitem>
<listitem>
<para>The class and functions (methods) comments specified above should be
in Java-Doc format.
</para>
<itemizedlist>
<listitem>
<para>Tip: in Eclipse use Alt+Shift+J to generate a javadoc skeleton.
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>Comments should be written in the code itself, describing the flow,
i.e. describing what the code does. It is required when the code is
not clear (i.e. self explaining), and recommended for any long code
(long code = code with more that 5 lines). 
</para>
</listitem>
<listitem>
<para>The best practice is writing in such a way that a programmer that
will read your code will be able to understand it, without
additional explanations. 
</para>
</listitem>
<listitem>
<para>Packages and non-trivial fields should also be documented.
</para>
</listitem>
</itemizedlist>
</section>

<section id="sec-6.1.2">
<title>Error Handling </title>
<itemizedlist>
<listitem>

<para>Make sure you're familiar with the concept of Checked
Exceptions in Java <biblioref linkend="javachecked"/>.
</para>
</listitem>
<listitem>
<para>We will use a single way to handle errors: throwing exceptions.
</para>
</listitem>
<listitem>
<para>Code should not write to <code>System.err</code>. 
</para>
</listitem>
<listitem>
<para>Code should not call <code>System.exit()</code>. 
</para>
</listitem>
<listitem>
<para>Writing to <code>System.err</code> is allowed only in the module that handles the
very beginning and very end of the flow (i.e. the class that
contains the <code>main()</code> method, and may be one or two other classes
that are called by it). 
</para>
</listitem>
<listitem>
<para>Calling <code>System.exit()</code> is allowed only for GUI applications, and only
in the module that handles the GUI events. 
</para>
</listitem>
<listitem>
<para><code>RuntimeException</code> and its subclasses should never be thrown
explicitly. It is also recommended to wrap implicit potential throws
of subclasses of <code>RuntimeException</code> by <code>try...catch</code> that throws a
subclass of Exception that is not a runtime exception. 
</para>
</listitem>
<listitem>
<para>When throwing an exception, include a string in the exception that
describes the problem, and how it can be fixed. 
</para>
</listitem>
<listitem>
<para>"Stopping" an exception is usually a very bad idea. "Stopping"
means is catching it somewhere and not throwing it (or another
exception) again. The problem is that the user will not be aware of
underlying the problem that caused the first exception to be thrown.
</para>
</listitem>
<listitem>
<para>Handling exceptions that are thrown from an inner components can be
done in two ways: 
</para>
<orderedlist>
<listitem>

<para>Catch them, and throw a new exception that wraps the
original ones. 
</para>
</listitem>
<listitem>
<para>Let them be thrown up in the call-stack.
</para>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
</section>

<section id="sec-6.1.3">
<title>Naming Conventions </title>
<itemizedlist>
<listitem>

<para>Package names should be in lower case letters only. Even a multi-word name should not include any upper-case letter.
</para>
</listitem>
<listitem>
<para>Class names must start with an upper case letter.
</para>
</listitem>
<listitem>
<para>Function names and variable names must start with lower case letter.
</para>
</listitem>
<listitem>
<para>Constant names must include upper-case letters only, No lower case
letters are allowed in constant names. The underscore (_) character
can be used to separate words in constant names. 
</para>
</listitem>
<listitem>
<para>Use meaningful names for everything.
</para>
</listitem>
</itemizedlist>
</section>

<section id="sec-6.1.4">
<title>Writing Good Code </title>

<!--<para>What does "SE" in SE-oriented code mean?
</para>  -->

<itemizedlist>
<listitem>

<para>Local variables should be declared in the inner-most possible
block. Don't declare local variables in advance, but ad-hoc. This
convention helps eliminating some hard-to-observe bugs. 
</para>
<orderedlist>
<listitem>

<para>Nevertheless, for the sake of saving many calls to a costly
constructor, it may be wise to declared a local variable
out of its minimal scope 
</para>
</listitem>
</orderedlist>
</listitem>
<listitem>
<para>Write short code.
</para>
<orderedlist>
<listitem>

<para>Classes should be short. Try writing classes that are no
longer than 300 lines. A long class is an evidence to poor
design. A long class is usually a class that had to be
created as several classes, in a hierarchical way. 
</para>
</listitem>
<listitem>
<para>Functions should be short - no more than 25 lines. A long
function is hard to understand, and is an evidence that one
function does too many things, that had to be partitioned
into several functions (most of them non-public). 
</para>
</listitem>
</orderedlist>
</listitem>
<listitem>
<para>Do not use nested classes. Nested classes are required only in rare
cases, where the nested class needs access to its parent's private
members , should not be known outside, and is logically part of the
parent, but needs also its own private context. Those cases are
rare. 
</para>
</listitem>
<listitem>
<para>Do not use nested static classes. You can use them only sometimes for
declaring specific exceptions, or in some rare cases. In general,
using nested classes, either static or non-static, makes a
hard-to-understand and hard-to-change code. 
</para>
</listitem>
<listitem>
<para>Make sure your code has no compilation warnings. Compilation
warnings are a good tool for avoiding bugs. A code that contains
warning makes them unusable. 
</para>
</listitem>
<listitem>
<para>It is strongly recommended that every class will contain all of its
"public" constructors / methods and fields together. Putting all of
the public stuff at the beginning of the class, with a clear comment
separator between public and non-public part, makes the class easier
to understand and use. 
</para>
<orderedlist>
<listitem>

<para>It's convenient to change eclipse's settings to place new
generated private methods at the bottom of the class.   
</para>
</listitem>
</orderedlist>
</listitem>
<listitem>
<para>Use constants. Numbers and strings should not be hard coded in the
code itself, but as constants. Put all the constants together at the
beginning of the class, and make them "final". 
</para>
</listitem>
<listitem>
<para>Never use early-access code or any code that may become incompatible
in future environment. 
</para>
</listitem>
<listitem>
<para>For <emphasis>abstract data types</emphasis>, that is, classes
that represent some non-atomic information as a single object, make
sure that the following conditions are met:
</para>
<orderedlist>
<listitem>
<para>Abstract data types should typically implement their own
"equals" and "hashCode" methods. Make sure that they are implemented
if necessary.
</para>
</listitem>
<listitem>
<para>Make sure you do not implement those methods when they should
not be implemented.
</para>
</listitem>
<listitem>
<para>Make sure you implement them correctly. Eclipse has a
default way to implement those methods (source--&gt; insert
--&gt; hashcode feature). Use it. Do not use another
implementation unless you know what you are doing. 
</para>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
<!--</section> -->

<!--<section id="sec-6.1.5">
<title>Some Software Engineering Concepts </title> -->
<!--<itemizedlist>
<listitem> -->

<para>Write modular modules.
</para>
<orderedlist>
<listitem>

<para>For each module, think that it can be used in another
context than you originally intend to use it. 
</para>
</listitem>
<listitem>
<para>For each module, think that it can be replaced by another
module with the same interface. 
</para>
</listitem>
<listitem>
<para>Write clear and simple interfaces for any module. A simple
interface consists of a relatively small set of functions,
that take very few parameters. UNIX system calls are a very
good example of a very small set of function (about 100
functions), each takes very few parameters (1 or 2. Only
one function takes 3 parameters). That set supplies all of
the required functionality that an OS should supply. 
</para>
</listitem>
<listitem>
<para>A module should not be aware of any module
that is not logically connected to it. In other words: If a module X
is not necessary for the definition of another module Y, than Y
should not refer to X in any way. 
</para>
</listitem>
</orderedlist>
</section>

<section id="code_annotations">
<title>Code annotations</title> 
<para>EXCITEMENT platform will adopt some Java code annotations,
starting with the followings. </para> 
<itemizedlist>
<listitem><para><code>@LanguageDependent</code>: Every class that is
language dependent (e.g. only for English, only for Spanish, etc)
should be annotated by <code>@LanguageDependent</code>.</para>
</listitem> 
<listitem>
<para><code>@ThreadSafe</code>, <code>@NotThreadSafe</code>: These two
annotations are for explicitly marking thread safety of a class.</para>  
</listitem> 
</itemizedlist> 
<para>Actual definitions of the Java annotations and their usage will be
provided by the implementation team (WP4). Also, the list of the
annotations will be expanded along with the implementation effort. </para>
</section>
</section> 

<section id="sec-6.2">
<title>List of Exceptions </title>
<para>Exceptions are part of the method signature, similar to inputs
and return types. However, it is not easy to specify an exception
hierarchy for the EXCITEMENT platform in detail at this stage. Thus,
in this specification, we will only try to outline them.  The objects
outlined in this section will form the top level objects in the
EXCITEMENT exception hierarchy. More detailed use cases and additional
exceptions will be added in the future during the development in WP4.
</para>

<para>The following exceptions form the top layer of the exception
hierarchy. They directly inherit from java.lang.Exception (or a
putative future generic EXCITEMENT Exception object).
</para>
<itemizedlist>
<listitem>
<para><code>ConfigurationException</code>: Interfaces of common
configuration can throw exceptions of various kinds. Exceptions
originated from common configuration code, and that can be checked,
should use or inherit this exception.  
</para>
</listitem>
<listitem>
<para><code>EDAException</code>: Interfaces and implementations of
EDAs can generate this type of exception. All checked exceptions
thrown from EDA code should use or inherit this exception.
</para>
</listitem>
<listitem>
<para><code>ComponentException</code>: This is an exception caused
within an entailment core component. It is the base type that will be
inherited by core component exceptions like
<code>KnowledgeComponentException</code>,
<code>DistanceComponentException</code>, or that of future core
components.
</para>
</listitem>
<listitem>
<para><code>KnowledgeComponentException</code>: Implementations of knowledge components (lexical resource and syntactic resource) can raise this exception.
</para>
</listitem>
<listitem>
<para><code>DistanceComponentException</code>: Implementations of distance calculation components can throw this exception. 
</para>
</listitem>
</itemizedlist>

<para>
The above exceptions are only covering the core components. LAP
components use different set of exceptions, namely UIMA exceptions,
and follow the UIMA component exception policies. The UIMA AE uses one
of the following exceptions;
<code>ResourceConfigurationException</code>,
<code>ResourceInitializationException</code>, and
<code>AnalysisEngineProcessException</code>.  The message encoded with
the exceptions must use a specific message digest format. For more
information on UIMA AE exceptions, see <biblioref
linkend="AEException"/>.
</para>
</section>

<section id="sec-6.3">
<title>Common Logging for Entailment Core </title>
<para>
Components often need to expose their progress and internal logic for
various purposes. EXCITEMENT core components are no exceptions. For
this purpose, all core components (including EDA) will share a common
logging facility. The <code>CommonLogging</code> class must support
the following capabilities:
</para>
<itemizedlist>
<listitem>

<para>Priority: the logging capability must support different levels of
priorities. For example, TRACE, DEBUG, INFO, ERROR, etc. 
</para>
</listitem>
<listitem>
<para>Originator: The originator of a log message should be
identifiable.  The common logging must provide a principled way of
distinguishing the log originator, with component name
(<code>getComponentName</code> of <code>Components</code>) and/or
class name.   
<!-- Gil: I think so, explicitly mentioned getComponentName  --> 
<!-- [SP: can we maybe directly re-use the component ID that we -->
<!-- introduced in the configuration for this?] -->
</para>
</listitem>
</itemizedlist>

<para>The specification does not specify further detail of the common
logging capability. It is expected that one of the well known Java
logging libraries will be imported for the EXCITEMENT platform. 
</para>

<para>
Note that, at least for the first iteration, the entailment core
common logging will only cover the EDAs and core components, not
LAPs. For LAP, we will use UIMA logging facilities. Integration of two
logging system will be considered in the second iteration.  Also note
that our coding standard does <emphasis role="bold">not</emphasis>
permit usage of standard error output <xref linkend="sec-6.1.2"/>. 
Thus, the log output is the only recommended way of exposing the inner
progress of a component. 

<!-- [SP: some technical questions... who writes -->
<!-- into the log file? Is it the EDA, or components? Or both? Which leads -->
<!-- me to the question - how will the log be accessed? Will it be part of -->
<!-- some global state, or will it be handed down through parameters? That -->
<!-- seems unnecessary, since we'll just have one log (right?) ] -->
</para>
</section>

<section id="sec-6.4">
<title>Conventions for Additional Names</title> 
<para>The EXCITEMENT platform will include many names, not only as Java
objects but also as UIMA type names, and also configuration names. 
This section summarizes some common naming conventions.  
</para>
<itemizedlist>
<listitem>

<para>Longer names are preferred to shorter names: For example, use
<code>customerAccountDataPath</code>, not <code>custAccDTPath</code>.  
</para>
</listitem>
<listitem>
<para>Do not use dash (-) or underscore (_) unless you have a good
reason: For example, <code>supportedLanguage</code> (feature name), or
<code>supported.language</code> (configuration name) are preferred
over "supported_language" or "supported-language". One exception might
be the naming of constants (like <code>PI_VALUE</code>), where uppercase
letters are used, and the usage of a dot (.) is not possible.
</para>
</listitem>
<listitem>
<para>Class names, or class like things (like UIMA type) should begin with
an uppercase letter: If they are a compound word, use
CamelCase. For example, "EntailmentType", or
"CalculatingSemanticDistance".   
</para>
</listitem>
<listitem>
<para>Member names, or member like names should begin with a lowercase
letter: If they are a compound word, they should use lower camel
case (like, "anotherFeatureName", "stem", "nextNode").  
</para>
</listitem>
<listitem>
<para>In all cases, the names should clearly represent what the value of
the name represents.  
</para>
</listitem>
</itemizedlist>

<para>In summary, all naming should be consistent with standard naming
convention. For UIMA types, treat a type just like a Java object.
UIMA feature structures are equivalent to class members, and all
features names should start with a lowercase letter, etc. Also, treat
name-value pairs of common configuration as member items within a
category. Thus, all property names of name-value pairs should start
with a lowercase letter.
</para>
</section>

<section>
<title>Boundary of LAP and Entailment Core: Where should my new component go? </title>
<para>
Another issue that is related to UIMA and the platform concerns the
boundary between the LAP (which uses CAS to represent its outputs) and
the Entailment Core (which uses proprietary Java data structures).
Which components should be provided as UIMA component (LAP component
that outputs to CAS), and which components should be provided as
entailment core components (with Java APIs)?
</para>

<para>
At the beginning of the project, only common linguistic analysis
components were expected to be provided as LAP component. However the
development is towards packaging TE-specific components like a
"predicate-truth annotator" as a LAP component as well.  This gives
rise to the question where a new component should be conceptualized
when we want to add a new capability: as a new UIMA (LAP) component?
Or, alternatively, as a new entailment-core component?
</para>

<para>
The following recommendations represent a "best practice" produced
collectively by the academic partners.
</para>
<itemizedlist>
<listitem>

<para>Generic language analysis components must be provided as LAP
components, since they will be also by other layers (transduction
layer, and user level code, etc).
</para>
</listitem>
<listitem>
<para>LAP components (i.e. UIMA annotators) are best suited for
annotation (adding labels to portions of text). If an analysis
components main goal is to add annotations, it should be implemented
as a LAP component.
</para>
</listitem>
<listitem>
<para>Given we now have text and hypothesis markings also as UIMA CAS
annotations, it is possible to add annotations that are specific for
textual entailment.
</para>
</listitem>
<listitem>
<para>It is recommended that a new analysis component should be
delivered as a LAP component if it is <emphasis>natural</emphasis> to
represent is as an annotator (for some interpretation of
"natural"). The advantage of doing so is that it can add new analysis
capability <emphasis>without</emphasis> the need to define additional
APIs.
</para>
</listitem>
<listitem>
<para>A final consideration is serialization. UIMA provides a generic
procedure for storing CAS objects. Thus, components that create
<emphasis>static</emphasis> annotations -- that is, which can be
considered to have an independent status as an annotation layer of a
dataset, independent of one particular experiment -- can be
conceptualized well as LAP components and can ignore all
considerations about serialization. 
<!-- Gil: checked [SP: this is new; please check] --> 
</para>
</listitem>
</itemizedlist>

<para>Note that the above list is not a hard guideline, but closer to
a suggestion. It is not very hard to imagine good counter examples for
each point. For example, distance calculation components are not
natural to be represented as an annotator. But a developer might want
to represent it as a LAP module when he wants to store the result
statically in a CAS to speed up repeated experiments.
</para>

<para>
Thus, developers have a certain level of freedom in their choice
between implementing components with the LAP or the EC. As we grow
more confident on UIMA and common platform, we may be able to provide
more concrete best practices on this issue.
</para>
</section>


   
   <!-- <section><title> Common Logging </title>  -->
   <!--    <para></para> -->
   <!-- </section>  -->

   <!-- <section><title>Implementation Transition Path </title>  -->
   <!--    <para></para> -->
   <!-- </section>  -->


   <!-- <section><title> Knowledge-base Storage Policy </title> -->
   <!--    <para></para>  -->
   <!-- </section>  -->

</section> <!-- end of Section 6-->


<!-- <section> <title> Using the Platform (or Internal Specification for WP6 and Commercial Partners)</title>  -->

<!-- <para> {TBD: Project proposal defines two specification for each cycle. One for open platform (3.1a and 3.2a), one for project-internals (3.1b and 3.2b). We might be able to generate "B" specifications by adding a specific section; internal specification that includes input interface from commercial partners.} </para>  -->
<!-- </section>  -->

<!-- <section> --> 
<!-- <title>Section Title</title> -->
<!-- <para>The body of the standard goes here.</para> -->
<!-- <para>This level goes into the table of contents.</para> -->
<!-- <section> -->
<!-- <title>Sub-section Title</title> -->
<!-- <para>This level goes into the table of contents.</para> -->
<!-- <section> -->
<!-- <title>Sub-sub-section Title</title> -->
<!-- <para>This level goes into the table of contents.</para> -->
<!-- <section> -->
<!-- <title>Sub-sub-sub-section Title</title> -->
<!-- <para>This level and others do not go into the table of contents.</para> -->
<!-- <section> -->
<!-- <title>Sub-sub-sub-sub-section Title</title> -->
<!-- <para>This level and others do not go into the table of contents.</para> -->
<!-- </section> -->
<!-- </section> -->
<!-- </section> -->
<!-- </section> -->
<!-- </section> -->

<section id="RefSec">
<title>References</title>
<para></para>

<bibliography><title>Bibliography</title>


<bibliomixed id="apachecommonsconf"><abbrev>Apache Configuration</abbrev><title>Apache Commons Configuration homepage</title>.
<citetitle><ulink url="http://commons.apache.org/configuration/
">http://commons.apache.org/configuration/</ulink></citetitle></bibliomixed>

<bibliomixed id="report_BIUTEE"><abbrev>BIUTEE</abbrev>EXCITEMENT WP3 ITD subgroup,
<title>Major Components of BIUTEE - Bar Ilan University Textual Entailment Engine</title>,
2012. <citetitle><ulink url="https://dl.dropbox.com/u/13718630/reports/BIUTEE_component_overview.pdf">https://dl.dropbox.com/u/13718630/reports/BIUTEE_component_overview.pdf</ulink></citetitle> 
</bibliomixed>


<bibliomixed id="javachecked"><abbrev>CheckedEx</abbrev><title>Java
Checked Exceptions (Java Programming Wikibooks)</title>. <citetitle><ulink
url="http://en.wikibooks.org/wiki/Java_Programming/Checked_Exceptions">http://en.wikibooks.org/wiki/Java_Programming/Checked_Exceptions</ulink></citetitle></bibliomixed>


<bibliomixed id="CLEARTK"><abbrev>CLEARTK</abbrev><title>CLEARTK homepage</title>.
<citetitle><ulink url="http://code.google.com/p/cleartk/">http://code.google.com/p/cleartk/</ulink></citetitle></bibliomixed>

<bibliomixed id="DKPRO"><abbrev>DKPRO</abbrev><title>DKPRO homepage</title>.
<citetitle><ulink url="http://code.google.com/p/dkpro-core-asl/">http://code.google.com/p/dkpro-core-asl/</ulink></citetitle></bibliomixed>

<bibliomixed id="docbook"><abbrev>DocBook</abbrev>OASIS Committee Draft 4.4 <title>DocBook XML</title>, 17 January 2005.
<citetitle><ulink url="http://www.docbook.org/specs/cd-docbook-docbook-4.4.html">http://www.docbook.org/specs/cd-docbook-docbook-4.4.html</ulink></citetitle></bibliomixed>

<bibliomixed id="report_EDITS"><abbrev>EDITS</abbrev>EXCITEMENT WP3 ITD subgroup,
<title>Major Components of EDITS - Textual Entailment Engine of FBK</title>,
2012. <citetitle><ulink url="https://dl.dropbox.com/u/13718630/reports/EDITS_component_overview.pdf">https://dl.dropbox.com/u/13718630/reports/EDITS_component_overview.pdf</ulink></citetitle> 
</bibliomixed>

<bibliomixed id="langid"><abbrev>ISO 639-1</abbrev><title>ISO 639-1
Codes for the representation of names of
languages</title>.<citetitle><ulink
url="http://en.wikipedia.org/wiki/ISO_639-1_codes">http://en.wikipedia.org/wiki/ISO_639-1</ulink></citetitle></bibliomixed>

<bibliomixed id="jconf"><abbrev>JConf</abbrev><title>JuliusLib JConf Configuration homepage</title>.
<citetitle><ulink url="http://www.sp.nitech.ac.jp/~ri/julius-dev/doxygen/julius/4.0/en/group__jfunc.html">http://www.sp.nitech.ac.jp/~ri/julius-dev/doxygen/julius/4.0/en/group__jfunc.html</ulink></citetitle></bibliomixed>

<bibliomixed id="Amnon"><abbrev>PredicateTruth</abbrev><title>Predicate
Truth Annotation</title>. <citetitle><ulink url="http://dl.dropbox.com/u/6327182/seminar%20work.doc">A Manual Syntactic Rulebase for a Textual Entailment Recognition System</ulink></citetitle></bibliomixed>

<!-- <bibliomixed id="oasis-spec"><abbrev>oasis-spec</abbrev>OASIS Working Draft 0.5 <title>OASIS Specification Publishing in DocBook XML</title>, 8 July 2010. -->
<!-- <citetitle><ulink url="http://docs.oasis-open.org/templates/DocBook/spec-0.5/oasis-specification-0.5.html">http://docs.oasis-open.org/templates/DocBook/spec-0.5/oasis-specification-0.5.html</ulink></citetitle></bibliomixed> -->

<bibliomixed id="uimaws2013"><abbrev>UIMAWS2013</abbrev>Noh and Pado,
<title>Using UIMA to Structure an Open Platform for Textual Entailment</title>,
UIMA workshop at GSCL, 2013. <citetitle><ulink url="http://ceur-ws.org/Vol-1038/paper_3.pdf">Using UIMA to Structure an Open Platform for Textual Entailment</ulink></citetitle>
</bibliomixed>

<bibliomixed id="jnle2013"><abbrev>JNLE2013</abbrev>Pado et al, 
<title>Design and Realization of a Modular Architecture for Textual Entailment</title>,
Natural Language Engineering, 2013. <citetitle><ulink url="http://www.nlpado.de/~sebastian/pub/papers/jnle13_pado.pdf">Design and Realization of a Modular Architecture for Textual Entailment</ulink></citetitle>
</bibliomixed>

<bibliomixed id="rfc2119"><abbrev>RFC 2119</abbrev>S. Bradner,
<title>Key words for use in RFCs to Indicate Requirement Levels</title>,
IETF (Internet Engineering Task Force) RFC 2119, March 1997. <citetitle><ulink url="http://www.ietf.org/rfc/rfc2119.txt">http://www.ietf.org/rfc/rfc2119.txt</ulink></citetitle>
</bibliomixed>

<bibliomixed id="TIMEX3"><abbrev>TIMEX3</abbrev>TimeML Working Group, 
<title>Guidelines for Temporal Expression Annotation for English for
TempEval 2010</title>, August 14, 2009  <citetitle><ulink
url="http://www.timeml.org/tempeval2/tempeval2-trial/guidelines/timex3guidelines-072009.pdf">Timex3guidelines-072009.pdf</ulink></citetitle>
</bibliomixed>


<bibliomixed id="report_TIE"><abbrev>TIE</abbrev>EXCITEMENT WP3 ITD subgroup,
<title>Major Components of TIE - Textual Entailment Engine of DFKI</title>,
2012. <citetitle><ulink url="https://dl.dropbox.com/u/13718630/reports/TIE_component_overview.pdf">https://dl.dropbox.com/u/13718630/reports/TIE_component_overview.pdf</ulink></citetitle> 
</bibliomixed>

<bibliomixed id="ref-Apache_UIMA"><abbrev>UIMA</abbrev> <title>Apache
UIMA Homepage</title>. 
<citetitle><ulink url="http://uima.apache.org">http://uima.apache.org</ulink></citetitle>
</bibliomixed>

<bibliomixed id="UIMA_CAS_ref"><abbrev>UIMA-CAS</abbrev> <title>Apache
UIMA reference, section on CAS</title>. 
<citetitle><ulink url="http://uima.apache.org/d/uimaj-2.4.0/references.html#ugr.ref.cas">
http://uima.apache.org/d/uimaj-2.4.0/references.html#ugr.ref.cas</ulink></citetitle>
</bibliomixed>

<bibliomixed id="ref-Apache_UIMA_DOC"><abbrev>UIMA-doc</abbrev> <title>Apache
UIMA Documentation</title>. 
<citetitle><ulink url="http://uima.apache.org/documentation.html">http://uima.apache.org/documentation.html</ulink></citetitle>
</bibliomixed>

<bibliomixed id="AEException"><abbrev>UIMA-exceptions</abbrev> <title>Apache
UIMA Tutorial and Developers Guide, section on Exceptions</title>. 
<citetitle><ulink
url="http://uima.apache.org/d/uimaj-2.4.0/tutorials_and_users_guides.html#ugr.tug.aae.throwing_exceptions_from_annotators"> 
http://uima.apache.org/d/uimaj-2.4.0/tutorials_and_users_guides.html#ugr.tug.aae.throwing_exceptions_from_annotators
</ulink></citetitle>
</bibliomixed>

<bibliomixed id="UIMA_ref_ser"><abbrev>UIMA-ser</abbrev> <title>Apache
UIMA reference, section on XMI CAS serialization</title>. 
<citetitle><ulink 	       url="http://uima.apache.org/d/uimaj-2.4.0/references.html#ugr.ref.xmi">
http://uima.apache.org/d/uimaj-2.4.0/references.html#ugr.ref.xmi</ulink></citetitle>
</bibliomixed>

<!-- <bibliomixed id="xml-assoc"><abbrev>xml-assoc</abbrev>James Clark. -->
<!-- <title>Associating Style Sheets with XML documents Version -->
<!-- 1.0</title>, W3C Recommendation 29 June 1999. <citetitle><ulink -->
<!-- url="http://www.w3.org/1999/06/REC-xml-stylesheet-19990629">http://www.w3.org/1999/06/REC-xml-stylesheet-19990629</ulink></citetitle> -->
<!-- </bibliomixed> -->


</bibliography>
</section>

<appendix id="genericTypesXML">
<title>Type Definition: types for general linguistic analysis</title>
<!-- <para>{For the moment, the type tables are not exhaust.}  -->
<!-- </para> -->
<!-- <para> -->
<!-- {At the 1.0 spec release, exhaust type lists will be released with the XML definition file that can be directly used in UIMA  and related tools}  -->
<!-- </para> -->
<para> Starting from the specification version 1.1, we have attached a
java project to the specification. You can download the
attachement that holds all the interface codes and the type system <ulink
url="https://dl.dropbox.com/u/13718630/codes/excitement_interface_codes_aug29.zip"><citetitle>EXCITEMENT
SPEC 1.1 interfaces and type systems</citetitle></ulink> 
</para>

<section>
<title>Segmentation types</title>
<para>
You can find the type definition in XML at
<code>LexicalUnits.xml</code> among the attached project files. 
</para> 
<para>Segmentations types are types that denotes various textual units,
lemma, heading, paragraphs, sentence, etc. 
</para>
<itemizedlist>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: An instance of this type annotates a sentence. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<itemizedlist>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Paragraph</code>
</para>
<itemizedlist>
<listitem>
<para>Description: An instance of this type annotates a paragraph.
</para>
</listitem>
<listitem>
<para>Supertype:  <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Stem</code>
</para>
<itemizedlist>
<listitem>
<para>Description: An instance of this type annotates a stem. It has a
    feature that holds the stem as string. 
</para>
</listitem>
<listitem>
<para>Supertype:  <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>value</code> (<code>uima.cas.String</code>): stem value. 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token</code>
</para>
<itemizedlist>
<listitem>
<para>Description: An instance of this type annotates a token. It has
    features that points lemma, stem, and POS of the token. 
</para>
</listitem>
<listitem>
<para>Supertype:  <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>lemma</code> (<code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma</code>) 
</para>
</listitem>
<listitem>
<para><code>stem</code> (<code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Stem</code>)   
</para>
</listitem>
<listitem>
<para><code>pos</code> (<code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>)     
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<section>
<title>POS types</title>
<para>
You can find the type definition in XML at
<code>POS.xml</code> among the attached project files.   
</para> 
<para>Annotations that are used to mark part-of-speech are defined by these
types. They are aligned with some simple hierarchy. 
</para>
<itemizedlist>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This is the top type of POS annotation hierarchy. It
    has one feature, <code>PosValue</code>, which denotes the raw output of the
    POS tagger. 
</para>
</listitem>
<listitem>
<para>Supertype:  <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>PosValue</code> (<code>uima.cas.String</code>) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates PP (pre-positions). 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates pronouns.
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PUNC</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates punctuations.
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates verbs.
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates adjectives.
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADV</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates adverbs.
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ART</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates articles.
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.CARD</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates cardinal numbers.
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.CONJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates conjunctions. 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.N</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates nouns. 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.NN</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates normal nouns. Note the
    supertype is noun, not POS. 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.N</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.NP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates proper nouns. Note the
    supertype is noun, not POS. 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.N</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates interjections.
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<section>
<title>Extension of basic POS types</title>
<para>In DKPro, there are also some extended POS tags designed to work for
specific text domains. We will generally not adopt them in
EXCITEMENTS. However, two examples are shown here as an example of a
type extension. They are designed for tweet texts, and the modules
that understand those types can take benefits from them. Moreover,
previously existing generic code that does not understand the
extensions, is still be able to access them in terms of the generic
types O and NP.
</para>
<itemizedlist>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.tweet.EMO</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates emoticons of tweet texts. Note
    the super type O. 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.tweet.NPV</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type annotates user ID of tweet texts. For
    example, "@tailblues", "@magritte", etc. Note the supertype NP. 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.NP</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<section>
<title>Mapping of tagger tagsets to the types</title>
<para>The following two lists show the mapping of English and German tags of
Tree Tagger, to the DKPro POS tags. This type of mapping (what
actually means, say, NN in German), should be provided by the pipeline
implementers.  
</para>

<para>
English Tags (Penn Treebank)
</para>
<itemizedlist>
<listitem>
<para>CC: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.CONJ
</para>
</listitem>
<listitem>
<para>CD: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.CARD 
</para>
</listitem>
<listitem>
<para>DT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ART  
</para>
</listitem>
<listitem>
<para>EX: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ART  
</para>
</listitem>
<listitem>
<para>IN: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PP   
</para>
</listitem>
<listitem>
<para>JJ: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADJ  
</para>
</listitem>
<listitem>
<para>JJR: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADJ 
</para>
</listitem>
<listitem>
<para>JJS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADJ 
</para>
</listitem>
<listitem>
<para>MD: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V    
</para>
</listitem>
<listitem>
<para>NN: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.NN   
</para>
</listitem>
<listitem>
<para>NNS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.NN  
</para>
</listitem>
<listitem>
<para>NP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.NP   
</para>
</listitem>
<listitem>
<para>NPS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.NP  
</para>
</listitem>
<listitem>
<para>PDT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ART 
</para>
</listitem>
<listitem>
<para>PP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR   
</para>
</listitem>
<listitem>
<para>PP$: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>RB: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADV  
</para>
</listitem>
<listitem>
<para>RBR: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADV 
</para>
</listitem>
<listitem>
<para>RBS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADV 
</para>
</listitem>
<listitem>
<para>RP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PP   
</para>
</listitem>
<listitem>
<para>SENT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PUNC 
</para>
</listitem>
<listitem>
<para>UH: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O    
</para>
</listitem>
<listitem>
<para>VB: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V    
</para>
</listitem>
<listitem>
<para>VBD: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VBG: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VBN: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VBP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VBZ: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VH: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V    
</para>
</listitem>
<listitem>
<para>VHD: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VHG: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VHP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VHN: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VHZ: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VV: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V    
</para>
</listitem>
<listitem>
<para>VVD: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VVG: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VVN: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VVP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>VVZ: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V   
</para>
</listitem>
<listitem>
<para>WDT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ART 
</para>
</listitem>
<listitem>
<para>WP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR   
</para>
</listitem>
<listitem>
<para>WP$: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>WRB: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADV 
</para>
</listitem>
<listitem>
<para>*: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O    
</para>
</listitem>
</itemizedlist>

<para>
German Tags (STTS) 
</para>
<itemizedlist>
<listitem>
<para>ADJA: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADJ 
</para>
</listitem>
<listitem>
<para>ADJD: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADJ 
</para>
</listitem>
<listitem>
<para>ADV: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ADV  
</para>
</listitem>
<listitem>
<para>APPR: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PP  
</para>
</listitem>
<listitem>
<para>APPR: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PP  
</para>
</listitem>
<listitem>
<para>APPO: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PP  
</para>
</listitem>
<listitem>
<para>APZR: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PP  
</para>
</listitem>
<listitem>
<para>ART: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.ART  
</para>
</listitem>
<listitem>
<para>CARD: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.CARD
</para>
</listitem>
<listitem>
<para>FM: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O    
</para>
</listitem>
<listitem>
<para>ITJ: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O    
</para>
</listitem>
<listitem>
<para>KOUI: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.CONJ
</para>
</listitem>
<listitem>
<para>KOUS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.CONJ
</para>
</listitem>
<listitem>
<para>KON: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.CONJ 
</para>
</listitem>
<listitem>
<para>KOKOM: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.CONJ
</para>
</listitem>
<listitem>
<para>NN: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.NN   
</para>
</listitem>
<listitem>
<para>NE: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.NP   
</para>
</listitem>
<listitem>
<para>PDS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>PDAT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR 
</para>
</listitem>
<listitem>
<para>PIS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>PIAT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR   
</para>
</listitem>
<listitem>
<para>PIDAT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>PPER: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR   
</para>
</listitem>
<listitem>
<para>PPOSS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>PPOSAT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR 
</para>
</listitem>
<listitem>
<para>PRELS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>PRELAT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR 
</para>
</listitem>
<listitem>
<para>PRF: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>PWS: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>PWAT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR 
</para>
</listitem>
<listitem>
<para>PWAV: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR 
</para>
</listitem>
<listitem>
<para>PAV: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PR  
</para>
</listitem>
<listitem>
<para>PTKZU: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O 
</para>
</listitem>
<listitem>
<para>PTKNEG: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O
</para>
</listitem>
<listitem>
<para>PTKVZ: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V 
</para>
</listitem>
<listitem>
<para>PTKANT: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O
</para>
</listitem>
<listitem>
<para>PTKA: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O  
</para>
</listitem>
<listitem>
<para>TRUNC: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O 
</para>
</listitem>
<listitem>
<para>VVIMP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V 
</para>
</listitem>
<listitem>
<para>VVINF: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V 
</para>
</listitem>
<listitem>
<para>VVIZU: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V 
</para>
</listitem>
<listitem>
<para>VVPP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V  
</para>
</listitem>
<listitem>
<para>VAFIN: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V 
</para>
</listitem>
<listitem>
<para>VAIMP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V 
</para>
</listitem>
<listitem>
<para>VAINF: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V 
</para>
</listitem>
<listitem>
<para>VAPP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V  
</para>
</listitem>
<listitem>
<para>VMFIN: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V 
</para>
</listitem>
<listitem>
<para>VMINF: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V 
</para>
</listitem>
<listitem>
<para>VMPP: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.V  
</para>
</listitem>
<listitem>
<para>XY: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O    
</para>
</listitem>
<listitem>
<para>$,: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PUNC 
</para>
</listitem>
<listitem>
<para>$.: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PUNC 
</para>
</listitem>
<listitem>
<para>$(: de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.PUNC 
</para>
</listitem>
<listitem>
<para>* : de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.O    
</para>
</listitem>
</itemizedlist>

</section>
</section>

<!-- DKPRO document metadata: we might not use it.  --> 
<!-- <section> -->
<!-- <title>Document Metadata</title> --> 
<!-- <itemizedlist> -->
<!-- <listitem> -->
<!-- <para><code>de.tudarmstadt.ukp.dkpro.core.api.metadata.type.DocumentMetaData</code> -->
<!-- </para> -->
<!-- <itemizedlist> -->
<!-- <listitem> -->
<!-- <para>Description: This type extends basic document annotation of UIMA -->
<!--     CAS. It holds additional data as strings.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para>Supertype: <code>uima.tcas.DocumentAnnotation</code> -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para>Features -->
<!-- </para> -->
<!-- <itemizedlist> -->
<!-- <listitem> -->
<!-- <para><code>documentTitle</code> (<code>uima.cas.String</code>) -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>documentId</code> (<code>uima.cas.String</code>) -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>documentUri</code> (<code>uima.cas.String</code>) -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>collectionId</code> (<code>uima.cas.String</code>)  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>documentBaseUri</code> (<code>uima.cas.String</code>)  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>isLastSegment</code> (<code>uima.cas.Boolean</code>)   -->
<!-- </para> -->
<!-- </listitem> -->
<!-- </itemizedlist> -->
<!-- </listitem> -->
<!-- </itemizedlist> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>de.tudarmstadt.ukp.dkpro.core.api.metadata.type.ProcessorMetaData</code>  -->
<!-- </para> -->
<!-- <itemizedlist> -->
<!-- <listitem> -->
<!-- <para>Description: This metadata is not related to a SOFA, and extended -->
<!--     from a <code>uima.cas.TOP</code>. It adds metadata of the processor -->
<!--     (annotator) to the CAS.  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para>Supertype: <code>uima.cas.TOP</code>  -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para>Features  -->
<!-- </para> -->
<!-- <itemizedlist> -->
<!-- <listitem> -->
<!-- <para><code>instanceId</code> (<code>uima.cas.String</code>) -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>name</code> (<code>uima.cas.String</code>) -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>version</code> (<code>uima.cas.String</code>) -->
<!-- </para> -->
<!-- </listitem> -->
<!-- <listitem> -->
<!-- <para><code>annotatorImplementationName</code> (<code>uima.cas.String</code>) -->
<!-- </para> -->
<!-- </listitem> -->
<!-- </itemizedlist> -->
<!-- </listitem> -->
<!-- </itemizedlist> -->
<!-- </listitem> -->
<!-- </itemizedlist> -->
<!-- </section> -->

<section>
<title>NER types</title>
<para>
You can find the type definition in XML at
<code>NamedEntity.xml</code> among the attached project files.   
</para> 
<para>These types are related to named entity recognition. It uses a top
type, which represents a generic entity. Actual types (person,
organization, etc) are provided by inherited types. 
</para>
<itemizedlist>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: This is the top annotation for NER types. It is a
    subtype of UIMA annotation, and provides one feature <code>value</code>. The
    feature holds raw output of the NER recognizer. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>value</code> (<code>uima.cas.String</code>)
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Nationality</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: This type represents an entity of Nationality. 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Norp</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: (From BBN) This type is named after its subtypes,
nationality, other, religion, political. The distinction between NORP
and other types is morphological. American and Americans is a
nationality, while America and US are geographical entities. 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Ordinal</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.OrgDesc</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Organization</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.PerDesc</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Percent</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Person</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Plant</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Product</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.ProductDesc</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Quantity</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Substance</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Time</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.WorkOfArt</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Animal</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Cardinal</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.ContactInfo</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Date</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Disease</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Event</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Fac</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.FacDesc</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Game</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Gpe</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.GpeDesc</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Language</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Law</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Location</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Location</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.ner.type.Money</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<!-- <section> -->
<!-- <title>Types for Constituent Parsing</title> -->
<!-- <para>These types are related to constituent parsing results. {To be -->
<!-- added: before 1.0.} -->
<!-- </para> -->
<!-- </section> -->

<section>
<title>Types for Constituency Parsing </title>
<para>
You can find the type definition in XML at
<code>Constituent.xml</code> among the attached project files.   
</para> 
<para>These types are related to constituency parse results. There is a top
constituency type that represents the constituency parse tree
node. Various nodes are represented as subtype of this top node
type. Only the top constituency type <code>Constituent</code> has features, and
all subtypes are inheriting the features. 
</para>
<itemizedlist>
<listitem>

<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent
</para>
<itemizedlist>
<listitem>

<para>Description: The type represents a parse tree node. Actual nodes
are represented by the subtypes of this type. This type provides
the features. It has four features. <code>constituentType</code> denotes the
output of the parser (raw output of the node type, the type is
mapped into one of the subtype of the node). <code>parent</code> denotes the
parent of a parse tree node, and <code>children</code> keeps children of the
nodes, as an array. The final feature is <code>syntacticFunction</code>,
which is a string, that keeps syntactic function string for the
node if the parse outputs a syntactic function value for the
node. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>

<para><code>constituentType</code> (<code>uima.cas.String</code>)
</para>
</listitem>
<listitem>
<para><code>parent</code> (<code>uima.tcas.Annotation</code>) 
</para>
</listitem>
<listitem>
<para><code>children</code> (<code>uima.cas.FSArray</code> of <code>uima.tcas.Annotation</code>)
</para>
</listitem>
<listitem>
<para><code>syntacticFunction</code> (<code>uima.cas.String</code>) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.DT
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.EX
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.FRAG
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.FW
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.IN
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.INTJ
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.JJ
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.JJR
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.JJS
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.LS
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.LST
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.MD
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.NAC
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.NN
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.NNP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.NNPS
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.NNS
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.NP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.NX
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.PDT
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.POS
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.PP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.PRN0
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.PRP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.PRPP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.PRT
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.PUNC
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.QP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.RB
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.RBR
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.ROOT
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.RP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.RRC
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.S
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.SBAR
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.SBARQ
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.SINV
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.SQ
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.SYM
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.TO
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.UCP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.UH
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.VB
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.VBD
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.VBG
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.VBN
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.VBP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.VBZ
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.VP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.WDT
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.WHADJP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.WHADVP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.WHNP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.WHPP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.WP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.WPP
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.WRB
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.X
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.XS
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.EX
</para>
<itemizedlist>
<listitem>

<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<section>
<title>Types for Dependency Parsing</title>
<para>
You can find the type definition in XML at
<code>Dependency.xml</code> among the attached project files.   
</para> 
<para>These types are related to dependency parse results. There is a top
Dependency type that represents dependency relations (actual relations
are expressed as inherited types), and nodes are expressed as type
Dependent. Each dependent points its Governor, and the dependency relation. 
</para>
<itemizedlist>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
<itemizedlist>
<listitem>
<para>Description: Subtypes of this type, represent the dependency
    relations. The     type has three features. Two as tokens. One as
    string. Feature     <code>Governor</code> points the governor word, and
    <code>Dependent</code> points the dependent word. String <code>DependencyType</code>
    holds the dependency type, as string outputted from the
    parser.  
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code> 
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>Governor</code>
      (<code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token</code>)
</para>
</listitem>
<listitem>
<para><code>Dependent</code>
      (<code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token</code>)
</para>
</listitem>
<listitem>
<para><code>DependencyType</code>
      (<code>uima.cas.String</code>)
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Governor</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: This type represents a Governor. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code> 
</para>
</listitem>
<listitem>
<para>Features 
</para>
<itemizedlist>
<listitem>
<para><code>Dependent</code> (<code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token</code>) 
</para>
</listitem>
<listitem>
<para><code>Dependency</code>
      (<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependent</code> 
</para>
<itemizedlist>
<listitem>
<para>Description: This type represents a Dependent.  
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code> 
</para>
</listitem>
<listitem>
<para>Features 
</para>
<itemizedlist>
<listitem>
<para><code>Governor</code> (<code>de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token</code>) 
</para>
</listitem>
<listitem>
<para><code>Dependency</code>
      (<code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.NSUBJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.AMOD</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.DEP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.DET</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.POBJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PREP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.CC</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.CONJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.NN</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.NUM</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.CCOMP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.NUMBER</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.CONJ_YET</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.COP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.ADVMOD</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.COMPLM</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.AUX0</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.NSUBJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.XCOMP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.POSS</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.DOBJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.AUXPASS</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.RCMOD</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.AGENT</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.APPOS</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.TMOD</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PARTMOD</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.MEASURE</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.ACOMP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PREDET</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.MARK</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.ADVCL</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.NEG</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.NSUBJPASS</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PREPC</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.QUANTMOD</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.CSUBJPASS</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.CSUBJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.REL</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PRT</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PUNCT</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PCOMP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.XCOMP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.EXPL</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.INFMOD</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.CSUBJPASS</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.ATTR</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.IOBJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.CONJP</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PRECONJ</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PURPCL</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PRED</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.PARATAXIS</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.ABBREV</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.POSSESSIVE</code>
</para>
<itemizedlist>
<listitem>
<para>Description: 
</para>
</listitem>
<listitem>
<para>Supertype:
    <code>de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency</code>
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<section>
<title>Types for Coreference Resolution</title>
<para>
You can find the type definition in XML at
<code>Coref.xml</code> among the attached project files.   
</para> 
<para>Coreference resolution is annotated with <code>CoreferenceLink</code> type. An
instance of the type annotates a span, and links its next (corefered)
span. A number of links will form a chain, and the starting point of
this chain is pointed by <code>CoreferenceChain</code> type. 
</para>
<itemizedlist>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.coref.type.CoreferenceLink</code>
</para>
<itemizedlist>
<listitem>
<para>Description: An instance of this type annotates a single
    co-reference link. It has two features. One is <code>next</code>, which
    points another coreference link, the other is <code>referenceType</code>
    that is a string that holds the string output of the coreference
    resolutioner. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code> 
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>next</code> 
      (<code>de.tudarmstadt.ukp.dkpro.core.api.coref.type.CoreferenceLink</code>)
</para>
</listitem>
<listitem>
<para><code>referenceType</code> (<code>uima.cas.String</code>) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>de.tudarmstadt.ukp.dkpro.core.api.coref.type.CoreferenceLink</code>
</para>
<itemizedlist>
<listitem>
<para>Description: A set of <code>CoreferenceLink</code> will form a chain that is
    linked by <code>next</code> feature of the <code>Corefrencelink</code>. This type is 
</para>

<para>
    coreference link. It has two features. One is <code>next</code>, which
    points another coreference link, the other is <code>referenceType</code>
    that is a string that holds the string output of the coreference
    resolutioner. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.AnnotationBase</code> 
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>first</code> 
      (<code>de.tudarmstadt.ukp.dkpro.core.api.coref.type.CoreferenceLink</code>)
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<section>
<title>Types for Semantic Role Labels</title>
<para>
You can find the type definition in XML at
<code>SemanticRole.xml</code> among the attached project files.   
</para> 

<itemizedlist>
<listitem>
<para>EXCITEMENT.semanticrole.Predicate
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents a predicate of semantic role
labeling. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.annotation</code> 
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>

<para><code>predicateName</code> (<code>uima.cas.String</code>): This feature represents the
name of this predicate. It refers to the sense of the 
predicate in PropBank or FrameNet. 
</para>
</listitem>
<listitem>
<para><code>arguments</code> (<code>uima.cas.FSArray</code>): This
feature is an array of <code>semanticrole.Argument</code>. It holds
the predicate's arguments.  
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>EXCITEMENT.semanticrole.Argument
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents an argument of semantic role
labeling. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.annotation</code> 
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>

<para><code>argumentName</code> (<code>uima.cas.String</code>): This
feature represents the name of this argument. It refers to the
different types of arguments in string, like "A0", "A1", "AM-LOC",
etc. 
</para>
</listitem>
<listitem>
<para><code>predicates</code> (<code>uima.cas.FSArray</code>): This
feature is an array of <code>semanticrole.Predicate</code>. This is a
backward references to predicates that governs this argument.  
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<section><title>Types for Temporal/NER events</title>
<para>
You can find the type definition in XML at
<code>TemporalExpression.xml</code> among the attached project files.   
</para> 

<itemizedlist>
<listitem>

<para><code>EXCITEMENT.temporal.DefaultTimeOfText</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type is anchored to a textual region (a
paragraph, or a document), and holds the "default time" that has
been determined for this passage and can be useful to interpret 
relative time expressions ("now", "yesterday") in the text. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: 
</para>
<itemizedlist>
<listitem>

<para><code>time</code> (<code>uima.cas.String</code>): This feature holds the default
time for the textual unit which is annotated by this
annotation. The time string is expressed in the normalized ISO
8601 format (more specifically, it is a concatenation of the
ISO 8601 calendar date and extended time: "YYYY-MM-DD
hh:mm:ss"). 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.temporal.TemporalExpression</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This is the top annotation for temporal
expressions, with a normalized time representation. It has four
subtypes, which reflects TIMEX3 temporal types of Date, Time,
Duration and Set <biblioref linkend="TIMEX3"/>. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: 
</para>
<itemizedlist>
<listitem>

<para><code>text</code> (<code>uima.cas.String</code>): This feature
holds the original expression appeared on the text.  
</para>
</listitem>
<listitem>
<para><code>resolvedTime</code> (<code>uima.cas.String</code>): This feature holds the
resolved time in ISO 8601 format. For example, "Yesterday",
will be resolved into "2012-11-01", etc. 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>


<listitem><para><code>EXCITEMENT.temporal.Date</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type represents a temporal expression of type
Date. The expression describes a calendar time like yesterday,
November 1943, Tuesday 18th, etc. 
</para>
</listitem>
<listitem>
<para>Supertype: EXCITEMENT.temporal.TemporalExpression 
</para> 
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>

<listitem><para><code>EXCITEMENT.temporal.Time</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type represents a temporal expression of type
Time. The expression refers to a time of the day, even if in a very
indefinite way: eleven in the morning, late last night, twenty after
twelve, etc. 
</para>
</listitem>
<listitem>
<para>Supertype: EXCITEMENT.temporal.TemporalExpression 
</para> 
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>

<listitem><para><code>EXCITEMENT.temporal.Duration</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type represents a temporal expression of type
Duration. The expression describes a duration with explicit
durations: 2 months, 48 hours, all last night, 20 days, etc. 
</para>
</listitem>
<listitem>
<para>Supertype: EXCITEMENT.temporal.TemporalExpression 
</para> 
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>


<listitem><para><code>EXCITEMENT.temporal.Set</code>
</para>
<itemizedlist>
<listitem>
<para>Description: This type represents a temporal expression of type
Set. For example, every winter, each Monday, etc. It indicates a
recurrence pattern. 
</para>
</listitem>
<listitem>
<para>Supertype: EXCITEMENT.temporal.TemporalExpression 
</para> 
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>


</itemizedlist>
</section>

<section><title>Types for Text Alignment</title>
<para>
You can find the type definition in XML at
<code>TextAlignment.xml</code> among the attached project files.   
</para> 

<itemizedlist>
<listitem>

<para><code>EXCITEMENT.alignment.AlignedText</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type represent an aligned textual unit. 
Its span refers to the "source" linguistic entity. This can be
a token (word alignment), a syntax node (phrase alignments), or
a sentence (sentence alignment). 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: 
</para>
<itemizedlist>
<listitem>
<para><code>alignedTo</code> (<code>uima.cas.FSArray</code>): This feature holds
references to other AlignedText instances. The array 
can have multiple references, which means that it is
one-to-many alignment. Likewise, a null array can also be a
valid value for this feature, if the underlying alignment 
method is an asymmetric one; empty array means that this
AlignedText instance is a recipient, but it does not align
itself to other text. 
</para>
</listitem>
<listitem>
<para><code>alignmentType</code> (<code>uima.cas.String</code>): This feature
holds additional information for the alignment as a string. 
</para>
</listitem>

</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

</appendix>

<appendix id="TETypesXML">
<title>Type Definition: types related to TE tasks </title>

<para>This appendix section formally defines the types introduced in
<xref linkend="TETypes"/>. Note that the string
<code>EXCITEMENT</code> used in this section will be interpolated with
an actual package name in the implementation. 
</para>
<!-- <para> Starting from the specification version 1.1, we have attached a -->
<!-- java project to the specification. You can download the -->
<!-- attachement that holds all the interface codes and the type system <ulink -->
<!-- url="https://dl.dropbox.com/u/13718630/codes/excitement_interface_codes_aug29.zip"><citetitle>EXCITEMENT -->
<!-- SPEC 1.1 interfaces and type systems</citetitle></ulink>  -->
<!-- </para> -->

<section>
<title>Types related to entailment problems</title>
<para>
You can find the type definition in XML at
<code>EntailmentTypes.xml</code> among the attached project files.   
</para> 
<itemizedlist>
<listitem>

<para><code>EXCITEMENT.entailment.EntailmentMetadata</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type provides metadata for entailment problem. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>
<para><code>language</code> (<code>uima.cas.String</code>): This
string holds the language of the entailment problem. 
</para>
</listitem>
<listitem>
<para><code>task</code> (<code>uima.cas.String</code>): This string holds the task
description which can be found in the RTE challenge data. 
</para>
</listitem>
<listitem>
<para><code>channel</code> (<code>uima.cas.String</code>): This feature can holds a string
that shows the channel where this problem was originated. For
example, "customer e-mail", "online forum", or " customer
transcription", etc. 
</para>
</listitem>
<listitem>
<para><code>origin</code> (<code>uima.cas.String</code>): This metadata field can hold a
string that shows the origin of this text and hypothesis. A
company name, or a product name. 
</para>
</listitem>
<listitem>
<para><code>TextDocumentID</code> (<code>uima.cas.String</code>): This field can hold a string that identifies the document of the TextView. This feature must have a value, if TextCollectionID is not null.
</para>
</listitem>
<listitem>
<para><code>TextCollectionID</code> (<code>uima.cas.String</code>): This field can hold a string that identifies the collection name where the document of the TextView belongs to.
</para>
</listitem>
<listitem>
<para><code>HypothesisDocumentID</code> (<code>uima.cas.String</code>): This field can hold a string that identifies the document of the HypothesisView. This feature must have a value, if HypothesisCollectionID is not null.
</para>
</listitem>
<listitem>
<para><code>HypothesisCollectionID</code> (<code>uima.cas.String</code>): This field can hold a string that identifies the collection name where the document of the HypothesisView belongs to.
</para>
</listitem>

</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.entailment.Pair</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents a text-hypothesis pair. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features
</para>
<itemizedlist>
<listitem>

<para><code>pairID</code> (<code>uima.cas.String</code>): ID of this pair. The main purpose
of this value is to distinguish a certain pair among multiple
pairs. 
</para>
</listitem>
<listitem>
<para><code>text</code> (<code>EXCITEMENT.entailment.Text</code>): This feature points a
<code>Text</code> instance, which represents the text part of this pair. 
</para>
</listitem>
<listitem>
<para><code>hypothesis</code> (<code>EXCITEMENT.entailment.Hypothesis</code>): This feature
points a <code>Hypothesis</code> instance, which represents the hypothesis
part of this pair.   
</para>
</listitem>
<listitem>
<para><code>goldAnswer</code> (<code>EXCITEMENT.entailment.Decision</code>): This feature
records the gold standard answer for this pair. If the pair
(and CAS) represents a training data, this value will be filled
in with the gold standard answer. If it is a null value, the
pair represents a entailment problem that is yet to be
answered. 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.entailment.Text</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents a text part of a T-H pair. This
type annotates a text item within the TextView. It can occur
multiple times (for multi-text problems)  
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: (no features)
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.entailment.Hypothesis</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents a hypothesis part of a T-H
pair. This type annotates a hypothesis item within the
HypothesisView. It can occur multiple times (for multi-hypothesis
problems) 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: (no features)
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.entailment.Decision</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents the entailment decision. It is
a string subtype. The type can only have one of "ENTAILMENT",
"NONENTAILMENT", "PARAPHRASE", "CONTRADICTION", and "UNKNOWN"
The type can be further expanded in the future. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.cas.String</code>
</para>
</listitem>
<listitem>
<para>Features: (no features)
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>

<section><title>Types for Predicate Truth</title>
<para>
You can find the type definition in XML at
<code>PredicateTruth.xml</code> among the attached project files.   
</para> 
<itemizedlist>
<listitem>
<para><code>EXCITEMENT.predicatetruth.PredicateTruth</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents a predicate truth value
annotation. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: 
</para>
<itemizedlist>
<listitem>

<para><code>value</code> (<code>PredicateTruthValue</code>): This represents the value of
the annotation. 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.predicatetruth.PredicateTruthValue</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type provides labels for
<code>PredicateTruth</code>. This type is a string subtype that only
permits "PT+", "PT-", and "PT?".  
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.cas.String</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.predicatetruth.ClauseTruth</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents a clause truth value
annotation. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: 
</para>
<itemizedlist>
<listitem>

<para><code>value</code> (<code>ClauseTruthValue</code>): This represents the value of
the annotation. 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.predicatetruth.ClauseTruthValue</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type provides labels for
<code>ClauseTruth</code>. This type is a string subtype that only
permits "CT+", "CT-", and "CT?".  
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.cas.String</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.predicatetruth.NegationAndUncertainty</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents a negation-and-uncertainty
annotation. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: 
</para>
<itemizedlist>
<listitem>

<para><code>value</code> (<code>NegationAndUncertaintyValue</code>): This represents the value of
the annotation. 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.predicatetruth.NegationAndUncertaintyValue</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type provides labels for
<code>NegationAndUncerntainty</code>. This type is a string subtype that
only permits "NU+", "NU-", and "NU?".   
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.cas.String</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.predicatetruth.PredicateSignature</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type represents an implication signature of a
predicate. 
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.tcas.Annotation</code>
</para>
</listitem>
<listitem>
<para>Features: 
</para>
<itemizedlist>
<listitem>

<para><code>value</code> (<code>PredicateSignatureValue</code>): This represents the
value of the annotation.  
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para><code>EXCITEMENT.predicatetruth.PredicateSignatureValue</code>
</para>
<itemizedlist>
<listitem>

<para>Description: This type provides labels for
<code>PredicateSignature</code>. This type is a string subtype that
only permits one of the following strings: "+ / -", "+ / ?", "?
/ -", "- \ +", "- / ?",      "? / +", "+ / +", "- / -", "? / ?".  
</para>
</listitem>
<listitem>
<para>Supertype: <code>uima.cas.String</code> 
</para>
</listitem>
<listitem>
<para>Features: (no features) 
</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>


</appendix> 


<!-- <appendix> -->
<!-- <title>Entailment Core Interfaces</title> -->
<!-- <para> Starting from the specification version 1.1, we have attached a -->
<!-- java source code project to the specification. You can download the -->
<!-- attachement that holds all the interface codes and the type system <ulink -->
<!-- url="https://dl.dropbox.com/u/13718630/codes/excitement_interface_codes_aug29.zip"><citetitle>EXCITEMENT -->
<!-- SPEC 1.1 interfaces and type systems</citetitle></ulink>  -->
<!-- </para> -->
<!-- <para> -->
<!-- Instead of listing the source codes, Appendix C now points the -->
<!-- source code file names within the attached Java -->
<!-- project. </para>  -->
<!-- <section id="c-1"><title><code>interface EDABasic</code> and related objects</title> -->
<!-- <section> -->
<!-- <title><code>interface EDABasic</code></title> -->
<!-- <para> See <code>EDABasic.java</code> in -->
<!-- <code>eu.excitement.entailment.core</code>. </para> -->
<!-- </section> -->

<!-- <section> -->
<!-- <title><code>interface TEDecision</code></title>  -->
<!-- <para> See <code>TEDecision.java</code> in -->
<!-- <code>eu.excitement.entailment.core</code>. </para> -->
<!-- </section> -->

<!-- <section id="c-1-DecisionLabel"><title><code>enum -->
<!-- DecisionLabel</code></title> -->
<!-- <para> See <code>DecisionLabel.java</code> in -->
<!-- <code>eu.excitement.entailment.core</code>. </para> -->
<!-- </section> -->
<!-- </section> -->

<!-- <section id="c-1.5"><title><code>interface -->
<!-- SinglePairProcessHelper</code></title> -->
<!-- <para> See <code>SinglePairProcessHelper.java</code> in -->
<!-- <code>eu.excitement.entailment.core.helpers</code>. </para> -->
<!-- </section> -->

<!-- <section id="c-2"><title><code>interface EDAMulti*</code></title> -->

<!-- <section><title><code>interface EDAMultiT</code></title> -->
<!-- <para> See <code>EDAMultiT.java</code> in -->
<!-- <code>eu.excitement.entailment.core</code>. </para> -->
<!-- </section> -->

<!-- <section><title><code>interface EDAMultiH</code></title> -->
<!-- <para> See <code>EDAMultiH.java</code> in -->
<!-- <code>eu.excitement.entailment.core</code>. </para> -->
<!-- </section> -->

<!-- <section><title><code>interface EDAMultiTH</code></title> -->
<!-- <para> See <code>EDAMultiTH.java</code> in -->
<!-- <code>eu.excitement.entailment.core</code>. </para> -->
<!-- </section> -->
<!-- </section>  -->

<!-- <section id="c-3"><title><code>class MultipleTHModeHelper</code></title> -->
<!-- <para> See <code>MultipleTHModeHelper.java</code> in -->
<!-- <code>eu.excitement.entailment.core.helpers</code>. </para> -->
<!-- </section> -->

<!-- <section id="c-4.0"> -->
<!-- <title><code>interface Components</code></title> -->
<!-- <para> See <code>Components.java</code> in -->
<!-- <code>eu.excitement.entailment.core</code>. </para> -->
<!-- </section> -->

<!-- <section id="c-4"><title><code>interface DistanceCalculation</code> -->
<!-- and related objects</title> -->

<!-- <section><title><code>interface DistanceCalculation</code></title> -->
<!-- <para> See <code>DistanceCalculation.java</code> in -->
<!-- <code>eu.excitement.entailment.core.component.distance</code>. </para> -->
<!-- </section> -->

<!-- <section><title><code>class DistanceValue</code></title> -->
<!-- <para> See <code>DistanceValue.java</code> in -->
<!-- <code>eu.excitement.entailment.core.component.distance</code>. </para> -->
<!-- </section> -->

<!-- </section> -->

<!-- <section id="c-5"><title><code>class LexicalResource</code> and -->
<!-- related objects</title>  -->
<!-- <section><title><code>class LexicalRule</code></title> -->
<!-- <para> See <code>LexicalRule.java</code> in -->
<!-- <code>eu.excitement.entailment.core.component.lexicalknowledge</code>. </para> -->
<!-- </section>  -->

<!-- <section><title><code>class PartOfSpeech</code></title> -->
<!-- <para> See <code>PartOfSpeech.java</code> in -->
<!-- <code>eu.excitement.entailment.core.representation.parsetree</code>. </para> -->
<!-- </section>  -->

<!-- <section><title><code>interface RuleInfo</code></title> -->
<!-- <para> See <code>RuleInfo.java</code> in -->
<!-- <code>eu.excitement.entailment.core.component.lexicalknowledge</code>. </para> -->
<!-- </section> -->

<!-- <section><title><code>interface LexicalResource</code></title> -->
<!-- <para> See <code>LexicalResource.java</code> in -->
<!-- <code>eu.excitement.entailment.core.component.lexicalknowledge</code>. </para> -->
<!-- </section> -->

<!-- </section> -->

<!-- <section id="c-6"><title><code>interface SyntacticResource</code> and -->
<!-- related objects </title>  -->

<!-- <section><title><code>class SyntacticRule</code></title> -->
<!-- <para> See <code>SyntacticRule.java</code> in -->
<!-- <code>eu.excitement.entailment.core.component.syntacticknowledge</code>. </para> -->
<!-- </section> -->
 
<!-- <section id="c-6-BasicNode"><title>class <code>BasicNode</code> and related classes</title>   -->
<!-- <para> See <code>AbstractNode.java, BasicNode.java, NodeInfo.java, -->
<!-- EdgeInfo.java, Info.java</code>, and other codes in -->
<!-- <code>eu.excitement.entailment.core.representation.parsetree</code>. </para> -->
<!-- </section> -->

<!-- <section><title><code>interface SyntacticResource</code></title> -->
<!-- <para> See <code>SyntacticResource.java</code> in -->
<!-- <code>eu.excitement.entailment.core.component.syntacticknowledge</code>. </para> -->
<!-- </section> -->

<!-- </section> -->

<!-- </appendix> -->

<appendix id="appendix_input_format">
<title>Supported Raw Input Formats</title>

<para>  Note that only the following extended RTE-5 format is mandatory (EDAs should support them), and other formats are optional (EDAs may support them). See <xref linkend="sec-5.2"/>. </para> 
<programlisting>&lt;!ELEMENT entailment-corpus (pair+)&gt;
&lt;!ATTLIST entailment-corpus
          lang CDATA #IMPLIED <!-- ISO 639-1 code like "EN", "IT" -->
          channel CDATA #IMPLIED&gt;
&lt;!ELEMENT pair (t,h)&gt;
&lt;!ATTLIST pair
          id CDATA #REQUIRED
          entailment (ENTAILMENT|NONENTAILMENT|CONTRADICTION|
                          PARAPHRASE|UNKNOWN) #IMPLIED
          task (IR|IE|QA|SUM) #IMPLIED &gt;
&lt;!ELEMENT t (#PCDATA)&gt;
&lt;!ELEMENT h (#PCDATA)&gt;
</programlisting> 
</appendix> 

<appendix id="list_of_changes">
<title> List of changes (version history) </title>
<!-- <para>TO BE ADDED (copy and reformat CHANGES file from GitHub
repository)</para> --> 
<section>
<title>Spec v1.1.4 to v2.0</title>
<para>Version 2.0 is a major update, and a large number of new content
has been added. This section only lists the name of the changes. A good
introduction to the changes introduced in the version 2.0 can be found
in the following slides: <ulink url="http://goo.gl/MiEO8d">new components in
EOP open spec 2.0</ulink>.
</para>
<section>
<title>Newly added sections</title>
<itemizedlist>
<listitem>
<para>Context sensitive lexical resource 
</para>
</listitem>
<!--
<listitem>
<para>Phrase level knowledge resource 
</para>
</listitem>
-->
<listitem>
<para>Annotator component in Entailment Core component 
</para>
</listitem>
<listitem>
<para>Semantic Similarity Decision algorithm 
</para>
</listitem>
<listitem>
<para>Alignment component and its type system
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>Added descriptions / clarifications</title>
<itemizedlist>
<listitem>
<para>LAP interface section (previously, section 6 in 1.1) now merged
  with LAP section (section 3). 
</para>
</listitem>
<listitem>
<para>All outdated information items are cleared out, or removed.  
</para>
</listitem>
<listitem>
<para>Syntactic resource interface and Syntactic Rule updated (reflecting
  latest code development). 
</para>
</listitem>
<listitem>
<para>New introduction sub-section added, and existing introduction
  revised. 
</para>
</listitem>
</itemizedlist>
</section>
</section>

<section>
<title>Spec v1.1.3 to v1.1.4</title>
<section>
<title>Newly written subsection</title>
<para>None. Main purpose of this release is to provide the latest Web
version of the specification for further discussion. 
</para>
</section>

<section>
<title>Added descriptions / clarifications</title>
<itemizedlist>
<listitem>
<para>updated coding standard to reflect latest changes, added link to
  project Wiki coding standard page. 
</para>
</listitem>
<listitem>
<para>RTE train/test file option, task become #IMPLIED (optional) 
</para>
</listitem>
<listitem>
<para>"confidence" clarified in Lexical rule, as probability. 
</para>
</listitem>
<listitem>
<para>method close() added to both LexicalResource interface and
  SyntacticResource. 
</para>
</listitem>
<listitem>
<para>SyntacticRule updated to reflect current upstream code. 
</para>
</listitem>
</itemizedlist>
</section>
</section>

<section>
<title>Spec v1.1.2 to v1.1.3</title>
<section>
<title>Newly written subsection</title>
<section>
<title>Section 5.1.4 Common Configuration XML file format</title>
<itemizedlist>
<listitem>
<para>XML file format is added in the specification. 
</para>
</listitem>
</itemizedlist>
</section>
</section>

<section>
<title>Added descriptions / clarifications</title>
<section>
<title>Section 5.1.3. common configuration class</title>
<itemizedlist>
<listitem>
<para>removed LoadConfiguration (replaced by the constructor)
</para>
</listitem>
<listitem>
<para>added a few more get/set methods, with clear notification that the
  methods will be expanded as needed.  
</para>
</listitem>
<listitem>
<para>some minor changes according to recent WP4 discussions. 
</para>
</listitem>
</itemizedlist>
</section>
</section>
</section>

<section>
<title>Spec v1.1.1 to v1.1.2</title>
<section>
<title>Newly written section/subsections</title>
<section>
<title>Section Scoring Component (4.5)</title>
<para>A generic component that provides "features". Now distance component 
is an extension of this scoring component type. 
</para>
</section>

<section>
<title>Subsection "interface LexicalResourceWithRelation" (4.7.3)</title>
<para>Now we removed TERuleRelation from LexicalRule and LexicalResource, and 
moved them to part of "generic relational queries" of 
LexicalResourceWithRelation. 
It also now comes with related subsections like RelationSpecifiers. 
</para>
</section>
</section>

<section>
<title>Added descriptions / clarifications</title>
<section>
<title>Related to new sections</title>
<para>Related to the above three section/subsections: related figures and
descriptions are changed in LexicalRule and DistanceComponent. 
</para>
</section>

<section>
<title>Changes in interface Component</title>
<para>Now the method initialize() is removed from the interface component.  
</para>
</section>
</section>
</section>

<section>
<title>Spec v1.1 to v1.1.1</title>
<section>
<title>Newly written subsections</title>
<section>
<title>Section "Linguistic Analysis Pipeline (LAP)" added. (Sec 6)</title>
<para>This is a new section that holds a single small subsection that
describes interface <code>LAPAccess</code>. 
</para>
</section>

<section>
<title>Sub-section "Lexical Resources with Own Relations" added. (Sec 4.6.3)</title>
<para>This is a new sub-section that describes interface
<code>LexicalResourceWithOwnRelations</code>. 
</para>
</section>
</section>

<section>
<title>Added descriptions / clarifications</title>
<section>
<title>Minor bug patches and clarifications</title>
<itemizedlist>
<listitem>
<para>TEDecision removed from lexicalresource (was not synced with actual interface 
</para>
</listitem>
</itemizedlist>
<para>source) 
</para>
<itemizedlist>
<listitem>
<para>string DEFAULT<subscript>CONFIDENT</subscript> was corrected to double (was not synced with actual i
</para>
</listitem>
</itemizedlist>
<para>nterface) 
</para>
<itemizedlist>
<listitem>
<para>Entailment.* types are now clarified: where to be put (EntailmentMetadata and 
</para>
</listitem>
</itemizedlist>
<para>Pair in the CAS, Text in TextView, Hypothesis in HypothesisView) 
</para>
<itemizedlist>
<listitem>
<para>Metadata and Pair type supertype corrected (to TOP, was Annotation) 
</para>
</listitem>
<listitem>
<para>Clarification added on "higher confident" on TEDecision. 
</para>
</listitem>
</itemizedlist>
</section>
</section>
</section>

<section>
<title>Spec v1.0 to v1.1</title>
<section>
<title>Newly written subsections</title>
<section>
<title>subsection "common log" added. (#96)</title>
<itemizedlist>
<listitem>
<para>In the Section 6.3
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>subsection "Concurrent Processing" added. (#108, #19, #45)</title>
<itemizedlist>
<listitem>
<para>In the Section 4.8
</para>
</listitem>
<listitem>
<para>"multi-thread" issue. 
</para>
</listitem>
<listitem>
<para>It adds a new interface EDAConcurrentProcessing, that gets a set of
  TE problems and return a set of TEDecisions, with concurrent
  processing. 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>subsection "Two groups of LAP components added"</title>
<itemizedlist>
<listitem>
<para>In the section 3.3.4.3 
</para>
</listitem>
<listitem>
<para>Clarification section that describes, LAP components that knows TE
  annotations, and generic components that does not. 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>subsection "Other cases: T-H from multiple documents, T-H on a same document" added. (#106)</title>
<itemizedlist>
<listitem>
<para>In the section 3.3.4.4 
</para>
</listitem>
<listitem>
<para>"T view / H view" naturally maps into two document (one for T, one
  for H). The section describes how we can cope with different
  situations like T on multiple documents, and T-H on the same
  document. 
</para>
</listitem>
<listitem>
<para>3.3.4 generally revised = (from 3.3.4.1 to 3.3.4.4) 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>subsection "Boundary of LAP and Entailment Core"</title>
<itemizedlist>
<listitem>
<para>In the section 6.5 
</para>
</listitem>
<listitem>
<para>Summarizes the discussion covered untill now. 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>sub-subsection "Rooms for improvment: EDA common training" added (#35, deferred issue #109 )</title>
<itemizedlist>
<listitem>
<para>In the section 4.2.1.7 
</para>
</listitem>
</itemizedlist>
</section>
</section>

<section>
<title>Added Descriptions / Clarifications (Moved sections, added a paragraph, etc)</title>
<section>
<title>Representation of Text and Hypothesis revised (more clear description)</title>
<itemizedlist>
<listitem>
<para>Section 3.3.4.1 and 3.3.4.2 revised: From Section 3.3.4.1 to 3.3.4.4
  worth a new reading for all readers. 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>"Auxiliary Layer" section added, and some interfaces moved into it (#101)</title>
<itemizedlist>
<listitem>
<para>Section 4.3 
</para>
</listitem>
<listitem>
<para>"MultipleMode helper", "SinglePairProcessHelper (previously
  EDARawTextWithLAP)", and "InitializationHelper"  now stays in
  "Auxiliary Layer". 
</para>
</listitem>
<listitem>
<para>#101 (Something that calls both EDA and LAP cannot be an
  EDA interface) resolved.  EDARawTextWithLAP -&gt; overhauled as an
  independent "helper".  
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>(Clarification) List of interfaces that an EDA can implement</title>
<itemizedlist>
<listitem>
<para>In the section 4.2.1.8
</para>
</listitem>
<listitem>
<para>At the end of EDABasic, a short section summarizes additional
  interfaces that an EDA can implement. It also lists the list of
  auxilary layer interfaces. 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>EDAs can now implement "Reconfigurable". (#97)</title>
<itemizedlist>
<listitem>
<para>In the section 4.9.2, it also describes about EDA and reconfigurable  
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>(Clarification) "NonEntailment" relation of "LexicalRule" (#100).</title>
<itemizedlist>
<listitem>
<para>In the section 4.6.1.2
</para>
</listitem>
<listitem>
<para>a description is added to clarify what is "NonEntailment" lexical
  rule. (in the <code>TELexicalRelation</code> <code>NonEntailment</code> description. )  
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>(Clarification) About "Instance Subsection" of configuration (#105)</title>
<itemizedlist>
<listitem>
<para>In the section 5.1.2
</para>
</listitem>
<listitem>
<para>a description with example is added to clarify what "instance"
  configuration is about. 
</para>
</listitem>
</itemizedlist>
</section>
</section>

<section>
<title>Data type fixed / expanded</title>
<section>
<title>BasicNode now has canonical types that reflects UIMA types (#90)</title>
<itemizedlist>
<listitem>
<para>Section 4.7.1.3 and Figure 11. 
</para>
</listitem>
<listitem>
<para>enum DependencyRelationType, enum NamedEntity, enum CanonicalPosTag. 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>EDA interface now becomes generic with types that extends TEDecision (#73)</title>
<itemizedlist>
<listitem>
<para>TEDecision object description (removed Object returning getInfo,
  added extension description) 
</para>
</listitem>
<listitem>
<para>Generic affected parts of EDABasic, EDAMulti*, InitializationHelper, MutipleTHModeHelper 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>"relation" (canonical relation) of Lexical Resource (#89)</title>
<itemizedlist>
<listitem>
<para>Section 4.6.1 (and 4.6.1.2) 
</para>
</listitem>
<listitem>
<para>it is now a new enum type of its own (<code>TELexicalRelation</code>), which
  can hold  <code>Entailment</code> or <code>NonEntailment</code>. It no longer reuses the
  Decision enum of EDA decision. 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>EntailmentMetadata now holds additional fields</title>
<itemizedlist>
<listitem>
<para>Section 3.3.4.1
</para>
</listitem>
<listitem>
<para>it now holds TextDocumentID, TextCollectionID, HypothesisDocumentID,
  and HypothesisCollectionID. 
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>type EXCITEMENT.temporal.TemporalExpression expanded (#103)</title>
<itemizedlist>
<listitem>
<para>Section 3.3.3.9 and Appendix A.9 
</para>
</listitem>
<listitem>
<para>We now have expanded temporal expression with subtypes according to
  TIMEX3-like classification.  
</para>
</listitem>
</itemizedlist>
</section>

<section>
<title>"alignment" type now has a string feature named "type". (#80)</title>
<itemizedlist>
<listitem>
<para>Section 3.3.3.10 
</para>
</listitem>
<listitem>
<para>Alignment now has a string for additional info. 
</para>
</listitem>
</itemizedlist>
</section>
</section>

<section>
<title>Misc</title>
<section>
<title>All runtime type check (RTTI) removed from core interface (#36)</title>
<itemizedlist>
<listitem>
<para>The only exception is JCas, where we cannot avoid using RTTI. 
</para>
</listitem>
</itemizedlist>
</section>
</section>
</section>

</appendix>

<!-- <appendix> -->
<!-- <title>Revision History</title> -->

<!-- <para> -->
<!-- (This will not be included in the final specification.) When you make a major revision like adding a section, please add the revision history. For the alpha editions, we are using SVN revision number to identify the affected revision. After alpha (first relase at plenary meeting), we will adopt the version numbers.  -->
<!-- </para> -->
<!-- <para> -->
<!-- <revhistory> -->
<!-- <revision> -->
<!-- <revnumber>0</revnumber> -->
<!-- <date>11 April 2012</date> -->
<!-- <authorinitials>Gil</authorinitials> -->
<!-- <revremark>New template structure, files and logos, directories and Readmes. -->
<!-- </revremark> -->
<!-- </revision> -->
<!-- <revision> -->
<!-- <revnumber>4</revnumber> -->
<!-- <date>13 April 2012</date> -->
<!-- <authorinitials>Gil</authorinitials> -->
<!-- <revremark>Put sections, and their brief descriptions. </revremark> -->
<!-- </revision> -->
<!-- </revhistory> -->
<!-- </para> -->
<!-- </appendix> -->

<!-- <appendix role="non-normative"> -->
<!-- <title>Acknowledgements</title> -->
<!-- <para>In a typical OASIS work product one might wish to list committee participants in a non-normative annex (markup shown above in the normative annex example) using wording along the line of "The following individuals have participated in the creation of this specification and are gratefully acknowledged:"</para> -->

<!-- <itemizedlist spacing="compact"> -->
<!-- <listitem><para>Mary Baker, Associate Member</para></listitem> -->
<!-- <listitem><para>Jane Doe, Example Corporation Member</para></listitem> -->
<!-- <listitem><para>John Able, Other Example Corporation Member</para></listitem> -->
<!-- </itemizedlist> -->

<!-- <para>Note that the itemized list uses <sgmltag>spacing="compact"</sgmltag> to remove the space between list items in the printed result, not the HTML result).</para> -->

<!-- </appendix> -->
</article>
<!-- <?nospell-end?> -->

